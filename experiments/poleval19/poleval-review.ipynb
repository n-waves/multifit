{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_dir_parent</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.577922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511494</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.876617</td>\n",
       "      <td>0.526718</td>\n",
       "      <td>0.465655</td>\n",
       "      <td>0.429593</td>\n",
       "      <td>0.507218</td>\n",
       "      <td>0.389830</td>\n",
       "      <td>0.811765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.572289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.426693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.860696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.433233</td>\n",
       "      <td>0.434975</td>\n",
       "      <td>0.483857</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.573913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469194</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.849751</td>\n",
       "      <td>0.488136</td>\n",
       "      <td>0.418061</td>\n",
       "      <td>0.523841</td>\n",
       "      <td>0.477067</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.847059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.577259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.461017</td>\n",
       "      <td>0.387230</td>\n",
       "      <td>0.530552</td>\n",
       "      <td>0.441885</td>\n",
       "      <td>0.323810</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.851741</td>\n",
       "      <td>0.487973</td>\n",
       "      <td>0.418319</td>\n",
       "      <td>0.488528</td>\n",
       "      <td>0.474608</td>\n",
       "      <td>0.344660</td>\n",
       "      <td>0.835294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model_dir_parent  \\\n",
       "0  data/hate/pl-10-reddit/models/sp25k   \n",
       "1  data/hate/pl-10-reddit/models/sp25k   \n",
       "2  data/hate/pl-10-reddit/models/sp25k   \n",
       "3  data/hate/pl-10-reddit/models/sp25k   \n",
       "4  data/hate/pl-10-reddit/models/sp25k   \n",
       "\n",
       "                                          model_name  test Accuracy  \\\n",
       "0  qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.870   \n",
       "1  qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.858   \n",
       "2  qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.853   \n",
       "3  qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.855   \n",
       "4  qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.862   \n",
       "\n",
       "   test F1 score bin  test Kappa Linear  test Loss  test Matthews Correff  \\\n",
       "0           0.577922                NaN   0.456889                    NaN   \n",
       "1           0.572289                NaN   0.426693                    NaN   \n",
       "2           0.573913                NaN   0.465223                    NaN   \n",
       "3           0.577259                NaN   0.483052                    NaN   \n",
       "4           0.576687                NaN   0.491995                    NaN   \n",
       "\n",
       "   test Precision  test Recall  valid Accuracy  valid F1 score bin  \\\n",
       "0        0.511494     0.664179        0.876617            0.526718   \n",
       "1        0.479798     0.708955        0.860696            0.500000   \n",
       "2        0.469194     0.738806        0.849751            0.488136   \n",
       "3        0.473684     0.738806        0.841791            0.461017   \n",
       "4        0.489583     0.701493        0.851741            0.487973   \n",
       "\n",
       "   valid Kappa Linear  valid Loss  valid Matthews Correff  valid Precision  \\\n",
       "0            0.465655    0.429593                0.507218         0.389830   \n",
       "1            0.433233    0.434975                0.483857         0.358974   \n",
       "2            0.418061    0.523841                0.477067         0.342857   \n",
       "3            0.387230    0.530552                0.441885         0.323810   \n",
       "4            0.418319    0.488528                0.474608         0.344660   \n",
       "\n",
       "   valid Recall  \n",
       "0      0.811765  \n",
       "1      0.823529  \n",
       "2      0.847059  \n",
       "3      0.800000  \n",
       "4      0.835294  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"./poleval.csv\", index_col=0)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_dir_parent</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>bwdlstm_ft20_cl8_lmseed-0-ftseed-0-clsweightse...</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.498822</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.930348</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>0.358982</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.694118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>bwdlstm_ft20_cl8_lmseed-0-ftseed-0-clsweightse...</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.519480</td>\n",
       "      <td>0.466780</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.921393</td>\n",
       "      <td>0.594872</td>\n",
       "      <td>0.351481</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.682353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>bwdlstm_ft20_cl8_lmseed-0-ftseed-0-clsweightse...</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.491071</td>\n",
       "      <td>0.452916</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.410448</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.289560</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>bwdlstm_ft20_cl8_lmseed-0-ftseed-0-clsweightse...</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.587234</td>\n",
       "      <td>0.510721</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>0.927363</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>0.393536</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.670588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>bwdlstm_ft20_cl8_lmseed-0-ftseed-0-clsweightse...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.443047</td>\n",
       "      <td>0.680412</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.322416</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.670588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model_dir_parent  \\\n",
       "0  data/hate/pl-10-reddit/models/sp25k   \n",
       "1  data/hate/pl-10-reddit/models/sp25k   \n",
       "2  data/hate/pl-10-reddit/models/sp25k   \n",
       "3  data/hate/pl-10-reddit/models/sp25k   \n",
       "4  data/hate/pl-10-reddit/models/sp25k   \n",
       "\n",
       "                                          model_name  test Accuracy  \\\n",
       "0  bwdlstm_ft20_cl8_lmseed-0-ftseed-0-clsweightse...          0.896   \n",
       "1  bwdlstm_ft20_cl8_lmseed-0-ftseed-0-clsweightse...          0.889   \n",
       "2  bwdlstm_ft20_cl8_lmseed-0-ftseed-0-clsweightse...          0.886   \n",
       "3  bwdlstm_ft20_cl8_lmseed-0-ftseed-0-clsweightse...          0.903   \n",
       "4  bwdlstm_ft20_cl8_lmseed-0-ftseed-0-clsweightse...          0.901   \n",
       "\n",
       "   test F1 score bin  test Loss  test Precision  test Recall  valid Accuracy  \\\n",
       "0           0.555556   0.498822        0.650000     0.485075        0.930348   \n",
       "1           0.519480   0.466780        0.618557     0.447761        0.921393   \n",
       "2           0.491071   0.452916        0.611111     0.410448        0.920398   \n",
       "3           0.587234   0.510721        0.683168     0.514925        0.927363   \n",
       "4           0.571429   0.443047        0.680412     0.492537        0.924378   \n",
       "\n",
       "   valid F1 score bin  valid Loss  valid Precision  valid Recall  \n",
       "0            0.627660    0.358982         0.572816      0.694118  \n",
       "1            0.594872    0.351481         0.527273      0.682353  \n",
       "2            0.578947    0.289560         0.523810      0.647059  \n",
       "3            0.609626    0.393536         0.558824      0.670588  \n",
       "4            0.600000    0.322416         0.542857      0.670588  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"./all-results-fixed.csv\", index_col=0) # marcins results\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_dir_parent</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.577922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511494</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.876617</td>\n",
       "      <td>0.526718</td>\n",
       "      <td>0.465655</td>\n",
       "      <td>0.429593</td>\n",
       "      <td>0.507218</td>\n",
       "      <td>0.389830</td>\n",
       "      <td>0.811765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.572289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.426693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.860696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.433233</td>\n",
       "      <td>0.434975</td>\n",
       "      <td>0.483857</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.573913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469194</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.849751</td>\n",
       "      <td>0.488136</td>\n",
       "      <td>0.418061</td>\n",
       "      <td>0.523841</td>\n",
       "      <td>0.477067</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.847059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.577259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.461017</td>\n",
       "      <td>0.387230</td>\n",
       "      <td>0.530552</td>\n",
       "      <td>0.441885</td>\n",
       "      <td>0.323810</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.851741</td>\n",
       "      <td>0.487973</td>\n",
       "      <td>0.418319</td>\n",
       "      <td>0.488528</td>\n",
       "      <td>0.474608</td>\n",
       "      <td>0.344660</td>\n",
       "      <td>0.835294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model_dir_parent  \\\n",
       "0  data/hate/pl-10-reddit/models/sp25k   \n",
       "1  data/hate/pl-10-reddit/models/sp25k   \n",
       "2  data/hate/pl-10-reddit/models/sp25k   \n",
       "3  data/hate/pl-10-reddit/models/sp25k   \n",
       "4  data/hate/pl-10-reddit/models/sp25k   \n",
       "\n",
       "                                          model_name  test Accuracy  \\\n",
       "0  qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.870   \n",
       "1  qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.858   \n",
       "2  qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.853   \n",
       "3  qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.855   \n",
       "4  qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.862   \n",
       "\n",
       "   test F1 score bin  test Kappa Linear  test Loss  test Matthews Correff  \\\n",
       "0           0.577922                NaN   0.456889                    NaN   \n",
       "1           0.572289                NaN   0.426693                    NaN   \n",
       "2           0.573913                NaN   0.465223                    NaN   \n",
       "3           0.577259                NaN   0.483052                    NaN   \n",
       "4           0.576687                NaN   0.491995                    NaN   \n",
       "\n",
       "   test Precision  test Recall  valid Accuracy  valid F1 score bin  \\\n",
       "0        0.511494     0.664179        0.876617            0.526718   \n",
       "1        0.479798     0.708955        0.860696            0.500000   \n",
       "2        0.469194     0.738806        0.849751            0.488136   \n",
       "3        0.473684     0.738806        0.841791            0.461017   \n",
       "4        0.489583     0.701493        0.851741            0.487973   \n",
       "\n",
       "   valid Kappa Linear  valid Loss  valid Matthews Correff  valid Precision  \\\n",
       "0            0.465655    0.429593                0.507218         0.389830   \n",
       "1            0.433233    0.434975                0.483857         0.358974   \n",
       "2            0.418061    0.523841                0.477067         0.342857   \n",
       "3            0.387230    0.530552                0.441885         0.323810   \n",
       "4            0.418319    0.488528                0.474608         0.344660   \n",
       "\n",
       "   valid Recall  \n",
       "0      0.811765  \n",
       "1      0.823529  \n",
       "2      0.847059  \n",
       "3      0.800000  \n",
       "4      0.835294  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1,df2], sort=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"model_name\"].str.contains(\"bwdlstm\")] # remove bwdlstm as it is wrong model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['qrnn_ft0_cl8', 'qrnn_ft20_cl8', 'qrnn_ft6_cl8', 'lstm_ft0_cl8', 'lstm_ft20_cl8', 'lstm_ft6_cl8',\n",
       "       'lstm_noearly_stop_ft6_cl8', 'lstm_nowce_ft6_cl8', 'lstm_small_ft6_el20', 'lstm_tmp-100', 'lstm_dp05_ft20_cl8',\n",
       "       'lstm_dp05_ft6_cl8'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"arch\"] = df[\"model_name\"].str.extract(\"(.*?)_lmseed.*\")\n",
    "df[\"arch\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['reddit', 'wiki'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ds\"] = df[\"model_dir_parent\"].str.extract(\".*pl-10-(.*)/models.*\")\n",
    "df[\"ds\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df[\"arch\"] == \"lstm_tmp-100\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.884046</td>\n",
       "      <td>0.541107</td>\n",
       "      <td>0.386346</td>\n",
       "      <td>0.468251</td>\n",
       "      <td>0.413414</td>\n",
       "      <td>0.592322</td>\n",
       "      <td>0.517430</td>\n",
       "      <td>0.907761</td>\n",
       "      <td>0.559696</td>\n",
       "      <td>0.484952</td>\n",
       "      <td>0.363650</td>\n",
       "      <td>0.505940</td>\n",
       "      <td>0.488150</td>\n",
       "      <td>0.681628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.044664</td>\n",
       "      <td>0.052320</td>\n",
       "      <td>0.058604</td>\n",
       "      <td>0.039129</td>\n",
       "      <td>0.066598</td>\n",
       "      <td>0.100605</td>\n",
       "      <td>0.022296</td>\n",
       "      <td>0.037469</td>\n",
       "      <td>0.041443</td>\n",
       "      <td>0.058652</td>\n",
       "      <td>0.030642</td>\n",
       "      <td>0.073917</td>\n",
       "      <td>0.082774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.294158</td>\n",
       "      <td>0.306861</td>\n",
       "      <td>0.330020</td>\n",
       "      <td>0.369281</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.790050</td>\n",
       "      <td>0.418733</td>\n",
       "      <td>0.332226</td>\n",
       "      <td>0.218546</td>\n",
       "      <td>0.390519</td>\n",
       "      <td>0.273381</td>\n",
       "      <td>0.447059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.517763</td>\n",
       "      <td>0.341244</td>\n",
       "      <td>0.430748</td>\n",
       "      <td>0.392833</td>\n",
       "      <td>0.543268</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.894279</td>\n",
       "      <td>0.537962</td>\n",
       "      <td>0.461222</td>\n",
       "      <td>0.329288</td>\n",
       "      <td>0.487962</td>\n",
       "      <td>0.427035</td>\n",
       "      <td>0.623529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.548852</td>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.464669</td>\n",
       "      <td>0.412878</td>\n",
       "      <td>0.601868</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>0.562657</td>\n",
       "      <td>0.490675</td>\n",
       "      <td>0.358859</td>\n",
       "      <td>0.507218</td>\n",
       "      <td>0.504137</td>\n",
       "      <td>0.670588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.429274</td>\n",
       "      <td>0.497233</td>\n",
       "      <td>0.442910</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.587191</td>\n",
       "      <td>0.513207</td>\n",
       "      <td>0.394423</td>\n",
       "      <td>0.526609</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>0.741176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.487822</td>\n",
       "      <td>0.743211</td>\n",
       "      <td>0.507263</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.843284</td>\n",
       "      <td>0.942289</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.605920</td>\n",
       "      <td>0.708696</td>\n",
       "      <td>0.605933</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.894118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear   test Loss  \\\n",
       "count     584.000000         584.000000          38.000000  584.000000   \n",
       "mean        0.884046           0.541107           0.386346    0.468251   \n",
       "std         0.013672           0.044664           0.052320    0.058604   \n",
       "min         0.786000           0.340909           0.294158    0.306861   \n",
       "25%         0.878000           0.517763           0.341244    0.430748   \n",
       "50%         0.886000           0.548852           0.391300    0.464669   \n",
       "75%         0.893000           0.571429           0.429274    0.497233   \n",
       "max         0.912000           0.622222           0.487822    0.743211   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count              38.000000      584.000000   584.000000      584.000000   \n",
       "mean                0.413414        0.592322     0.517430        0.907761   \n",
       "std                 0.039129        0.066598     0.100605        0.022296   \n",
       "min                 0.330020        0.369281     0.223881        0.790050   \n",
       "25%                 0.392833        0.543268     0.447761        0.894279   \n",
       "50%                 0.412878        0.601868     0.500000        0.916418   \n",
       "75%                 0.442910        0.641304     0.597015        0.923383   \n",
       "max                 0.507263        0.756098     0.843284        0.942289   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count          584.000000          324.000000  584.000000   \n",
       "mean             0.559696            0.484952    0.363650   \n",
       "std              0.037469            0.041443    0.058652   \n",
       "min              0.418733            0.332226    0.218546   \n",
       "25%              0.537962            0.461222    0.329288   \n",
       "50%              0.562657            0.490675    0.358859   \n",
       "75%              0.587191            0.513207    0.394423   \n",
       "max              0.648936            0.605920    0.708696   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count              324.000000       584.000000    584.000000  \n",
       "mean                 0.505940         0.488150      0.681628  \n",
       "std                  0.030642         0.073917      0.082774  \n",
       "min                  0.390519         0.273381      0.447059  \n",
       "25%                  0.487962         0.427035      0.623529  \n",
       "50%                  0.507218         0.504137      0.670588  \n",
       "75%                  0.526609         0.540816      0.741176  \n",
       "max                  0.605933         0.764706      0.894118  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM on wiki or on reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.880810</td>\n",
       "      <td>0.514146</td>\n",
       "      <td>0.386346</td>\n",
       "      <td>0.464212</td>\n",
       "      <td>0.413414</td>\n",
       "      <td>0.581972</td>\n",
       "      <td>0.480881</td>\n",
       "      <td>0.906833</td>\n",
       "      <td>0.542377</td>\n",
       "      <td>0.493213</td>\n",
       "      <td>0.364210</td>\n",
       "      <td>0.505140</td>\n",
       "      <td>0.485381</td>\n",
       "      <td>0.642577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.011998</td>\n",
       "      <td>0.052149</td>\n",
       "      <td>0.052320</td>\n",
       "      <td>0.065367</td>\n",
       "      <td>0.039129</td>\n",
       "      <td>0.061509</td>\n",
       "      <td>0.105518</td>\n",
       "      <td>0.022386</td>\n",
       "      <td>0.033830</td>\n",
       "      <td>0.042047</td>\n",
       "      <td>0.061358</td>\n",
       "      <td>0.032287</td>\n",
       "      <td>0.079529</td>\n",
       "      <td>0.082740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.294158</td>\n",
       "      <td>0.306861</td>\n",
       "      <td>0.330020</td>\n",
       "      <td>0.369281</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.790050</td>\n",
       "      <td>0.418733</td>\n",
       "      <td>0.332226</td>\n",
       "      <td>0.218546</td>\n",
       "      <td>0.390519</td>\n",
       "      <td>0.273381</td>\n",
       "      <td>0.447059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.495575</td>\n",
       "      <td>0.341244</td>\n",
       "      <td>0.424022</td>\n",
       "      <td>0.392833</td>\n",
       "      <td>0.544839</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.894527</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.466806</td>\n",
       "      <td>0.335349</td>\n",
       "      <td>0.486658</td>\n",
       "      <td>0.421900</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.522800</td>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.458297</td>\n",
       "      <td>0.412878</td>\n",
       "      <td>0.579193</td>\n",
       "      <td>0.481343</td>\n",
       "      <td>0.912935</td>\n",
       "      <td>0.546625</td>\n",
       "      <td>0.499253</td>\n",
       "      <td>0.364061</td>\n",
       "      <td>0.507686</td>\n",
       "      <td>0.489378</td>\n",
       "      <td>0.635294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.429274</td>\n",
       "      <td>0.492554</td>\n",
       "      <td>0.442910</td>\n",
       "      <td>0.616329</td>\n",
       "      <td>0.557836</td>\n",
       "      <td>0.922139</td>\n",
       "      <td>0.563532</td>\n",
       "      <td>0.521648</td>\n",
       "      <td>0.396743</td>\n",
       "      <td>0.525712</td>\n",
       "      <td>0.537937</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.487822</td>\n",
       "      <td>0.743211</td>\n",
       "      <td>0.507263</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.843284</td>\n",
       "      <td>0.942289</td>\n",
       "      <td>0.639053</td>\n",
       "      <td>0.605920</td>\n",
       "      <td>0.708696</td>\n",
       "      <td>0.605933</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.894118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear   test Loss  \\\n",
       "count     210.000000         210.000000          38.000000  210.000000   \n",
       "mean        0.880810           0.514146           0.386346    0.464212   \n",
       "std         0.011998           0.052149           0.052320    0.065367   \n",
       "min         0.786000           0.340909           0.294158    0.306861   \n",
       "25%         0.877000           0.495575           0.341244    0.424022   \n",
       "50%         0.883000           0.522800           0.391300    0.458297   \n",
       "75%         0.888000           0.550000           0.429274    0.492554   \n",
       "max         0.901000           0.608392           0.487822    0.743211   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count              38.000000      210.000000   210.000000      210.000000   \n",
       "mean                0.413414        0.581972     0.480881        0.906833   \n",
       "std                 0.039129        0.061509     0.105518        0.022386   \n",
       "min                 0.330020        0.369281     0.223881        0.790050   \n",
       "25%                 0.392833        0.544839     0.417910        0.894527   \n",
       "50%                 0.412878        0.579193     0.481343        0.912935   \n",
       "75%                 0.442910        0.616329     0.557836        0.922139   \n",
       "max                 0.507263        0.756098     0.843284        0.942289   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count          210.000000          210.000000  210.000000   \n",
       "mean             0.542377            0.493213    0.364210   \n",
       "std              0.033830            0.042047    0.061358   \n",
       "min              0.418733            0.332226    0.218546   \n",
       "25%              0.521739            0.466806    0.335349   \n",
       "50%              0.546625            0.499253    0.364061   \n",
       "75%              0.563532            0.521648    0.396743   \n",
       "max              0.639053            0.605920    0.708696   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count              210.000000       210.000000    210.000000  \n",
       "mean                 0.505140         0.485381      0.642577  \n",
       "std                  0.032287         0.079529      0.082740  \n",
       "min                  0.390519         0.273381      0.447059  \n",
       "25%                  0.486658         0.421900      0.588235  \n",
       "50%                  0.507686         0.489378      0.635294  \n",
       "75%                  0.525712         0.537937      0.705882  \n",
       "max                  0.605933         0.764706      0.894118  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focus=[\"test F1 score bin\", \"valid F1 score bin\"]\n",
    "wiki = df[df[\"ds\"] == \"wiki\"]\n",
    "wiki.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.895304</td>\n",
       "      <td>0.557343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.463688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645122</td>\n",
       "      <td>0.493592</td>\n",
       "      <td>0.920674</td>\n",
       "      <td>0.587429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.337478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527694</td>\n",
       "      <td>0.667008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005932</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036094</td>\n",
       "      <td>0.045885</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.020043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033589</td>\n",
       "      <td>0.044828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.873000</td>\n",
       "      <td>0.479638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.388060</td>\n",
       "      <td>0.890547</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.227242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421384</td>\n",
       "      <td>0.576471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.891750</td>\n",
       "      <td>0.538375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.445491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.622321</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>0.574359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.317254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.508698</td>\n",
       "      <td>0.635294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642940</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.921393</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.338125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.658824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.579652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.494402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.529851</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.361941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.547632</td>\n",
       "      <td>0.694118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.554716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.936318</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.474846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617977</td>\n",
       "      <td>0.835294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear   test Loss  \\\n",
       "count     184.000000         184.000000                0.0  184.000000   \n",
       "mean        0.895304           0.557343                NaN    0.463688   \n",
       "std         0.005932           0.029341                NaN    0.045555   \n",
       "min         0.873000           0.479638                NaN    0.308932   \n",
       "25%         0.891750           0.538375                NaN    0.445491   \n",
       "50%         0.896000           0.560000                NaN    0.469791   \n",
       "75%         0.899000           0.579652                NaN    0.494402   \n",
       "max         0.912000           0.622222                NaN    0.554716   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count                    0.0      184.000000   184.000000      184.000000   \n",
       "mean                     NaN        0.645122     0.493592        0.920674   \n",
       "std                      NaN        0.036094     0.045885        0.007117   \n",
       "min                      NaN        0.523810     0.388060        0.890547   \n",
       "25%                      NaN        0.622321     0.455224        0.917413   \n",
       "50%                      NaN        0.642940     0.492537        0.921393   \n",
       "75%                      NaN        0.670330     0.529851        0.925373   \n",
       "max                      NaN        0.744681     0.626866        0.936318   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count          184.000000                 0.0  184.000000   \n",
       "mean             0.587429                 NaN    0.337478   \n",
       "std              0.020043                 NaN    0.037845   \n",
       "min              0.531250                 NaN    0.227242   \n",
       "25%              0.574359                 NaN    0.317254   \n",
       "50%              0.587629                 NaN    0.338125   \n",
       "75%              0.600000                 NaN    0.361941   \n",
       "max              0.648936                 NaN    0.474846   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count                     0.0       184.000000    184.000000  \n",
       "mean                      NaN         0.527694      0.667008  \n",
       "std                       NaN         0.033589      0.044828  \n",
       "min                       NaN         0.421384      0.576471  \n",
       "25%                       NaN         0.508698      0.635294  \n",
       "50%                       NaN         0.530000      0.658824  \n",
       "75%                       NaN         0.547632      0.694118  \n",
       "max                       NaN         0.617977      0.835294  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focus=[\"test F1 score bin\", \"valid F1 score bin\"]\n",
    "reddit = df[df[\"arch\"].str.startswith(\"lstm_ft\") & (df[\"ds\"] == \"reddit\")]\n",
    "reddit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_dir_parent</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "      <th>arch</th>\n",
       "      <th>ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.492891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.388060</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542553</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.561702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.930348</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.358982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.519480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.463098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.921393</td>\n",
       "      <td>0.594872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.351481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.495575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.449501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.289560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.587234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>0.927363</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.393536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.558952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.673684</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.927363</td>\n",
       "      <td>0.617801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.381014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.556604</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.546218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.457810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.314275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563107</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.542222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.375518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533981</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.439562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670213</td>\n",
       "      <td>0.470149</td>\n",
       "      <td>0.936318</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.259310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617977</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.544643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522936</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.584071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.579235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.327854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.541485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.481187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.334556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.506912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.506958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.410448</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.585635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.353671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.543779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.434235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.440298</td>\n",
       "      <td>0.931343</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.305361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.635593</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.919403</td>\n",
       "      <td>0.588832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.394445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.506787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.354573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.453971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.583784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.324631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637363</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.926368</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.347545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.556701</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.613445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>0.574359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.354521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.608059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.512180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.597122</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.546256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.474846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.921393</td>\n",
       "      <td>0.590674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.382168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>0.581281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.360472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.513043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.440298</td>\n",
       "      <td>0.926368</td>\n",
       "      <td>0.579545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.261940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.560440</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.575107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.435515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533981</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.601626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.512516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>0.599034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.362585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.293562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.562771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.321803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.488479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.503330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.395522</td>\n",
       "      <td>0.931343</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.286096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.470149</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.579235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.317424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-5...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.595918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.453026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.369372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-5...</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.412375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.901493</td>\n",
       "      <td>0.543779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.341758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.446970</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.343866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.552301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.526710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.579235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.542222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.245958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>0.569948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.366041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.542986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.484061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.292909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.573034</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.561265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.478323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.596639</td>\n",
       "      <td>0.529851</td>\n",
       "      <td>0.912438</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.371474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.486726</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.559671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.314330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626263</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.342852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.548043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.401640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.890547</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.359008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421384</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.528139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>0.556150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.327826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.568965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.445748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.303262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633027</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>0.589474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.334571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.508621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.440298</td>\n",
       "      <td>0.921393</td>\n",
       "      <td>0.586387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.341839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.590038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.384665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.906468</td>\n",
       "      <td>0.572727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.314057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>0.561798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.337562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>0.589474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.342792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.303226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.347164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.429450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660550</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>0.554974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.313667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.521367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.583784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.490258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.914428</td>\n",
       "      <td>0.574257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.392229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.502203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.425373</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.548523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.631068</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.329670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542056</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.490045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619835</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.914428</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.358677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.332558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504274</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.338581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.607004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.919403</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.237768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516393</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>0.574359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.372592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model_dir_parent  \\\n",
       "76   data/hate/pl-10-reddit/models/sp25k   \n",
       "77   data/hate/pl-10-reddit/models/sp25k   \n",
       "78   data/hate/pl-10-reddit/models/sp25k   \n",
       "79   data/hate/pl-10-reddit/models/sp25k   \n",
       "80   data/hate/pl-10-reddit/models/sp25k   \n",
       "81   data/hate/pl-10-reddit/models/sp25k   \n",
       "82   data/hate/pl-10-reddit/models/sp25k   \n",
       "83   data/hate/pl-10-reddit/models/sp25k   \n",
       "84   data/hate/pl-10-reddit/models/sp25k   \n",
       "85   data/hate/pl-10-reddit/models/sp25k   \n",
       "86   data/hate/pl-10-reddit/models/sp25k   \n",
       "87   data/hate/pl-10-reddit/models/sp25k   \n",
       "88   data/hate/pl-10-reddit/models/sp25k   \n",
       "89   data/hate/pl-10-reddit/models/sp25k   \n",
       "90   data/hate/pl-10-reddit/models/sp25k   \n",
       "91   data/hate/pl-10-reddit/models/sp25k   \n",
       "92   data/hate/pl-10-reddit/models/sp25k   \n",
       "93   data/hate/pl-10-reddit/models/sp25k   \n",
       "94   data/hate/pl-10-reddit/models/sp25k   \n",
       "95   data/hate/pl-10-reddit/models/sp25k   \n",
       "96   data/hate/pl-10-reddit/models/sp25k   \n",
       "97   data/hate/pl-10-reddit/models/sp25k   \n",
       "98   data/hate/pl-10-reddit/models/sp25k   \n",
       "99   data/hate/pl-10-reddit/models/sp25k   \n",
       "100  data/hate/pl-10-reddit/models/sp25k   \n",
       "101  data/hate/pl-10-reddit/models/sp25k   \n",
       "102  data/hate/pl-10-reddit/models/sp25k   \n",
       "103  data/hate/pl-10-reddit/models/sp25k   \n",
       "104  data/hate/pl-10-reddit/models/sp25k   \n",
       "105  data/hate/pl-10-reddit/models/sp25k   \n",
       "..                                   ...   \n",
       "306  data/hate/pl-10-reddit/models/sp25k   \n",
       "307  data/hate/pl-10-reddit/models/sp25k   \n",
       "308  data/hate/pl-10-reddit/models/sp25k   \n",
       "309  data/hate/pl-10-reddit/models/sp25k   \n",
       "310  data/hate/pl-10-reddit/models/sp25k   \n",
       "311  data/hate/pl-10-reddit/models/sp25k   \n",
       "312  data/hate/pl-10-reddit/models/sp25k   \n",
       "313  data/hate/pl-10-reddit/models/sp25k   \n",
       "314  data/hate/pl-10-reddit/models/sp25k   \n",
       "315  data/hate/pl-10-reddit/models/sp25k   \n",
       "316  data/hate/pl-10-reddit/models/sp25k   \n",
       "317  data/hate/pl-10-reddit/models/sp25k   \n",
       "318  data/hate/pl-10-reddit/models/sp25k   \n",
       "319  data/hate/pl-10-reddit/models/sp25k   \n",
       "320  data/hate/pl-10-reddit/models/sp25k   \n",
       "321  data/hate/pl-10-reddit/models/sp25k   \n",
       "322  data/hate/pl-10-reddit/models/sp25k   \n",
       "323  data/hate/pl-10-reddit/models/sp25k   \n",
       "324  data/hate/pl-10-reddit/models/sp25k   \n",
       "325  data/hate/pl-10-reddit/models/sp25k   \n",
       "326  data/hate/pl-10-reddit/models/sp25k   \n",
       "327  data/hate/pl-10-reddit/models/sp25k   \n",
       "328  data/hate/pl-10-reddit/models/sp25k   \n",
       "329  data/hate/pl-10-reddit/models/sp25k   \n",
       "330  data/hate/pl-10-reddit/models/sp25k   \n",
       "331  data/hate/pl-10-reddit/models/sp25k   \n",
       "332  data/hate/pl-10-reddit/models/sp25k   \n",
       "333  data/hate/pl-10-reddit/models/sp25k   \n",
       "334  data/hate/pl-10-reddit/models/sp25k   \n",
       "335  data/hate/pl-10-reddit/models/sp25k   \n",
       "\n",
       "                                            model_name  test Accuracy  \\\n",
       "76   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.893   \n",
       "77   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.897   \n",
       "78   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.889   \n",
       "79   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.886   \n",
       "80   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.903   \n",
       "81   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.899   \n",
       "82   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.896   \n",
       "83   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.892   \n",
       "84   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.897   \n",
       "85   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.898   \n",
       "86   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.898   \n",
       "87   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.906   \n",
       "88   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.895   \n",
       "89   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.893   \n",
       "90   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.901   \n",
       "91   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.898   \n",
       "92   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.891   \n",
       "93   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.896   \n",
       "94   lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...          0.891   \n",
       "95   lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.908   \n",
       "96   lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.893   \n",
       "97   lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.895   \n",
       "98   lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.892   \n",
       "99   lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.888   \n",
       "100  lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.901   \n",
       "101  lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.902   \n",
       "102  lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.894   \n",
       "103  lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.899   \n",
       "104  lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.889   \n",
       "105  lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.896   \n",
       "..                                                 ...            ...   \n",
       "306  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-5...          0.901   \n",
       "307  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-5...          0.890   \n",
       "308  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.900   \n",
       "309  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.893   \n",
       "310  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.897   \n",
       "311  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.895   \n",
       "312  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.899   \n",
       "313  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.889   \n",
       "314  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.893   \n",
       "315  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.891   \n",
       "316  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.873   \n",
       "317  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.891   \n",
       "318  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.900   \n",
       "319  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.895   \n",
       "320  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.886   \n",
       "321  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.893   \n",
       "322  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.892   \n",
       "323  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.904   \n",
       "324  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.894   \n",
       "325  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.902   \n",
       "326  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.901   \n",
       "327  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.888   \n",
       "328  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.901   \n",
       "329  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.887   \n",
       "330  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.893   \n",
       "331  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.895   \n",
       "332  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.895   \n",
       "333  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.894   \n",
       "334  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.899   \n",
       "335  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.906   \n",
       "\n",
       "     test F1 score bin  test Kappa Linear  test Loss  test Matthews Correff  \\\n",
       "76            0.492891                NaN   0.500168                    NaN   \n",
       "77            0.561702                NaN   0.496962                    NaN   \n",
       "78            0.519480                NaN   0.463098                    NaN   \n",
       "79            0.495575                NaN   0.449501                    NaN   \n",
       "80            0.587234                NaN   0.509811                    NaN   \n",
       "81            0.558952                NaN   0.444723                    NaN   \n",
       "82            0.555556                NaN   0.473386                    NaN   \n",
       "83            0.546218                NaN   0.457810                    NaN   \n",
       "84            0.542222                NaN   0.534131                    NaN   \n",
       "85            0.552632                NaN   0.439562                    NaN   \n",
       "86            0.544643                NaN   0.465242                    NaN   \n",
       "87            0.584071                NaN   0.447657                    NaN   \n",
       "88            0.541485                NaN   0.481187                    NaN   \n",
       "89            0.506912                NaN   0.506958                    NaN   \n",
       "90            0.543779                NaN   0.434235                    NaN   \n",
       "91            0.595238                NaN   0.507020                    NaN   \n",
       "92            0.506787                NaN   0.460268                    NaN   \n",
       "93            0.518519                NaN   0.453971                    NaN   \n",
       "94            0.515556                NaN   0.519612                    NaN   \n",
       "95            0.613445                NaN   0.444260                    NaN   \n",
       "96            0.608059                NaN   0.512180                    NaN   \n",
       "97            0.556962                NaN   0.519183                    NaN   \n",
       "98            0.564516                NaN   0.528106                    NaN   \n",
       "99            0.513043                NaN   0.464349                    NaN   \n",
       "100           0.575107                NaN   0.435515                    NaN   \n",
       "101           0.601626                NaN   0.512516                    NaN   \n",
       "102           0.530973                NaN   0.515985                    NaN   \n",
       "103           0.562771                NaN   0.452660                    NaN   \n",
       "104           0.488479                NaN   0.503330                    NaN   \n",
       "105           0.547826                NaN   0.465411                    NaN   \n",
       "..                 ...                ...        ...                    ...   \n",
       "306           0.595918                NaN   0.453026                    NaN   \n",
       "307           0.576923                NaN   0.412375                    NaN   \n",
       "308           0.576271                NaN   0.458157                    NaN   \n",
       "309           0.552301                NaN   0.526710                    NaN   \n",
       "310           0.542222                NaN   0.378023                    NaN   \n",
       "311           0.549356                NaN   0.502734                    NaN   \n",
       "312           0.542986                NaN   0.484061                    NaN   \n",
       "313           0.561265                NaN   0.478323                    NaN   \n",
       "314           0.559671                NaN   0.460062                    NaN   \n",
       "315           0.532189                NaN   0.520550                    NaN   \n",
       "316           0.548043                NaN   0.401640                    NaN   \n",
       "317           0.528139                NaN   0.489808                    NaN   \n",
       "318           0.568965                NaN   0.445748                    NaN   \n",
       "319           0.567901                NaN   0.542561                    NaN   \n",
       "320           0.508621                NaN   0.528722                    NaN   \n",
       "321           0.590038                NaN   0.384665                    NaN   \n",
       "322           0.534483                NaN   0.502705                    NaN   \n",
       "323           0.586207                NaN   0.488476                    NaN   \n",
       "324           0.558333                NaN   0.466521                    NaN   \n",
       "325           0.566372                NaN   0.447245                    NaN   \n",
       "326           0.592593                NaN   0.429450                    NaN   \n",
       "327           0.521367                NaN   0.500936                    NaN   \n",
       "328           0.602410                NaN   0.490258                    NaN   \n",
       "329           0.502203                NaN   0.516663                    NaN   \n",
       "330           0.548523                NaN   0.473883                    NaN   \n",
       "331           0.588235                NaN   0.490045                    NaN   \n",
       "332           0.549356                NaN   0.458278                    NaN   \n",
       "333           0.558333                NaN   0.485095                    NaN   \n",
       "334           0.607004                NaN   0.308932                    NaN   \n",
       "335           0.614754                NaN   0.471272                    NaN   \n",
       "\n",
       "     test Precision  test Recall  valid Accuracy  valid F1 score bin  \\\n",
       "76         0.675325     0.388060        0.923383            0.569832   \n",
       "77         0.653465     0.492537        0.930348            0.627660   \n",
       "78         0.618557     0.447761        0.921393            0.594872   \n",
       "79         0.608696     0.417910        0.920398            0.578947   \n",
       "80         0.683168     0.514925        0.927363            0.609626   \n",
       "81         0.673684     0.477612        0.924378            0.600000   \n",
       "82         0.650000     0.485075        0.927363            0.617801   \n",
       "83         0.625000     0.485075        0.928358            0.617021   \n",
       "84         0.670330     0.455224        0.922388            0.585106   \n",
       "85         0.670213     0.470149        0.936318            0.632184   \n",
       "86         0.677778     0.455224        0.920398            0.587629   \n",
       "87         0.717391     0.492537        0.923383            0.579235   \n",
       "88         0.652632     0.462687        0.925373            0.590164   \n",
       "89         0.662651     0.410448        0.925373            0.585635   \n",
       "90         0.710843     0.440298        0.931343            0.614525   \n",
       "91         0.635593     0.559702        0.919403            0.588832   \n",
       "92         0.643678     0.417910        0.920398            0.555556   \n",
       "93         0.682927     0.417910        0.923383            0.583784   \n",
       "94         0.637363     0.432836        0.926368            0.593407   \n",
       "95         0.701923     0.544776        0.917413            0.574359   \n",
       "96         0.597122     0.619403        0.897512            0.546256   \n",
       "97         0.640777     0.492537        0.921393            0.590674   \n",
       "98         0.614035     0.522388        0.915423            0.581281   \n",
       "99         0.614583     0.440298        0.926368            0.579545   \n",
       "100        0.676768     0.500000        0.922388            0.585106   \n",
       "101        0.660714     0.552239        0.917413            0.599034   \n",
       "102        0.652174     0.447761        0.928358            0.600000   \n",
       "103        0.670103     0.485075        0.924378            0.595745   \n",
       "104        0.638554     0.395522        0.931343            0.596491   \n",
       "105        0.656250     0.470149        0.923383            0.579235   \n",
       "..              ...          ...             ...                 ...   \n",
       "306        0.657658     0.544776        0.923383            0.592593   \n",
       "307        0.595238     0.559702        0.901493            0.543779   \n",
       "308        0.666667     0.507463        0.920398            0.583333   \n",
       "309        0.628571     0.492537        0.923383            0.579235   \n",
       "310        0.670330     0.455224        0.928358            0.612903   \n",
       "311        0.646465     0.477612        0.917413            0.569948   \n",
       "312        0.689655     0.447761        0.928358            0.586207   \n",
       "313        0.596639     0.529851        0.912438            0.555556   \n",
       "314        0.623853     0.507463        0.916418            0.575758   \n",
       "315        0.626263     0.462687        0.924378            0.586957   \n",
       "316        0.523810     0.574627        0.890547            0.549180   \n",
       "317        0.628866     0.455224        0.917413            0.556150   \n",
       "318        0.673469     0.492537        0.922388            0.580645   \n",
       "319        0.633027     0.514925        0.922388            0.589474   \n",
       "320        0.602041     0.440298        0.921393            0.586387   \n",
       "321        0.606299     0.574627        0.906468            0.572727   \n",
       "322        0.632653     0.462687        0.922388            0.561798   \n",
       "323        0.693878     0.507463        0.922388            0.589474   \n",
       "324        0.632075     0.500000        0.923383            0.592593   \n",
       "325        0.695652     0.477612        0.917413            0.546448   \n",
       "326        0.660550     0.537313        0.915423            0.554974   \n",
       "327        0.610000     0.455224        0.923383            0.583784   \n",
       "328        0.652174     0.559702        0.914428            0.574257   \n",
       "329        0.612903     0.425373        0.922388            0.580645   \n",
       "330        0.631068     0.485075        0.924378            0.604167   \n",
       "331        0.619835     0.559702        0.914428            0.590476   \n",
       "332        0.646465     0.477612        0.916418            0.584158   \n",
       "333        0.632075     0.500000        0.928358            0.600000   \n",
       "334        0.634146     0.582090        0.919403            0.608696   \n",
       "335        0.681818     0.559702        0.917413            0.574359   \n",
       "\n",
       "     valid Kappa Linear  valid Loss  valid Matthews Correff  valid Precision  \\\n",
       "76                  NaN    0.336440                     NaN         0.542553   \n",
       "77                  NaN    0.358982                     NaN         0.572816   \n",
       "78                  NaN    0.351481                     NaN         0.527273   \n",
       "79                  NaN    0.289560                     NaN         0.523810   \n",
       "80                  NaN    0.393536                     NaN         0.558824   \n",
       "81                  NaN    0.322416                     NaN         0.542857   \n",
       "82                  NaN    0.381014                     NaN         0.556604   \n",
       "83                  NaN    0.314275                     NaN         0.563107   \n",
       "84                  NaN    0.375518                     NaN         0.533981   \n",
       "85                  NaN    0.259310                     NaN         0.617977   \n",
       "86                  NaN    0.364343                     NaN         0.522936   \n",
       "87                  NaN    0.327854                     NaN         0.540816   \n",
       "88                  NaN    0.334556                     NaN         0.551020   \n",
       "89                  NaN    0.353671                     NaN         0.552083   \n",
       "90                  NaN    0.305361                     NaN         0.585106   \n",
       "91                  NaN    0.394445                     NaN         0.517857   \n",
       "92                  NaN    0.354573                     NaN         0.526316   \n",
       "93                  NaN    0.324631                     NaN         0.540000   \n",
       "94                  NaN    0.347545                     NaN         0.556701   \n",
       "95                  NaN    0.354521                     NaN         0.509091   \n",
       "96                  NaN    0.474846                     NaN         0.436620   \n",
       "97                  NaN    0.382168                     NaN         0.527778   \n",
       "98                  NaN    0.360472                     NaN         0.500000   \n",
       "99                  NaN    0.261940                     NaN         0.560440   \n",
       "100                 NaN    0.344719                     NaN         0.533981   \n",
       "101                 NaN    0.362585                     NaN         0.508197   \n",
       "102                 NaN    0.293562                     NaN         0.568421   \n",
       "103                 NaN    0.321803                     NaN         0.543689   \n",
       "104                 NaN    0.286096                     NaN         0.593023   \n",
       "105                 NaN    0.317424                     NaN         0.540816   \n",
       "..                  ...         ...                     ...              ...   \n",
       "306                 NaN    0.369372                     NaN         0.538462   \n",
       "307                 NaN    0.341758                     NaN         0.446970   \n",
       "308                 NaN    0.343866                     NaN         0.523364   \n",
       "309                 NaN    0.376918                     NaN         0.540816   \n",
       "310                 NaN    0.245958                     NaN         0.564356   \n",
       "311                 NaN    0.366041                     NaN         0.509259   \n",
       "312                 NaN    0.292909                     NaN         0.573034   \n",
       "313                 NaN    0.371474                     NaN         0.486726   \n",
       "314                 NaN    0.314330                     NaN         0.504425   \n",
       "315                 NaN    0.342852                     NaN         0.545455   \n",
       "316                 NaN    0.359008                     NaN         0.421384   \n",
       "317                 NaN    0.327826                     NaN         0.509804   \n",
       "318                 NaN    0.303262                     NaN         0.534653   \n",
       "319                 NaN    0.334571                     NaN         0.533333   \n",
       "320                 NaN    0.341839                     NaN         0.528302   \n",
       "321                 NaN    0.314057                     NaN         0.466667   \n",
       "322                 NaN    0.337562                     NaN         0.537634   \n",
       "323                 NaN    0.342792                     NaN         0.533333   \n",
       "324                 NaN    0.303226                     NaN         0.538462   \n",
       "325                 NaN    0.347164                     NaN         0.510204   \n",
       "326                 NaN    0.313667                     NaN         0.500000   \n",
       "327                 NaN    0.378845                     NaN         0.540000   \n",
       "328                 NaN    0.392229                     NaN         0.495726   \n",
       "329                 NaN    0.355745                     NaN         0.534653   \n",
       "330                 NaN    0.329670                     NaN         0.542056   \n",
       "331                 NaN    0.358677                     NaN         0.496000   \n",
       "332                 NaN    0.332558                     NaN         0.504274   \n",
       "333                 NaN    0.338581                     NaN         0.568421   \n",
       "334                 NaN    0.237768                     NaN         0.516393   \n",
       "335                 NaN    0.372592                     NaN         0.509091   \n",
       "\n",
       "     valid Recall           arch      ds  \n",
       "76       0.600000  lstm_ft20_cl8  reddit  \n",
       "77       0.694118  lstm_ft20_cl8  reddit  \n",
       "78       0.682353  lstm_ft20_cl8  reddit  \n",
       "79       0.647059  lstm_ft20_cl8  reddit  \n",
       "80       0.670588  lstm_ft20_cl8  reddit  \n",
       "81       0.670588  lstm_ft20_cl8  reddit  \n",
       "82       0.694118  lstm_ft20_cl8  reddit  \n",
       "83       0.682353  lstm_ft20_cl8  reddit  \n",
       "84       0.647059  lstm_ft20_cl8  reddit  \n",
       "85       0.647059  lstm_ft20_cl8  reddit  \n",
       "86       0.670588  lstm_ft20_cl8  reddit  \n",
       "87       0.623529  lstm_ft20_cl8  reddit  \n",
       "88       0.635294  lstm_ft20_cl8  reddit  \n",
       "89       0.623529  lstm_ft20_cl8  reddit  \n",
       "90       0.647059  lstm_ft20_cl8  reddit  \n",
       "91       0.682353  lstm_ft20_cl8  reddit  \n",
       "92       0.588235  lstm_ft20_cl8  reddit  \n",
       "93       0.635294  lstm_ft20_cl8  reddit  \n",
       "94       0.635294  lstm_ft20_cl8  reddit  \n",
       "95       0.658824  lstm_ft20_cl8  reddit  \n",
       "96       0.729412  lstm_ft20_cl8  reddit  \n",
       "97       0.670588  lstm_ft20_cl8  reddit  \n",
       "98       0.694118  lstm_ft20_cl8  reddit  \n",
       "99       0.600000  lstm_ft20_cl8  reddit  \n",
       "100      0.647059  lstm_ft20_cl8  reddit  \n",
       "101      0.729412  lstm_ft20_cl8  reddit  \n",
       "102      0.635294  lstm_ft20_cl8  reddit  \n",
       "103      0.658824  lstm_ft20_cl8  reddit  \n",
       "104      0.600000  lstm_ft20_cl8  reddit  \n",
       "105      0.623529  lstm_ft20_cl8  reddit  \n",
       "..            ...            ...     ...  \n",
       "306      0.658824   lstm_ft6_cl8  reddit  \n",
       "307      0.694118   lstm_ft6_cl8  reddit  \n",
       "308      0.658824   lstm_ft6_cl8  reddit  \n",
       "309      0.623529   lstm_ft6_cl8  reddit  \n",
       "310      0.670588   lstm_ft6_cl8  reddit  \n",
       "311      0.647059   lstm_ft6_cl8  reddit  \n",
       "312      0.600000   lstm_ft6_cl8  reddit  \n",
       "313      0.647059   lstm_ft6_cl8  reddit  \n",
       "314      0.670588   lstm_ft6_cl8  reddit  \n",
       "315      0.635294   lstm_ft6_cl8  reddit  \n",
       "316      0.788235   lstm_ft6_cl8  reddit  \n",
       "317      0.611765   lstm_ft6_cl8  reddit  \n",
       "318      0.635294   lstm_ft6_cl8  reddit  \n",
       "319      0.658824   lstm_ft6_cl8  reddit  \n",
       "320      0.658824   lstm_ft6_cl8  reddit  \n",
       "321      0.741176   lstm_ft6_cl8  reddit  \n",
       "322      0.588235   lstm_ft6_cl8  reddit  \n",
       "323      0.658824   lstm_ft6_cl8  reddit  \n",
       "324      0.658824   lstm_ft6_cl8  reddit  \n",
       "325      0.588235   lstm_ft6_cl8  reddit  \n",
       "326      0.623529   lstm_ft6_cl8  reddit  \n",
       "327      0.635294   lstm_ft6_cl8  reddit  \n",
       "328      0.682353   lstm_ft6_cl8  reddit  \n",
       "329      0.635294   lstm_ft6_cl8  reddit  \n",
       "330      0.682353   lstm_ft6_cl8  reddit  \n",
       "331      0.729412   lstm_ft6_cl8  reddit  \n",
       "332      0.694118   lstm_ft6_cl8  reddit  \n",
       "333      0.635294   lstm_ft6_cl8  reddit  \n",
       "334      0.741176   lstm_ft6_cl8  reddit  \n",
       "335      0.658824   lstm_ft6_cl8  reddit  \n",
       "\n",
       "[184 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki test F1</th>\n",
       "      <th>reddit test F1</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.514146</td>\n",
       "      <td>0.557343</td>\n",
       "      <td>0.043197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.052149</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>-0.022808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.479638</td>\n",
       "      <td>0.138729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.495575</td>\n",
       "      <td>0.538375</td>\n",
       "      <td>0.042800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.522800</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.037200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.579652</td>\n",
       "      <td>0.029652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.013831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wiki test F1  reddit test F1       diff\n",
       "count    210.000000      184.000000 -26.000000\n",
       "mean       0.514146        0.557343   0.043197\n",
       "std        0.052149        0.029341  -0.022808\n",
       "min        0.340909        0.479638   0.138729\n",
       "25%        0.495575        0.538375   0.042800\n",
       "50%        0.522800        0.560000   0.037200\n",
       "75%        0.550000        0.579652   0.029652\n",
       "max        0.608392        0.622222   0.013831"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikivsreddit = pd.DataFrame({\"wiki test F1\":wiki.describe()[\"test F1 score bin\"], \n",
    "              \"reddit test F1\": reddit.describe()[\"test F1 score bin\"]})\n",
    "wikivsreddit[\"diff\"] = wikivsreddit[\"reddit test F1\"] - wikivsreddit[\"wiki test F1\"]\n",
    "wikivsreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.888961</td>\n",
       "      <td>0.528825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.524034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.615529</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.921406</td>\n",
       "      <td>0.585514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.351811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534038</td>\n",
       "      <td>0.654489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005927</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036916</td>\n",
       "      <td>0.052513</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.025376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045318</td>\n",
       "      <td>0.048253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.337015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.365672</td>\n",
       "      <td>0.892537</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.247777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.419580</td>\n",
       "      <td>0.541176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.509484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594943</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>0.568252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504505</td>\n",
       "      <td>0.620588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.526988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.541785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614966</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.921393</td>\n",
       "      <td>0.583935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.346929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528846</td>\n",
       "      <td>0.652941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.892250</td>\n",
       "      <td>0.548926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638811</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>0.604476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.388405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569490</td>\n",
       "      <td>0.682353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.938308</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.453879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.776471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear  test Loss  \\\n",
       "count      76.000000          76.000000                0.0  76.000000   \n",
       "mean        0.888961           0.528825                NaN   0.524034   \n",
       "std         0.005927           0.031651                NaN   0.063405   \n",
       "min         0.874000           0.457944                NaN   0.337015   \n",
       "25%         0.885000           0.509484                NaN   0.492292   \n",
       "50%         0.890000           0.526988                NaN   0.541785   \n",
       "75%         0.892250           0.548926                NaN   0.562234   \n",
       "max         0.902000           0.602151                NaN   0.641866   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count                    0.0       76.000000    76.000000       76.000000   \n",
       "mean                     NaN        0.615529     0.467400        0.921406   \n",
       "std                      NaN        0.036916     0.052513        0.009106   \n",
       "min                      NaN        0.530303     0.365672        0.892537   \n",
       "25%                      NaN        0.594943     0.432836        0.916418   \n",
       "50%                      NaN        0.614966     0.462687        0.921393   \n",
       "75%                      NaN        0.638811     0.500000        0.928358   \n",
       "max                      NaN        0.725000     0.626866        0.938308   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count           76.000000                 0.0   76.000000   \n",
       "mean             0.585514                 NaN    0.351811   \n",
       "std              0.025376                 NaN    0.048383   \n",
       "min              0.526316                 NaN    0.247777   \n",
       "25%              0.568252                 NaN    0.316945   \n",
       "50%              0.583935                 NaN    0.346929   \n",
       "75%              0.604476                 NaN    0.388405   \n",
       "max              0.643564                 NaN    0.453879   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count                     0.0        76.000000     76.000000  \n",
       "mean                      NaN         0.534038      0.654489  \n",
       "std                       NaN         0.045318      0.048253  \n",
       "min                       NaN         0.419580      0.541176  \n",
       "25%                       NaN         0.504505      0.620588  \n",
       "50%                       NaN         0.528846      0.652941  \n",
       "75%                       NaN         0.569490      0.682353  \n",
       "max                       NaN         0.632184      0.776471  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"model_name\"].str.startswith(\"lstm_dp\") & df[\"model_dir_parent\"].str.contains(\"reddit\")].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select submission\n",
    "\n",
    "- `X` Select Using F1\n",
    "- `X` Select Using Accuracy\n",
    "   - [ ] Retrain the best 10 models, using \"accuracy early stopping\"\n",
    "- [x] Use half test for validation \n",
    "   - `V` select using F1\n",
    "   - `V` select using Accuracy\n",
    "- [x] Deduplicate validation\n",
    "   - `X` Select using F1\n",
    "   - [ ] Select using Accuracy\n",
    "   \n",
    "## Raw - Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Recall</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>arch</th>\n",
       "      <th>ds</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.617801</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.556604</td>\n",
       "      <td>0.617801</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.567686</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.549550</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.693182</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.621053</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.425373</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.561905</td>\n",
       "      <td>0.621053</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.531532</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.440298</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.561702</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.561702</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.470149</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.670213</td>\n",
       "      <td>0.617977</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.592233</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test F1 score bin  valid F1 score bin  test Accuracy  test Recall  \\\n",
       "82            0.555556            0.617801          0.896     0.485075   \n",
       "257           0.567686            0.618557          0.901     0.485075   \n",
       "107           0.537037            0.619883          0.900     0.432836   \n",
       "113           0.549550            0.620690          0.900     0.455224   \n",
       "297           0.513514            0.621053          0.892     0.425373   \n",
       "228           0.531532            0.625698          0.896     0.440298   \n",
       "77            0.561702            0.627660          0.897     0.492537   \n",
       "227           0.561702            0.631579          0.897     0.492537   \n",
       "85            0.552632            0.632184          0.898     0.470149   \n",
       "230           0.565217            0.648936          0.900     0.485075   \n",
       "\n",
       "     valid Recall  test Precision  valid Precision  valid F1 score bin  \\\n",
       "82       0.694118        0.650000         0.556604            0.617801   \n",
       "257      0.705882        0.684211         0.550459            0.618557   \n",
       "107      0.623529        0.707317         0.616279            0.619883   \n",
       "113      0.635294        0.693182         0.606742            0.620690   \n",
       "297      0.694118        0.647727         0.561905            0.621053   \n",
       "228      0.658824        0.670455         0.595745            0.625698   \n",
       "77       0.694118        0.653465         0.572816            0.627660   \n",
       "227      0.705882        0.653465         0.571429            0.631579   \n",
       "85       0.647059        0.670213         0.617977            0.632184   \n",
       "230      0.717647        0.677083         0.592233            0.648936   \n",
       "\n",
       "              arch      ds                                         model_name  \n",
       "82   lstm_ft20_cl8  reddit  lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...  \n",
       "257   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-9...  \n",
       "107  lstm_ft20_cl8  reddit  lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...  \n",
       "113  lstm_ft20_cl8  reddit  lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...  \n",
       "297   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-4...  \n",
       "228   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-5...  \n",
       "77   lstm_ft20_cl8  reddit  lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...  \n",
       "227   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-4...  \n",
       "85   lstm_ft20_cl8  reddit  lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...  \n",
       "230   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-5...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order=\"valid F1 score bin\"\n",
    "focus=[\"test F1 score bin\", \"valid F1 score bin\", \n",
    "       \"test Accuracy\", \"test Recall\", \"valid Recall\",\n",
    "       \"test Precision\", \"valid Precision\", order, \"arch\", \"ds\", \"model_name\"]\n",
    "reddit.sort_values([order])[focus].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Recall</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>arch</th>\n",
       "      <th>ds</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.602511</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.602511</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.605042</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.522936</td>\n",
       "      <td>0.605042</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.605578</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.567164</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.649573</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.605578</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0.607004</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.516393</td>\n",
       "      <td>0.607004</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.608059</td>\n",
       "      <td>0.546256</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.597122</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.608059</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.613445</td>\n",
       "      <td>0.574359</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.613445</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.572973</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.614232</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.616541</td>\n",
       "      <td>0.458065</td>\n",
       "      <td>0.614232</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.574359</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.480620</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test F1 score bin  valid F1 score bin  test Accuracy  test Recall  \\\n",
       "190           0.602511            0.571429          0.905     0.537313   \n",
       "236           0.605042            0.587629          0.906     0.537313   \n",
       "273           0.605578            0.594059          0.901     0.567164   \n",
       "334           0.607004            0.608696          0.899     0.582090   \n",
       "96            0.608059            0.546256          0.893     0.619403   \n",
       "95            0.613445            0.574359          0.908     0.544776   \n",
       "290           0.614035            0.572973          0.912     0.522388   \n",
       "213           0.614232            0.591667          0.897     0.611940   \n",
       "335           0.614754            0.574359          0.906     0.559702   \n",
       "275           0.622222            0.579439          0.898     0.626866   \n",
       "\n",
       "     valid Recall  test Precision  valid Precision  test F1 score bin  \\\n",
       "190      0.682353        0.685714         0.491525           0.602511   \n",
       "236      0.670588        0.692308         0.522936           0.605042   \n",
       "273      0.705882        0.649573         0.512821           0.605578   \n",
       "334      0.741176        0.634146         0.516393           0.607004   \n",
       "96       0.729412        0.597122         0.436620           0.608059   \n",
       "95       0.658824        0.701923         0.509091           0.613445   \n",
       "290      0.623529        0.744681         0.530000           0.614035   \n",
       "213      0.835294        0.616541         0.458065           0.614232   \n",
       "335      0.658824        0.681818         0.509091           0.614754   \n",
       "275      0.729412        0.617647         0.480620           0.622222   \n",
       "\n",
       "              arch      ds                                         model_name  \n",
       "190   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-0...  \n",
       "236   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-6...  \n",
       "273   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-1...  \n",
       "334   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...  \n",
       "96   lstm_ft20_cl8  reddit  lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...  \n",
       "95   lstm_ft20_cl8  reddit  lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...  \n",
       "290   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-3...  \n",
       "213   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-2...  \n",
       "335   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...  \n",
       "275   lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-1...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order=\"test F1 score bin\"\n",
    "focus=[\"test F1 score bin\", \"valid F1 score bin\", \n",
    "       \"test Accuracy\", \"test Recall\", \"valid Recall\",\n",
    "       \"test Precision\", \"valid Precision\", order, \"arch\", \"ds\", \"model_name\"]\n",
    "reddit.sort_values([order])[focus].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Recall</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "      <th>arch</th>\n",
       "      <th>ds</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0.607004</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.516393</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.565022</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.588710</td>\n",
       "      <td>0.611650</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.640351</td>\n",
       "      <td>0.520661</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.596899</td>\n",
       "      <td>0.580357</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.620968</td>\n",
       "      <td>0.467626</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.510460</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.548043</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.421384</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.572650</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.449664</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.617512</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.585185</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.589552</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.580882</td>\n",
       "      <td>0.463576</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.614232</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.616541</td>\n",
       "      <td>0.458065</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test F1 score bin  valid F1 score bin  test Accuracy  test Recall  \\\n",
       "334           0.607004            0.608696          0.899     0.582090   \n",
       "288           0.538462            0.565022          0.880     0.522388   \n",
       "225           0.588710            0.611650          0.898     0.544776   \n",
       "261           0.596899            0.580357          0.896     0.574627   \n",
       "218           0.510460            0.602740          0.883     0.455224   \n",
       "316           0.548043            0.549180          0.873     0.574627   \n",
       "238           0.553030            0.572650          0.882     0.544776   \n",
       "259           0.592308            0.617512          0.894     0.574627   \n",
       "204           0.585185            0.593220          0.888     0.589552   \n",
       "213           0.614232            0.591667          0.897     0.611940   \n",
       "\n",
       "     valid Recall  test Precision  valid Precision  valid Recall  \\\n",
       "334      0.741176        0.634146         0.516393      0.741176   \n",
       "288      0.741176        0.555556         0.456522      0.741176   \n",
       "225      0.741176        0.640351         0.520661      0.741176   \n",
       "261      0.764706        0.620968         0.467626      0.764706   \n",
       "218      0.776471        0.580952         0.492537      0.776471   \n",
       "316      0.788235        0.523810         0.421384      0.788235   \n",
       "238      0.788235        0.561538         0.449664      0.788235   \n",
       "259      0.788235        0.611111         0.507576      0.788235   \n",
       "204      0.823529        0.580882         0.463576      0.823529   \n",
       "213      0.835294        0.616541         0.458065      0.835294   \n",
       "\n",
       "             arch      ds                                         model_name  \n",
       "334  lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...  \n",
       "288  lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-3...  \n",
       "225  lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-4...  \n",
       "261  lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-0...  \n",
       "218  lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-3...  \n",
       "316  lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...  \n",
       "238  lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-6...  \n",
       "259  lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-9...  \n",
       "204  lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-1...  \n",
       "213  lstm_ft6_cl8  reddit  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-2...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order=\"valid Recall\"\n",
    "focus=[\"test F1 score bin\", \"valid F1 score bin\", \n",
    "       \"test Accuracy\", \"test Recall\", \"valid Recall\",\n",
    "       \"test Precision\", \"valid Precision\", order, \"arch\", \"ds\", \"model_name\"]\n",
    "reddit.sort_values([order])[focus].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kappa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>arch</th>\n",
       "      <th>ds</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.534799</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.890547</td>\n",
       "      <td>0.451338</td>\n",
       "      <td>0.468657</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.510288</td>\n",
       "      <td>0.881592</td>\n",
       "      <td>0.449771</td>\n",
       "      <td>0.477813</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.581315</td>\n",
       "      <td>0.510288</td>\n",
       "      <td>0.881592</td>\n",
       "      <td>0.449771</td>\n",
       "      <td>0.477813</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.566802</td>\n",
       "      <td>0.511013</td>\n",
       "      <td>0.889552</td>\n",
       "      <td>0.453148</td>\n",
       "      <td>0.472147</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.511013</td>\n",
       "      <td>0.889552</td>\n",
       "      <td>0.453148</td>\n",
       "      <td>0.472147</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.545994</td>\n",
       "      <td>0.513011</td>\n",
       "      <td>0.869652</td>\n",
       "      <td>0.449292</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>qrnn_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>qrnn_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.545994</td>\n",
       "      <td>0.513011</td>\n",
       "      <td>0.869652</td>\n",
       "      <td>0.449292</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>qrnn_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>qrnn_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.554795</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.881592</td>\n",
       "      <td>0.453966</td>\n",
       "      <td>0.483499</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.516364</td>\n",
       "      <td>0.867662</td>\n",
       "      <td>0.452361</td>\n",
       "      <td>0.501671</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.516364</td>\n",
       "      <td>0.867662</td>\n",
       "      <td>0.452361</td>\n",
       "      <td>0.501671</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test F1 score bin  valid F1 score bin  valid Accuracy  \\\n",
       "263           0.534799            0.508929        0.890547   \n",
       "256           0.570423            0.510288        0.881592   \n",
       "218           0.581315            0.510288        0.881592   \n",
       "264           0.566802            0.511013        0.889552   \n",
       "226           0.560606            0.511013        0.889552   \n",
       "101           0.545994            0.513011        0.869652   \n",
       "82            0.545994            0.513011        0.869652   \n",
       "251           0.554795            0.514286        0.881592   \n",
       "60            0.549383            0.516364        0.867662   \n",
       "41            0.549383            0.516364        0.867662   \n",
       "\n",
       "     valid Kappa Linear  valid Matthews Correff                       arch  \\\n",
       "263            0.451338                0.468657  lstm_noearly_stop_ft6_cl8   \n",
       "256            0.449771                0.477813  lstm_noearly_stop_ft6_cl8   \n",
       "218            0.449771                0.477813               lstm_ft6_cl8   \n",
       "264            0.453148                0.472147  lstm_noearly_stop_ft6_cl8   \n",
       "226            0.453148                0.472147               lstm_ft6_cl8   \n",
       "101            0.449292                0.494118               qrnn_ft6_cl8   \n",
       "82             0.449292                0.494118               qrnn_ft6_cl8   \n",
       "251            0.453966                0.483499  lstm_noearly_stop_ft6_cl8   \n",
       "60             0.452361                0.501671              qrnn_ft20_cl8   \n",
       "41             0.452361                0.501671              qrnn_ft20_cl8   \n",
       "\n",
       "         ds                                         model_name  \n",
       "263    wiki  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "256    wiki  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "218    wiki  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-0...  \n",
       "264    wiki  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "226    wiki  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...  \n",
       "101  reddit  qrnn_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-0...  \n",
       "82   reddit  qrnn_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-0...  \n",
       "251    wiki  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "60   reddit  qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...  \n",
       "41   reddit  qrnn_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order=\"valid Kappa Linear\"\n",
    "focus=[\"test F1 score bin\", \"valid F1 score bin\", \"valid Accuracy\", order, \n",
    "       \"valid Matthews Correff\", \"arch\", \"ds\", \"model_name\"]\n",
    "q=df[~df[order].isnull() & ~df[\"arch\"].str.contains(\"ft0\")]\n",
    "#q=nedf\n",
    "q.sort_values([order])[focus].head(int(len(q) * 0.1)).sort_values([\"valid F1 score bin\"]).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>arch</th>\n",
       "      <th>ds</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.544681</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.553796</td>\n",
       "      <td>0.556015</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.544681</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.553796</td>\n",
       "      <td>0.556015</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.491071</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>0.556291</td>\n",
       "      <td>0.556969</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.527132</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>0.554454</td>\n",
       "      <td>0.557567</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.532787</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>0.558752</td>\n",
       "      <td>0.562558</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.539419</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>0.558752</td>\n",
       "      <td>0.562558</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.930348</td>\n",
       "      <td>0.564153</td>\n",
       "      <td>0.564547</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.930348</td>\n",
       "      <td>0.564153</td>\n",
       "      <td>0.564547</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.504274</td>\n",
       "      <td>0.605128</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.563475</td>\n",
       "      <td>0.569221</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.515284</td>\n",
       "      <td>0.639053</td>\n",
       "      <td>0.939303</td>\n",
       "      <td>0.605920</td>\n",
       "      <td>0.605933</td>\n",
       "      <td>lstm_ft20_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test F1 score bin  valid F1 score bin  valid Accuracy  \\\n",
       "191           0.544681            0.594595        0.925373   \n",
       "229           0.544681            0.594595        0.925373   \n",
       "152           0.491071            0.595506        0.928358   \n",
       "206           0.527132            0.595745        0.924378   \n",
       "195           0.532787            0.600000        0.924378   \n",
       "233           0.539419            0.600000        0.924378   \n",
       "202           0.534483            0.602273        0.930348   \n",
       "240           0.530973            0.602273        0.930348   \n",
       "158           0.504274            0.605128        0.923383   \n",
       "164           0.515284            0.639053        0.939303   \n",
       "\n",
       "     valid Kappa Linear  valid Matthews Correff                       arch  \\\n",
       "191            0.553796                0.556015               lstm_ft6_cl8   \n",
       "229            0.553796                0.556015  lstm_noearly_stop_ft6_cl8   \n",
       "152            0.556291                0.556969              lstm_ft20_cl8   \n",
       "206            0.554454                0.557567               lstm_ft6_cl8   \n",
       "195            0.558752                0.562558               lstm_ft6_cl8   \n",
       "233            0.558752                0.562558  lstm_noearly_stop_ft6_cl8   \n",
       "202            0.564153                0.564547               lstm_ft6_cl8   \n",
       "240            0.564153                0.564547  lstm_noearly_stop_ft6_cl8   \n",
       "158            0.563475                0.569221              lstm_ft20_cl8   \n",
       "164            0.605920                0.605933              lstm_ft20_cl8   \n",
       "\n",
       "       ds                                         model_name  \n",
       "191  wiki  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-0...  \n",
       "229  wiki  lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...  \n",
       "152  wiki  lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...  \n",
       "206  wiki  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-7...  \n",
       "195  wiki  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-0...  \n",
       "233  wiki  lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...  \n",
       "202  wiki  lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-3...  \n",
       "240  wiki  lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...  \n",
       "158  wiki  lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...  \n",
       "164  wiki  lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.sort_values([\"valid F1 score bin\"])[focus].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>248.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>248.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.879641</td>\n",
       "      <td>0.530643</td>\n",
       "      <td>0.386346</td>\n",
       "      <td>0.457431</td>\n",
       "      <td>0.413414</td>\n",
       "      <td>0.570750</td>\n",
       "      <td>0.521004</td>\n",
       "      <td>0.903499</td>\n",
       "      <td>0.546103</td>\n",
       "      <td>0.495688</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.512618</td>\n",
       "      <td>0.473181</td>\n",
       "      <td>0.679602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.055190</td>\n",
       "      <td>0.052320</td>\n",
       "      <td>0.063028</td>\n",
       "      <td>0.039129</td>\n",
       "      <td>0.059511</td>\n",
       "      <td>0.118153</td>\n",
       "      <td>0.020746</td>\n",
       "      <td>0.027297</td>\n",
       "      <td>0.034083</td>\n",
       "      <td>0.057716</td>\n",
       "      <td>0.026121</td>\n",
       "      <td>0.075373</td>\n",
       "      <td>0.099951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.294158</td>\n",
       "      <td>0.306861</td>\n",
       "      <td>0.330020</td>\n",
       "      <td>0.369281</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.790050</td>\n",
       "      <td>0.418733</td>\n",
       "      <td>0.332226</td>\n",
       "      <td>0.218546</td>\n",
       "      <td>0.419594</td>\n",
       "      <td>0.273381</td>\n",
       "      <td>0.447059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.502193</td>\n",
       "      <td>0.341244</td>\n",
       "      <td>0.418202</td>\n",
       "      <td>0.392833</td>\n",
       "      <td>0.529791</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.889303</td>\n",
       "      <td>0.527197</td>\n",
       "      <td>0.472108</td>\n",
       "      <td>0.338949</td>\n",
       "      <td>0.495752</td>\n",
       "      <td>0.413740</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.544039</td>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.447006</td>\n",
       "      <td>0.412878</td>\n",
       "      <td>0.559381</td>\n",
       "      <td>0.526119</td>\n",
       "      <td>0.906468</td>\n",
       "      <td>0.546516</td>\n",
       "      <td>0.497312</td>\n",
       "      <td>0.366850</td>\n",
       "      <td>0.512162</td>\n",
       "      <td>0.463526</td>\n",
       "      <td>0.694118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.429274</td>\n",
       "      <td>0.485430</td>\n",
       "      <td>0.442910</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>0.563876</td>\n",
       "      <td>0.518347</td>\n",
       "      <td>0.396206</td>\n",
       "      <td>0.529294</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.487822</td>\n",
       "      <td>0.743211</td>\n",
       "      <td>0.507263</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.843284</td>\n",
       "      <td>0.942289</td>\n",
       "      <td>0.639053</td>\n",
       "      <td>0.605920</td>\n",
       "      <td>0.708696</td>\n",
       "      <td>0.605933</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.894118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear   test Loss  \\\n",
       "count     248.000000         248.000000          38.000000  248.000000   \n",
       "mean        0.879641           0.530643           0.386346    0.457431   \n",
       "std         0.011587           0.055190           0.052320    0.063028   \n",
       "min         0.786000           0.340909           0.294158    0.306861   \n",
       "25%         0.875000           0.502193           0.341244    0.418202   \n",
       "50%         0.881000           0.544039           0.391300    0.447006   \n",
       "75%         0.886000           0.570470           0.429274    0.485430   \n",
       "max         0.901000           0.608392           0.487822    0.743211   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count              38.000000      248.000000   248.000000      248.000000   \n",
       "mean                0.413414        0.570750     0.521004        0.903499   \n",
       "std                 0.039129        0.059511     0.118153        0.020746   \n",
       "min                 0.330020        0.369281     0.223881        0.790050   \n",
       "25%                 0.392833        0.529791     0.432836        0.889303   \n",
       "50%                 0.412878        0.559381     0.526119        0.906468   \n",
       "75%                 0.442910        0.607477     0.619403        0.920398   \n",
       "max                 0.507263        0.756098     0.843284        0.942289   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count          248.000000          248.000000  248.000000   \n",
       "mean             0.546103            0.495688    0.366369   \n",
       "std              0.027297            0.034083    0.057716   \n",
       "min              0.418733            0.332226    0.218546   \n",
       "25%              0.527197            0.472108    0.338949   \n",
       "50%              0.546516            0.497312    0.366850   \n",
       "75%              0.563876            0.518347    0.396206   \n",
       "max              0.639053            0.605920    0.708696   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count              248.000000       248.000000    248.000000  \n",
       "mean                 0.512618         0.473181      0.679602  \n",
       "std                  0.026121         0.075373      0.099951  \n",
       "min                  0.419594         0.273381      0.447059  \n",
       "25%                  0.495752         0.413740      0.600000  \n",
       "50%                  0.512162         0.463526      0.694118  \n",
       "75%                  0.529294         0.525253      0.764706  \n",
       "max                  0.605933         0.764706      0.894118  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.529631</td>\n",
       "      <td>0.524965</td>\n",
       "      <td>0.903483</td>\n",
       "      <td>0.485005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.046230</td>\n",
       "      <td>0.006772</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>0.006333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.460094</td>\n",
       "      <td>0.514523</td>\n",
       "      <td>0.882587</td>\n",
       "      <td>0.468980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.488976</td>\n",
       "      <td>0.520200</td>\n",
       "      <td>0.890547</td>\n",
       "      <td>0.481969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.538836</td>\n",
       "      <td>0.524252</td>\n",
       "      <td>0.906965</td>\n",
       "      <td>0.486925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.572976</td>\n",
       "      <td>0.531253</td>\n",
       "      <td>0.917662</td>\n",
       "      <td>0.491206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>0.491477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test F1 score bin  valid F1 score bin  valid Accuracy  \\\n",
       "count          20.000000           20.000000       20.000000   \n",
       "mean            0.529631            0.524965        0.903483   \n",
       "std             0.046230            0.006772        0.015004   \n",
       "min             0.460094            0.514523        0.882587   \n",
       "25%             0.488976            0.520200        0.890547   \n",
       "50%             0.538836            0.524252        0.906965   \n",
       "75%             0.572976            0.531253        0.917662   \n",
       "max             0.581818            0.534884        0.922388   \n",
       "\n",
       "       valid Matthews Correff  \n",
       "count               20.000000  \n",
       "mean                 0.485005  \n",
       "std                  0.006333  \n",
       "min                  0.468980  \n",
       "25%                  0.481969  \n",
       "50%                  0.486925  \n",
       "75%                  0.491206  \n",
       "max                  0.491477  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order=\"valid Matthews Correff\"\n",
    "focus=[\"test F1 score bin\", \"valid F1 score bin\", \"valid Accuracy\", order, \"arch\", \"ds\", \"model_name\"]\n",
    "q=df[~df[order].isnull() & ~df[\"arch\"].str.contains(\"ft0\")]\n",
    "#q=nedf\n",
    "q.sort_values([order])[focus].head(int(len(q) * 0.2)).sort_values([\"valid F1 score bin\"]).tail(20).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['redditdedup'], dtype=object),\n",
       " array(['lstm_ft6_cl20', 'lstm_ft6_cl6'], dtype=object))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = pd.read_csv(\"./all-results-dedup.csv\", index_col=0)\n",
    "ddf[\"ds\"] = ddf[\"model_dir_parent\"].str.extract(\".*pl-10-(.*)/models.*\")\n",
    "ddf[\"arch\"] = ddf[\"model_name\"].str.extract(\"(.*?)_lmseed.*\")\n",
    "ddf[\"ds\"].unique(), ddf[\"arch\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>arch</th>\n",
       "      <th>ds</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.555102</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.891</td>\n",
       "      <td>lstm_ft6_cl20</td>\n",
       "      <td>redditdedup</td>\n",
       "      <td>lstm_ft6_cl20_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.503311</td>\n",
       "      <td>0.884</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>redditdedup</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.533898</td>\n",
       "      <td>0.503497</td>\n",
       "      <td>0.890</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>redditdedup</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.503597</td>\n",
       "      <td>0.886</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>redditdedup</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.566802</td>\n",
       "      <td>0.509317</td>\n",
       "      <td>0.893</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>redditdedup</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-1-ftseed-0-clsweightseed-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.509317</td>\n",
       "      <td>0.897</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>redditdedup</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.510822</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.887</td>\n",
       "      <td>lstm_ft6_cl20</td>\n",
       "      <td>redditdedup</td>\n",
       "      <td>lstm_ft6_cl20_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.542056</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.902</td>\n",
       "      <td>lstm_ft6_cl20</td>\n",
       "      <td>redditdedup</td>\n",
       "      <td>lstm_ft6_cl20_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.542056</td>\n",
       "      <td>0.532374</td>\n",
       "      <td>0.902</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>redditdedup</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.525822</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.899</td>\n",
       "      <td>lstm_ft6_cl20</td>\n",
       "      <td>redditdedup</td>\n",
       "      <td>lstm_ft6_cl20_lmseed-0-ftseed-0-clsweightseed-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test F1 score bin  valid F1 score bin  test Accuracy           arch  \\\n",
       "24           0.555102            0.502994          0.891  lstm_ft6_cl20   \n",
       "49           0.516667            0.503311          0.884   lstm_ft6_cl6   \n",
       "41           0.533898            0.503497          0.890   lstm_ft6_cl6   \n",
       "58           0.540323            0.503597          0.886   lstm_ft6_cl6   \n",
       "68           0.566802            0.509317          0.893   lstm_ft6_cl6   \n",
       "39           0.596078            0.509317          0.897   lstm_ft6_cl6   \n",
       "15           0.510822            0.529412          0.887  lstm_ft6_cl20   \n",
       "31           0.542056            0.529915          0.902  lstm_ft6_cl20   \n",
       "50           0.542056            0.532374          0.902   lstm_ft6_cl6   \n",
       "2            0.525822            0.559441          0.899  lstm_ft6_cl20   \n",
       "\n",
       "             ds                                         model_name  \n",
       "24  redditdedup  lstm_ft6_cl20_lmseed-1-ftseed-0-clsweightseed-...  \n",
       "49  redditdedup  lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-2...  \n",
       "41  redditdedup  lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-0...  \n",
       "58  redditdedup  lstm_ft6_cl6_lmseed-1-ftseed-0-clsweightseed-0...  \n",
       "68  redditdedup  lstm_ft6_cl6_lmseed-1-ftseed-0-clsweightseed-2...  \n",
       "39  redditdedup  lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-0...  \n",
       "15  redditdedup  lstm_ft6_cl20_lmseed-0-ftseed-0-clsweightseed-...  \n",
       "31  redditdedup  lstm_ft6_cl20_lmseed-1-ftseed-0-clsweightseed-...  \n",
       "50  redditdedup  lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-3...  \n",
       "2   redditdedup  lstm_ft6_cl20_lmseed-0-ftseed-0-clsweightseed-...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focus=[\"test F1 score bin\", \"valid F1 score bin\", \"test Accuracy\", \"arch\", \"ds\", \"model_name\"]\n",
    "ddf.sort_values([\"valid F1 score bin\"])[focus].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Halftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['reddithalftest'], dtype=object),\n",
       " array(['lstm_ft6_cl6'], dtype=object))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf = pd.read_csv(\"./all-results-halftest.csv\", index_col=0)\n",
    "hdf[\"ds\"] = hdf[\"model_dir_parent\"].str.extract(\".*pl-10-(.*)/models.*\")\n",
    "hdf[\"arch\"] = hdf[\"model_name\"].str.extract(\"(.*?)_lmseed.*\")\n",
    "hdf[\"ds\"].unique(), hdf[\"arch\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>arch</th>\n",
       "      <th>ds</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>reddithalftest</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>reddithalftest</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>reddithalftest</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.549618</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>reddithalftest</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>reddithalftest</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.554745</td>\n",
       "      <td>0.607407</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.607407</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>reddithalftest</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.583942</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>reddithalftest</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.598425</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>reddithalftest</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>reddithalftest</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>lstm_ft6_cl6</td>\n",
       "      <td>reddithalftest</td>\n",
       "      <td>lstm_ft6_cl6_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test F1 score bin  valid F1 score bin  test Accuracy  valid F1 score bin  \\\n",
       "27           0.557377            0.604651          0.838            0.604651   \n",
       "7            0.569231            0.604651          0.888            0.604651   \n",
       "4            0.622222            0.604651          0.898            0.604651   \n",
       "23           0.549618            0.604651          0.882            0.604651   \n",
       "26           0.609375            0.606061          0.900            0.606061   \n",
       "9            0.554745            0.607407          0.878            0.607407   \n",
       "16           0.583942            0.611940          0.886            0.611940   \n",
       "12           0.598425            0.615385          0.898            0.615385   \n",
       "1            0.580645            0.626866          0.896            0.626866   \n",
       "37           0.627737            0.629371          0.898            0.629371   \n",
       "\n",
       "            arch              ds  \\\n",
       "27  lstm_ft6_cl6  reddithalftest   \n",
       "7   lstm_ft6_cl6  reddithalftest   \n",
       "4   lstm_ft6_cl6  reddithalftest   \n",
       "23  lstm_ft6_cl6  reddithalftest   \n",
       "26  lstm_ft6_cl6  reddithalftest   \n",
       "9   lstm_ft6_cl6  reddithalftest   \n",
       "16  lstm_ft6_cl6  reddithalftest   \n",
       "12  lstm_ft6_cl6  reddithalftest   \n",
       "1   lstm_ft6_cl6  reddithalftest   \n",
       "37  lstm_ft6_cl6  reddithalftest   \n",
       "\n",
       "                                           model_name  \n",
       "27  lstm_ft6_cl6_lmseed-1-ftseed-0-clsweightseed-0...  \n",
       "7   lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-0...  \n",
       "4   lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-0...  \n",
       "23  lstm_ft6_cl6_lmseed-1-ftseed-0-clsweightseed-0...  \n",
       "26  lstm_ft6_cl6_lmseed-1-ftseed-0-clsweightseed-0...  \n",
       "9   lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-0...  \n",
       "16  lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-7...  \n",
       "12  lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-3...  \n",
       "1   lstm_ft6_cl6_lmseed-0-ftseed-0-clsweightseed-0...  \n",
       "37  lstm_ft6_cl6_lmseed-1-ftseed-0-clsweightseed-9...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order=\"valid F1 score bin\"\n",
    "#order=\"valid Accuracy\"\n",
    "focus=[\"test F1 score bin\", \"valid F1 score bin\", \"test Accuracy\", order, \"arch\", \"ds\", \"model_name\"]\n",
    "hdf.sort_values([order])[focus].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['wiki'], dtype=object),\n",
       " array(['lstm_noearly_stop_ft6_cl8'], dtype=object))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nedf = pd.read_csv(\"./poleval-noearly.csv\", index_col=0)\n",
    "nedf[\"ds\"] = nedf[\"model_dir_parent\"].str.extract(\".*pl-10-(.*)/models.*\")\n",
    "nedf[\"arch\"] = nedf[\"model_name\"].str.extract(\"(.*?)_lmseed.*\")\n",
    "nedf[\"ds\"].unique(), nedf[\"arch\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Kappa quadratic</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.884026</td>\n",
       "      <td>0.540362</td>\n",
       "      <td>0.451621</td>\n",
       "      <td>0.582396</td>\n",
       "      <td>0.514336</td>\n",
       "      <td>0.903561</td>\n",
       "      <td>0.541631</td>\n",
       "      <td>0.490324</td>\n",
       "      <td>0.490324</td>\n",
       "      <td>0.490324</td>\n",
       "      <td>0.378578</td>\n",
       "      <td>0.504238</td>\n",
       "      <td>0.465598</td>\n",
       "      <td>0.666873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.006953</td>\n",
       "      <td>0.036469</td>\n",
       "      <td>0.036495</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.078603</td>\n",
       "      <td>0.017295</td>\n",
       "      <td>0.028827</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>0.035378</td>\n",
       "      <td>0.028528</td>\n",
       "      <td>0.063967</td>\n",
       "      <td>0.068605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.453704</td>\n",
       "      <td>0.383624</td>\n",
       "      <td>0.512658</td>\n",
       "      <td>0.365672</td>\n",
       "      <td>0.879602</td>\n",
       "      <td>0.497238</td>\n",
       "      <td>0.441865</td>\n",
       "      <td>0.441865</td>\n",
       "      <td>0.441865</td>\n",
       "      <td>0.310931</td>\n",
       "      <td>0.448687</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.878250</td>\n",
       "      <td>0.517938</td>\n",
       "      <td>0.418870</td>\n",
       "      <td>0.546561</td>\n",
       "      <td>0.436567</td>\n",
       "      <td>0.888060</td>\n",
       "      <td>0.515848</td>\n",
       "      <td>0.455593</td>\n",
       "      <td>0.455593</td>\n",
       "      <td>0.455593</td>\n",
       "      <td>0.348865</td>\n",
       "      <td>0.483228</td>\n",
       "      <td>0.408611</td>\n",
       "      <td>0.611765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.549590</td>\n",
       "      <td>0.449618</td>\n",
       "      <td>0.583582</td>\n",
       "      <td>0.526119</td>\n",
       "      <td>0.902985</td>\n",
       "      <td>0.536872</td>\n",
       "      <td>0.488905</td>\n",
       "      <td>0.488905</td>\n",
       "      <td>0.488905</td>\n",
       "      <td>0.371432</td>\n",
       "      <td>0.496245</td>\n",
       "      <td>0.452722</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.566180</td>\n",
       "      <td>0.478240</td>\n",
       "      <td>0.611950</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.921144</td>\n",
       "      <td>0.561875</td>\n",
       "      <td>0.518846</td>\n",
       "      <td>0.518846</td>\n",
       "      <td>0.518846</td>\n",
       "      <td>0.409666</td>\n",
       "      <td>0.521986</td>\n",
       "      <td>0.531640</td>\n",
       "      <td>0.717647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.517178</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>0.930348</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.564153</td>\n",
       "      <td>0.564153</td>\n",
       "      <td>0.564153</td>\n",
       "      <td>0.449702</td>\n",
       "      <td>0.564547</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.776471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Loss  test Precision  \\\n",
       "count      38.000000          38.000000  38.000000       38.000000   \n",
       "mean        0.884026           0.540362   0.451621        0.582396   \n",
       "std         0.006953           0.036469   0.036495        0.042296   \n",
       "min         0.870000           0.453704   0.383624        0.512658   \n",
       "25%         0.878250           0.517938   0.418870        0.546561   \n",
       "50%         0.885000           0.549590   0.449618        0.583582   \n",
       "75%         0.889000           0.566180   0.478240        0.611950   \n",
       "max         0.895000           0.608392   0.517178        0.662791   \n",
       "\n",
       "       test Recall  valid Accuracy  valid F1 score bin  valid Kappa  \\\n",
       "count    38.000000       38.000000           38.000000    36.000000   \n",
       "mean      0.514336        0.903561            0.541631     0.490324   \n",
       "std       0.078603        0.017295            0.028827     0.036302   \n",
       "min       0.365672        0.879602            0.497238     0.441865   \n",
       "25%       0.436567        0.888060            0.515848     0.455593   \n",
       "50%       0.526119        0.902985            0.536872     0.488905   \n",
       "75%       0.582090        0.921144            0.561875     0.518846   \n",
       "max       0.649254        0.930348            0.602273     0.564153   \n",
       "\n",
       "       valid Kappa Linear  valid Kappa quadratic  valid Loss  \\\n",
       "count           36.000000              36.000000   38.000000   \n",
       "mean             0.490324               0.490324    0.378578   \n",
       "std              0.036302               0.036302    0.035378   \n",
       "min              0.441865               0.441865    0.310931   \n",
       "25%              0.455593               0.455593    0.348865   \n",
       "50%              0.488905               0.488905    0.371432   \n",
       "75%              0.518846               0.518846    0.409666   \n",
       "max              0.564153               0.564153    0.449702   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count               36.000000        38.000000     38.000000  \n",
       "mean                 0.504238         0.465598      0.666873  \n",
       "std                  0.028528         0.063967      0.068605  \n",
       "min                  0.448687         0.392405      0.529412  \n",
       "25%                  0.483228         0.408611      0.611765  \n",
       "50%                  0.496245         0.452722      0.676471  \n",
       "75%                  0.521986         0.531640      0.717647  \n",
       "max                  0.564547         0.582418      0.776471  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nedf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>valid Kappa</th>\n",
       "      <th>arch</th>\n",
       "      <th>ds</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.515837</td>\n",
       "      <td>0.497238</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.447685</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.502128</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.441865</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.534799</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.451338</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.510288</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.449771</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.566802</td>\n",
       "      <td>0.511013</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.453148</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.583026</td>\n",
       "      <td>0.512820</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.454013</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.513274</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.455848</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.453966</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.554795</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.453966</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.514523</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.454830</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test F1 score bin  valid F1 score bin  test Accuracy  valid Kappa  \\\n",
       "9            0.515837            0.497238          0.893     0.447685   \n",
       "29           0.560000            0.502128          0.879     0.441865   \n",
       "35           0.534799            0.508929          0.873     0.451338   \n",
       "28           0.570423            0.510288          0.878     0.449771   \n",
       "36           0.566802            0.511013          0.893     0.453148   \n",
       "33           0.583026            0.512820          0.887     0.454013   \n",
       "32           0.573529            0.513274          0.884     0.455848   \n",
       "26           0.608392            0.514286          0.888     0.453966   \n",
       "23           0.554795            0.514286          0.870     0.453966   \n",
       "31           0.581818            0.514523          0.885     0.454830   \n",
       "\n",
       "                         arch    ds  \\\n",
       "9   lstm_noearly_stop_ft6_cl8  wiki   \n",
       "29  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "35  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "28  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "36  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "33  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "32  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "26  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "23  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "31  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "\n",
       "                                           model_name  \n",
       "9   lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...  \n",
       "29  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "35  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "28  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "36  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "33  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "32  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "26  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "23  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "31  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order=\"valid Kappa\"\n",
    "focus=[\"test F1 score bin\", \"valid F1 score bin\", \"test Accuracy\", order, \"arch\", \"ds\", \"model_name\"]\n",
    "nedf.sort_values([order])[focus].head(10).sort_values([\"valid F1 score bin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>arch</th>\n",
       "      <th>ds</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.515837</td>\n",
       "      <td>0.497238</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.448687</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.502128</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.464773</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.534799</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.468657</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.510288</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.477813</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.566802</td>\n",
       "      <td>0.511013</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.472147</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.583026</td>\n",
       "      <td>0.512820</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.476972</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.513274</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.474415</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.483499</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.514523</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.481969</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.519824</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.482413</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test F1 score bin  valid F1 score bin  test Accuracy  \\\n",
       "9            0.515837            0.497238          0.893   \n",
       "29           0.560000            0.502128          0.879   \n",
       "35           0.534799            0.508929          0.873   \n",
       "28           0.570423            0.510288          0.878   \n",
       "36           0.566802            0.511013          0.893   \n",
       "33           0.583026            0.512820          0.887   \n",
       "32           0.573529            0.513274          0.884   \n",
       "26           0.608392            0.514286          0.888   \n",
       "31           0.581818            0.514523          0.885   \n",
       "34           0.571429            0.519824          0.880   \n",
       "\n",
       "    valid Matthews Correff                       arch    ds  \\\n",
       "9                 0.448687  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "29                0.464773  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "35                0.468657  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "28                0.477813  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "36                0.472147  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "33                0.476972  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "32                0.474415  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "26                0.483499  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "31                0.481969  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "34                0.482413  lstm_noearly_stop_ft6_cl8  wiki   \n",
       "\n",
       "                                           model_name  \n",
       "9   lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...  \n",
       "29  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "35  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "28  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "36  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "33  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "32  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "26  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "31  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  \n",
       "34  lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-cl...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order=\"valid Matthews Correff\"\n",
    "focus=[\"test F1 score bin\", \"valid F1 score bin\", \"test Accuracy\", order, \"arch\", \"ds\", \"model_name\"]\n",
    "nedf.sort_values([order])[focus].head(10).sort_values([\"valid F1 score bin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_dir_parent</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Kappa quadratic</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "      <th>ds</th>\n",
       "      <th>arch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/hate/pl-10-wiki/models/sp25k</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.489083</td>\n",
       "      <td>0.471327</td>\n",
       "      <td>0.589474</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.350842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/hate/pl-10-wiki/models/sp25k</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.544681</td>\n",
       "      <td>0.446630</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.553796</td>\n",
       "      <td>0.553796</td>\n",
       "      <td>0.553796</td>\n",
       "      <td>0.335345</td>\n",
       "      <td>0.556015</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/hate/pl-10-wiki/models/sp25k</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.497959</td>\n",
       "      <td>0.510850</td>\n",
       "      <td>0.549550</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.911443</td>\n",
       "      <td>0.557214</td>\n",
       "      <td>0.509312</td>\n",
       "      <td>0.509312</td>\n",
       "      <td>0.509312</td>\n",
       "      <td>0.366872</td>\n",
       "      <td>0.516918</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/hate/pl-10-wiki/models/sp25k</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.454685</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>0.909453</td>\n",
       "      <td>0.547264</td>\n",
       "      <td>0.498286</td>\n",
       "      <td>0.498286</td>\n",
       "      <td>0.498286</td>\n",
       "      <td>0.409838</td>\n",
       "      <td>0.505727</td>\n",
       "      <td>0.474138</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/hate/pl-10-wiki/models/sp25k</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.472040</td>\n",
       "      <td>0.584746</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>0.918408</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.545825</td>\n",
       "      <td>0.545825</td>\n",
       "      <td>0.545825</td>\n",
       "      <td>0.357952</td>\n",
       "      <td>0.553520</td>\n",
       "      <td>0.513043</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm_noearly_stop_ft6_cl8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model_dir_parent  \\\n",
       "0  data/hate/pl-10-wiki/models/sp25k   \n",
       "1  data/hate/pl-10-wiki/models/sp25k   \n",
       "2  data/hate/pl-10-wiki/models/sp25k   \n",
       "3  data/hate/pl-10-wiki/models/sp25k   \n",
       "4  data/hate/pl-10-wiki/models/sp25k   \n",
       "\n",
       "                                          model_name  test Accuracy  \\\n",
       "0  lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...          0.883   \n",
       "1  lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...          0.893   \n",
       "2  lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...          0.877   \n",
       "3  lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...          0.889   \n",
       "4  lstm_noearly_stop_ft6_cl8_lmseed-0-ftseed-0-cl...          0.886   \n",
       "\n",
       "   test F1 score bin  test Loss  test Precision  test Recall  valid Accuracy  \\\n",
       "0           0.489083   0.471327        0.589474     0.417910        0.923383   \n",
       "1           0.544681   0.446630        0.633663     0.477612        0.925373   \n",
       "2           0.497959   0.510850        0.549550     0.455224        0.911443   \n",
       "3           0.554217   0.454685        0.600000     0.514925        0.909453   \n",
       "4           0.547619   0.472040        0.584746     0.514925        0.918408   \n",
       "\n",
       "   valid F1 score bin  valid Kappa  valid Kappa Linear  valid Kappa quadratic  \\\n",
       "0            0.560000          NaN                 NaN                    NaN   \n",
       "1            0.594595     0.553796            0.553796               0.553796   \n",
       "2            0.557214     0.509312            0.509312               0.509312   \n",
       "3            0.547264     0.498286            0.498286               0.498286   \n",
       "4            0.590000     0.545825            0.545825               0.545825   \n",
       "\n",
       "   valid Loss  valid Matthews Correff  valid Precision  valid Recall    ds  \\\n",
       "0    0.350842                     NaN         0.544444      0.576471  wiki   \n",
       "1    0.335345                0.556015         0.550000      0.647059  wiki   \n",
       "2    0.366872                0.516918         0.482759      0.658824  wiki   \n",
       "3    0.409838                0.505727         0.474138      0.647059  wiki   \n",
       "4    0.357952                0.553520         0.513043      0.694118  wiki   \n",
       "\n",
       "                        arch  \n",
       "0  lstm_noearly_stop_ft6_cl8  \n",
       "1  lstm_noearly_stop_ft6_cl8  \n",
       "2  lstm_noearly_stop_ft6_cl8  \n",
       "3  lstm_noearly_stop_ft6_cl8  \n",
       "4  lstm_noearly_stop_ft6_cl8  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nedf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted corss entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['qrnn_ft0_cl8', 'qrnn_ft20_cl8', 'qrnn_ft6_cl8', 'lstm_ft0_cl8', 'lstm_ft20_cl8', 'lstm_ft6_cl8',\n",
       "       'lstm_noearly_stop_ft6_cl8', 'lstm_nowce_ft6_cl8', 'lstm_small_ft6_el20', 'lstm_dp05_ft20_cl8',\n",
       "       'lstm_dp05_ft6_cl8'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"arch\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.442618</td>\n",
       "      <td>0.543644</td>\n",
       "      <td>0.885605</td>\n",
       "      <td>0.506515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.056835</td>\n",
       "      <td>0.017263</td>\n",
       "      <td>0.005514</td>\n",
       "      <td>0.022520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.509317</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.463182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.392634</td>\n",
       "      <td>0.531996</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.491514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.457767</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.885500</td>\n",
       "      <td>0.505817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.490414</td>\n",
       "      <td>0.555947</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.517761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.539535</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.565151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test F1 score bin  valid F1 score bin  test Accuracy  \\\n",
       "count          38.000000           38.000000      38.000000   \n",
       "mean            0.442618            0.543644       0.885605   \n",
       "std             0.056835            0.017263       0.005514   \n",
       "min             0.340909            0.509317       0.876000   \n",
       "25%             0.392634            0.531996       0.882000   \n",
       "50%             0.457767            0.545455       0.885500   \n",
       "75%             0.490414            0.555947       0.888000   \n",
       "max             0.539535            0.581081       0.901000   \n",
       "\n",
       "       valid Matthews Correff  \n",
       "count               38.000000  \n",
       "mean                 0.506515  \n",
       "std                  0.022520  \n",
       "min                  0.463182  \n",
       "25%                  0.491514  \n",
       "50%                  0.505817  \n",
       "75%                  0.517761  \n",
       "max                  0.565151  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"arch\"] == \"lstm_nowce_ft6_cl8\"][focus].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.547691</td>\n",
       "      <td>0.542830</td>\n",
       "      <td>0.878553</td>\n",
       "      <td>0.508073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.030312</td>\n",
       "      <td>0.035475</td>\n",
       "      <td>0.016858</td>\n",
       "      <td>0.030323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.418733</td>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.419594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.533211</td>\n",
       "      <td>0.520081</td>\n",
       "      <td>0.875250</td>\n",
       "      <td>0.491206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.552581</td>\n",
       "      <td>0.544979</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.509452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.566869</td>\n",
       "      <td>0.567013</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.526846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.564547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test F1 score bin  valid F1 score bin  test Accuracy  \\\n",
       "count          38.000000           38.000000      38.000000   \n",
       "mean            0.547691            0.542830       0.878553   \n",
       "std             0.030312            0.035475       0.016858   \n",
       "min             0.451613            0.418733       0.786000   \n",
       "25%             0.533211            0.520081       0.875250   \n",
       "50%             0.552581            0.544979       0.880000   \n",
       "75%             0.566869            0.567013       0.886000   \n",
       "max             0.608392            0.602273       0.895000   \n",
       "\n",
       "       valid Matthews Correff  \n",
       "count               38.000000  \n",
       "mean                 0.508073  \n",
       "std                  0.030323  \n",
       "min                  0.419594  \n",
       "25%                  0.491206  \n",
       "50%                  0.509452  \n",
       "75%                  0.526846  \n",
       "max                  0.564547  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"arch\"] == \"lstm_ft6_cl8\") & (df[\"ds\"]==\"wiki\")][focus].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight's Model selection based on the 1k pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed1</th>\n",
       "      <th>seed0</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.525926</td>\n",
       "      <td>0.469891</td>\n",
       "      <td>0.056035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.024596</td>\n",
       "      <td>0.038780</td>\n",
       "      <td>-0.014185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.495798</td>\n",
       "      <td>0.394231</td>\n",
       "      <td>0.101568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.504658</td>\n",
       "      <td>0.443662</td>\n",
       "      <td>0.060996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.526767</td>\n",
       "      <td>0.478060</td>\n",
       "      <td>0.048707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.539330</td>\n",
       "      <td>0.490383</td>\n",
       "      <td>0.048947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.564885</td>\n",
       "      <td>0.523809</td>\n",
       "      <td>0.041076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           seed1      seed0      diff\n",
       "count  10.000000  10.000000  0.000000\n",
       "mean    0.525926   0.469891  0.056035\n",
       "std     0.024596   0.038780 -0.014185\n",
       "min     0.495798   0.394231  0.101568\n",
       "25%     0.504658   0.443662  0.060996\n",
       "50%     0.526767   0.478060  0.048707\n",
       "75%     0.539330   0.490383  0.048947\n",
       "max     0.564885   0.523809  0.041076"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focus = ['test F1 score bin',\n",
    " 'test Accuracy',\n",
    " 'test Recall',\n",
    " 'test Precision']\n",
    "arch=\"lstm_small_ft6_el20\"\n",
    "seed1 = df[(df[\"arch\"] == arch)&df[\"model_name\"].str.contains(\"lmseed-1\")&(df[\"ds\"]==\"wiki\")][focus]\n",
    "seed0 = df[(df[\"arch\"] == arch)&df[\"model_name\"].str.contains(\"lmseed-0\")&(df[\"ds\"]==\"wiki\")][focus]\n",
    "res = pd.DataFrame({\"seed1\":seed1.describe()['test F1 score bin'], \"seed0\":seed0.describe()['test F1 score bin']})\n",
    "res[\"diff\"] = res[\"seed1\"]-res[\"seed0\"]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.hist([\n",
    "         seed0[\"test F1 score bin\"],\n",
    "         seed1[\"test F1 score bin\"]\n",
    "          \n",
    "         ],\n",
    "    bins=10,\n",
    "        label=[\"Language model, seed=0, 1 epoch\", \"Language model, seed=1, 1 epoch\"], histtype='bar', stacked=False,\n",
    "        range=[0.3,0.7])\n",
    "plt.legend()\n",
    "plt.xlabel(\"test F1 score\");\n",
    "plt.ylabel(\"count\");\n",
    "plt.savefig(\"1k.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='1k.pdf' target='_blank'>1k.pdf</a><br>"
      ],
      "text/plain": [
       "/home/pczapla/workspace/ulmfit-multilingual/experiments/poleval19/1k.pdf"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.FileLink(\"1k.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed1</th>\n",
       "      <th>seed0</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>151.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.555511</td>\n",
       "      <td>0.539647</td>\n",
       "      <td>0.015865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.028428</td>\n",
       "      <td>0.033603</td>\n",
       "      <td>-0.005174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.488479</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.036866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.536181</td>\n",
       "      <td>0.515420</td>\n",
       "      <td>0.020761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.541485</td>\n",
       "      <td>0.016849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.576201</td>\n",
       "      <td>0.563492</td>\n",
       "      <td>0.012709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.614232</td>\n",
       "      <td>0.007990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            seed1       seed0      diff\n",
       "count  151.000000  147.000000  4.000000\n",
       "mean     0.555511    0.539647  0.015865\n",
       "std      0.028428    0.033603 -0.005174\n",
       "min      0.488479    0.451613  0.036866\n",
       "25%      0.536181    0.515420  0.020761\n",
       "50%      0.558333    0.541485  0.016849\n",
       "75%      0.576201    0.563492  0.012709\n",
       "max      0.622222    0.614232  0.007990"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focus = ['test F1 score bin',\n",
    " 'test Accuracy',\n",
    " 'test Recall',\n",
    " 'test Precision']\n",
    "arch=\"lstm_ft6_cl8\"\n",
    "seed1 = df[df[\"model_name\"].str.contains(\"lmseed-1\") & df[\"model_name\"].str.contains(\"lstm_ft\")][focus]\n",
    "seed0 = df[df[\"model_name\"].str.contains(\"lmseed-0\") & df[\"model_name\"].str.contains(\"lstm_ft\")][focus]\n",
    "res = pd.DataFrame({\"seed1\":seed1.describe()['test F1 score bin'], \"seed0\":seed0.describe()['test F1 score bin']})\n",
    "res[\"diff\"] = res[\"seed1\"]-res[\"seed0\"]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "ax = plt.hist([\n",
    "         seed0[\"test F1 score bin\"],\n",
    "         seed1[\"test F1 score bin\"]\n",
    "          \n",
    "         ],\n",
    "    bins=10,\n",
    "        label=[\"Language model, seed=0, 10 epochs\", \"Language model, seed=1, 10 epochs\"], histtype='bar', stacked=False,\n",
    "        range=[0.3,0.7])\n",
    "plt.legend()\n",
    "plt.xlabel(\"test F1 score\");\n",
    "plt.ylabel(\"count\");\n",
    "plt.savefig(\"10k.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='10k.pdf' target='_blank'>10k.pdf</a><br>"
      ],
      "text/plain": [
       "/home/pczapla/workspace/ulmfit-multilingual/experiments/poleval19/10k.pdf"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.FileLink(\"10k.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame({\"seed1\":seed1['test F1 score bin'], \"seed0\":seed0['test F1 score bin']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ablation studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test F1 score bin</th>\n",
       "      <td>584.0</td>\n",
       "      <td>0.541107</td>\n",
       "      <td>0.044664</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.517763</td>\n",
       "      <td>0.548852</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count      mean       std       min       25%       50%  \\\n",
       "test F1 score bin  584.0  0.541107  0.044664  0.340909  0.517763  0.548852   \n",
       "\n",
       "                        75%       max  \n",
       "test F1 score bin  0.571429  0.622222  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"test F1 score bin\"]].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lmseed\"] = df[\"model_name\"].str.extract(\".*lmseed-([0-9]).*\")\n",
    "df[\"fine_tune\"] = df[\"model_name\"].str.extract(\".*ft([0-9]+).*\") != \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"model\", \"exp_type\"]] = df[\"model_name\"].str.extract(\"(qrnn|lstm)_?(.*?)_ft[0-9]+_.l[0-9]+.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"exp_type\"]==\"reg\",\"exp_type\"] = \"_reg\"\n",
    "df.loc[df[\"exp_type\"]==\"\",\"exp_type\"] = \"_reg\"\n",
    "df.loc[df[\"exp_type\"]==\"_reg\",\"exp_type\"] = \"_orig\"\n",
    "df.loc[df[\"exp_type\"]==\"noearly_stop\",\"exp_type\"] = \"wo early stopping\"\n",
    "df.loc[df[\"exp_type\"]==\"nowce\",\"exp_type\"] = \"cross entropy wo wieghts\"\n",
    "df.loc[df[\"exp_type\"]==\"small\",\"exp_type\"] = \"1 epoch pretraining\"\n",
    "df.loc[df[\"exp_type\"]==\"dp05\",\"exp_type\"] = \"dropmul = 0.5\"\n",
    "ft=df[\"fine_tune\"]==True\n",
    "df.loc[ft, \"fine_tune\"] = \"yes\"\n",
    "df.loc[~ft,\"fine_tune\"] = \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>model</th>\n",
       "      <th>exp_type</th>\n",
       "      <th>lmseed</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "      <td>0</td>\n",
       "      <td>0.553660</td>\n",
       "      <td>0.029906</td>\n",
       "      <td>0.614232</td>\n",
       "      <td>0.575757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "      <td>1</td>\n",
       "      <td>0.560869</td>\n",
       "      <td>0.028504</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.580522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm</td>\n",
       "      <td>dropmul = 0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519352</td>\n",
       "      <td>0.030414</td>\n",
       "      <td>0.589552</td>\n",
       "      <td>0.533757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reddit</td>\n",
       "      <td>lstm</td>\n",
       "      <td>dropmul = 0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.538298</td>\n",
       "      <td>0.030352</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.557069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reddit</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "      <td>0</td>\n",
       "      <td>0.572165</td>\n",
       "      <td>0.018227</td>\n",
       "      <td>0.603279</td>\n",
       "      <td>0.587732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reddit</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572165</td>\n",
       "      <td>0.018227</td>\n",
       "      <td>0.603279</td>\n",
       "      <td>0.587732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1 epoch pretraining</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469891</td>\n",
       "      <td>0.038780</td>\n",
       "      <td>0.523809</td>\n",
       "      <td>0.490383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1 epoch pretraining</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525926</td>\n",
       "      <td>0.024596</td>\n",
       "      <td>0.564885</td>\n",
       "      <td>0.539330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523124</td>\n",
       "      <td>0.027906</td>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.540592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550656</td>\n",
       "      <td>0.027349</td>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.573604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm</td>\n",
       "      <td>cross entropy wo wieghts</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433285</td>\n",
       "      <td>0.062494</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.487437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm</td>\n",
       "      <td>cross entropy wo wieghts</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451950</td>\n",
       "      <td>0.050503</td>\n",
       "      <td>0.539535</td>\n",
       "      <td>0.490566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm</td>\n",
       "      <td>wo early stopping</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516319</td>\n",
       "      <td>0.033725</td>\n",
       "      <td>0.564315</td>\n",
       "      <td>0.546150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wiki</td>\n",
       "      <td>lstm</td>\n",
       "      <td>wo early stopping</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564405</td>\n",
       "      <td>0.019395</td>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.574534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ds model                  exp_type lmseed      mean       std  \\\n",
       "0   reddit  lstm                     _orig      0  0.553660  0.029906   \n",
       "1   reddit  lstm                     _orig      1  0.560869  0.028504   \n",
       "2   reddit  lstm             dropmul = 0.5      0  0.519352  0.030414   \n",
       "3   reddit  lstm             dropmul = 0.5      1  0.538298  0.030352   \n",
       "4   reddit  qrnn                     _orig      0  0.572165  0.018227   \n",
       "5   reddit  qrnn                     _orig      1  0.572165  0.018227   \n",
       "8     wiki  lstm       1 epoch pretraining      0  0.469891  0.038780   \n",
       "9     wiki  lstm       1 epoch pretraining      1  0.525926  0.024596   \n",
       "11    wiki  lstm                     _orig      0  0.523124  0.027906   \n",
       "13    wiki  lstm                     _orig      1  0.550656  0.027349   \n",
       "14    wiki  lstm  cross entropy wo wieghts      0  0.433285  0.062494   \n",
       "15    wiki  lstm  cross entropy wo wieghts      1  0.451950  0.050503   \n",
       "16    wiki  lstm         wo early stopping      0  0.516319  0.033725   \n",
       "17    wiki  lstm         wo early stopping      1  0.564405  0.019395   \n",
       "\n",
       "         max       75%  \n",
       "0   0.614232  0.575757  \n",
       "1   0.622222  0.580522  \n",
       "2   0.589552  0.533757  \n",
       "3   0.602151  0.557069  \n",
       "4   0.603279  0.587732  \n",
       "5   0.603279  0.587732  \n",
       "8   0.523809  0.490383  \n",
       "9   0.564885  0.539330  \n",
       "11  0.570470  0.540592  \n",
       "13  0.608392  0.573604  \n",
       "14  0.521739  0.487437  \n",
       "15  0.539535  0.490566  \n",
       "16  0.564315  0.546150  \n",
       "17  0.608392  0.574534  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = df.pivot_table(index=\"model_name\", columns=[\"ds\", \"model\", \"exp_type\", \"lmseed\", \"fine_tune\"], \n",
    "               values=[\"test F1 score bin\"]).describe().T.sort_values([\"ds\",\"model\", \"exp_type\",\"mean\"]).reset_index()\n",
    "del results[\"level_0\"]\n",
    "results[results[\"fine_tune\"] == \"yes\"][[\"ds\",\"model\", \"exp_type\", \"lmseed\", \"mean\", \"std\", \"max\", \"75%\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>fine_tune</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wiki</td>\n",
       "      <td>no</td>\n",
       "      <td>0.522515</td>\n",
       "      <td>0.026661</td>\n",
       "      <td>0.582781</td>\n",
       "      <td>0.541998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wiki</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.536890</td>\n",
       "      <td>0.030744</td>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.558897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reddit</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.561675</td>\n",
       "      <td>0.027365</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.581680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reddit</td>\n",
       "      <td>no</td>\n",
       "      <td>0.573931</td>\n",
       "      <td>0.016832</td>\n",
       "      <td>0.603390</td>\n",
       "      <td>0.581451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ds fine_tune      mean       std       max       75%\n",
       "0    wiki        no  0.522515  0.026661  0.582781  0.541998\n",
       "1    wiki       yes  0.536890  0.030744  0.608392  0.558897\n",
       "2  reddit       yes  0.561675  0.027365  0.622222  0.581680\n",
       "3  reddit        no  0.573931  0.016832  0.603390  0.581451"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = df[df[\"exp_type\"]==\"_orig\"].pivot_table(index=\"model_name\", columns=[\"ds\", \"fine_tune\"], \n",
    "               values=[\"test F1 score bin\"]).describe().T.sort_values([\"mean\"]).reset_index()\n",
    "del results[\"level_0\"]\n",
    "results[[\"ds\", \"fine_tune\", \"mean\", \"std\", \"max\", \"75%\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_dir_parent</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "      <th>arch</th>\n",
       "      <th>ds</th>\n",
       "      <th>lmseed</th>\n",
       "      <th>fine_tune</th>\n",
       "      <th>model</th>\n",
       "      <th>exp_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.577922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511494</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.876617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429593</td>\n",
       "      <td>0.507218</td>\n",
       "      <td>0.389830</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.572289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.426693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.860696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434975</td>\n",
       "      <td>0.483857</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.573913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469194</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.849751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523841</td>\n",
       "      <td>0.477067</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.577259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530552</td>\n",
       "      <td>0.441885</td>\n",
       "      <td>0.323810</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.851741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488528</td>\n",
       "      <td>0.474608</td>\n",
       "      <td>0.344660</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.570588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470874</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.829851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537976</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.309735</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.842786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541371</td>\n",
       "      <td>0.454872</td>\n",
       "      <td>0.328638</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.457041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497512</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.857711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452747</td>\n",
       "      <td>0.473131</td>\n",
       "      <td>0.352041</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378810</td>\n",
       "      <td>0.492229</td>\n",
       "      <td>0.382857</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.557185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458937</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471542</td>\n",
       "      <td>0.494311</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-1...</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.578231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.419756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.634328</td>\n",
       "      <td>0.891542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345693</td>\n",
       "      <td>0.532369</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-2...</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.494505</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.873632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425387</td>\n",
       "      <td>0.484692</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-3...</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.574924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.876617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449001</td>\n",
       "      <td>0.518262</td>\n",
       "      <td>0.392265</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-4...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.603390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.419202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552795</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.881592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407950</td>\n",
       "      <td>0.511490</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-5...</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.594771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.427007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.529070</td>\n",
       "      <td>0.679105</td>\n",
       "      <td>0.881592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408002</td>\n",
       "      <td>0.500378</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.869652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478236</td>\n",
       "      <td>0.505266</td>\n",
       "      <td>0.377660</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.474490</td>\n",
       "      <td>0.694030</td>\n",
       "      <td>0.877612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403486</td>\n",
       "      <td>0.525650</td>\n",
       "      <td>0.395604</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.448317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519774</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427392</td>\n",
       "      <td>0.539378</td>\n",
       "      <td>0.411429</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.550820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.892537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404172</td>\n",
       "      <td>0.539953</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.580420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.419509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.546053</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.890547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378666</td>\n",
       "      <td>0.491477</td>\n",
       "      <td>0.414966</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.453675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.604478</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435547</td>\n",
       "      <td>0.503941</td>\n",
       "      <td>0.396450</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.593857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.423210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>0.891542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410248</td>\n",
       "      <td>0.526933</td>\n",
       "      <td>0.424051</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.468421</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.867662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508237</td>\n",
       "      <td>0.501671</td>\n",
       "      <td>0.373684</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.362120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.885572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317093</td>\n",
       "      <td>0.525116</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.366643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.887562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317464</td>\n",
       "      <td>0.496125</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.486303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.505747</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.867662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441740</td>\n",
       "      <td>0.479220</td>\n",
       "      <td>0.368132</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>0.889552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413494</td>\n",
       "      <td>0.522595</td>\n",
       "      <td>0.418750</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.578073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.442141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520958</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>0.891542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373358</td>\n",
       "      <td>0.526933</td>\n",
       "      <td>0.424051</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.590747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564626</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.888557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400573</td>\n",
       "      <td>0.503877</td>\n",
       "      <td>0.412903</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.577465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.413595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.899503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342127</td>\n",
       "      <td>0.528914</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>qrnn_ft20_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-5...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.595918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.453026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-5...</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.412375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.901493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.446970</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.552301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.526710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.542222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.542986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.484061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.573034</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.561265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.478323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.596639</td>\n",
       "      <td>0.529851</td>\n",
       "      <td>0.912438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.486726</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.559671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626263</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.548043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.401640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.890547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421384</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.528139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.568965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.445748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633027</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.508621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.440298</td>\n",
       "      <td>0.921393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.590038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.384665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.906468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.429450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660550</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.521367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.490258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.502203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.425373</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.548523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.631068</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542056</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.490045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619835</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504274</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.607004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.919403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516393</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model_dir_parent  \\\n",
       "19   data/hate/pl-10-reddit/models/sp25k   \n",
       "20   data/hate/pl-10-reddit/models/sp25k   \n",
       "21   data/hate/pl-10-reddit/models/sp25k   \n",
       "22   data/hate/pl-10-reddit/models/sp25k   \n",
       "23   data/hate/pl-10-reddit/models/sp25k   \n",
       "24   data/hate/pl-10-reddit/models/sp25k   \n",
       "25   data/hate/pl-10-reddit/models/sp25k   \n",
       "26   data/hate/pl-10-reddit/models/sp25k   \n",
       "27   data/hate/pl-10-reddit/models/sp25k   \n",
       "28   data/hate/pl-10-reddit/models/sp25k   \n",
       "29   data/hate/pl-10-reddit/models/sp25k   \n",
       "30   data/hate/pl-10-reddit/models/sp25k   \n",
       "31   data/hate/pl-10-reddit/models/sp25k   \n",
       "32   data/hate/pl-10-reddit/models/sp25k   \n",
       "33   data/hate/pl-10-reddit/models/sp25k   \n",
       "34   data/hate/pl-10-reddit/models/sp25k   \n",
       "35   data/hate/pl-10-reddit/models/sp25k   \n",
       "36   data/hate/pl-10-reddit/models/sp25k   \n",
       "37   data/hate/pl-10-reddit/models/sp25k   \n",
       "57   data/hate/pl-10-reddit/models/sp25k   \n",
       "58   data/hate/pl-10-reddit/models/sp25k   \n",
       "59   data/hate/pl-10-reddit/models/sp25k   \n",
       "60   data/hate/pl-10-reddit/models/sp25k   \n",
       "61   data/hate/pl-10-reddit/models/sp25k   \n",
       "62   data/hate/pl-10-reddit/models/sp25k   \n",
       "63   data/hate/pl-10-reddit/models/sp25k   \n",
       "64   data/hate/pl-10-reddit/models/sp25k   \n",
       "65   data/hate/pl-10-reddit/models/sp25k   \n",
       "66   data/hate/pl-10-reddit/models/sp25k   \n",
       "67   data/hate/pl-10-reddit/models/sp25k   \n",
       "..                                   ...   \n",
       "306  data/hate/pl-10-reddit/models/sp25k   \n",
       "307  data/hate/pl-10-reddit/models/sp25k   \n",
       "308  data/hate/pl-10-reddit/models/sp25k   \n",
       "309  data/hate/pl-10-reddit/models/sp25k   \n",
       "310  data/hate/pl-10-reddit/models/sp25k   \n",
       "311  data/hate/pl-10-reddit/models/sp25k   \n",
       "312  data/hate/pl-10-reddit/models/sp25k   \n",
       "313  data/hate/pl-10-reddit/models/sp25k   \n",
       "314  data/hate/pl-10-reddit/models/sp25k   \n",
       "315  data/hate/pl-10-reddit/models/sp25k   \n",
       "316  data/hate/pl-10-reddit/models/sp25k   \n",
       "317  data/hate/pl-10-reddit/models/sp25k   \n",
       "318  data/hate/pl-10-reddit/models/sp25k   \n",
       "319  data/hate/pl-10-reddit/models/sp25k   \n",
       "320  data/hate/pl-10-reddit/models/sp25k   \n",
       "321  data/hate/pl-10-reddit/models/sp25k   \n",
       "322  data/hate/pl-10-reddit/models/sp25k   \n",
       "323  data/hate/pl-10-reddit/models/sp25k   \n",
       "324  data/hate/pl-10-reddit/models/sp25k   \n",
       "325  data/hate/pl-10-reddit/models/sp25k   \n",
       "326  data/hate/pl-10-reddit/models/sp25k   \n",
       "327  data/hate/pl-10-reddit/models/sp25k   \n",
       "328  data/hate/pl-10-reddit/models/sp25k   \n",
       "329  data/hate/pl-10-reddit/models/sp25k   \n",
       "330  data/hate/pl-10-reddit/models/sp25k   \n",
       "331  data/hate/pl-10-reddit/models/sp25k   \n",
       "332  data/hate/pl-10-reddit/models/sp25k   \n",
       "333  data/hate/pl-10-reddit/models/sp25k   \n",
       "334  data/hate/pl-10-reddit/models/sp25k   \n",
       "335  data/hate/pl-10-reddit/models/sp25k   \n",
       "\n",
       "                                            model_name  test Accuracy  \\\n",
       "19   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.870   \n",
       "20   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.858   \n",
       "21   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.853   \n",
       "22   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.855   \n",
       "23   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.862   \n",
       "24   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.854   \n",
       "25   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.850   \n",
       "26   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.865   \n",
       "27   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.871   \n",
       "28   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.849   \n",
       "29   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-1...          0.876   \n",
       "30   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-2...          0.864   \n",
       "31   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-3...          0.861   \n",
       "32   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-4...          0.883   \n",
       "33   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-5...          0.876   \n",
       "34   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.848   \n",
       "35   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.856   \n",
       "36   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.873   \n",
       "37   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.863   \n",
       "57   qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.880   \n",
       "58   qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.865   \n",
       "59   qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.881   \n",
       "60   qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.854   \n",
       "61   qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.876   \n",
       "62   qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.867   \n",
       "63   qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.868   \n",
       "64   qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.878   \n",
       "65   qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.873   \n",
       "66   qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.885   \n",
       "67   qrnn_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-...          0.880   \n",
       "..                                                 ...            ...   \n",
       "306  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-5...          0.901   \n",
       "307  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-5...          0.890   \n",
       "308  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.900   \n",
       "309  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.893   \n",
       "310  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.897   \n",
       "311  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.895   \n",
       "312  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.899   \n",
       "313  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.889   \n",
       "314  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.893   \n",
       "315  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.891   \n",
       "316  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.873   \n",
       "317  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.891   \n",
       "318  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.900   \n",
       "319  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.895   \n",
       "320  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.886   \n",
       "321  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.893   \n",
       "322  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.892   \n",
       "323  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.904   \n",
       "324  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.894   \n",
       "325  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.902   \n",
       "326  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.901   \n",
       "327  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.888   \n",
       "328  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.901   \n",
       "329  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.887   \n",
       "330  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.893   \n",
       "331  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.895   \n",
       "332  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.895   \n",
       "333  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.894   \n",
       "334  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.899   \n",
       "335  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.906   \n",
       "\n",
       "     test F1 score bin  test Kappa Linear  test Loss  test Matthews Correff  \\\n",
       "19            0.577922                NaN   0.456889                    NaN   \n",
       "20            0.572289                NaN   0.426693                    NaN   \n",
       "21            0.573913                NaN   0.465223                    NaN   \n",
       "22            0.577259                NaN   0.483052                    NaN   \n",
       "23            0.576687                NaN   0.491995                    NaN   \n",
       "24            0.570588                NaN   0.483143                    NaN   \n",
       "25            0.561404                NaN   0.519333                    NaN   \n",
       "26            0.597015                NaN   0.457041                    NaN   \n",
       "27            0.582524                NaN   0.418411                    NaN   \n",
       "28            0.557185                NaN   0.482558                    NaN   \n",
       "29            0.578231                NaN   0.419756                    NaN   \n",
       "30            0.569620                NaN   0.458027                    NaN   \n",
       "31            0.574924                NaN   0.477018                    NaN   \n",
       "32            0.603390                NaN   0.419202                    NaN   \n",
       "33            0.594771                NaN   0.427007                    NaN   \n",
       "34            0.530864                NaN   0.488566                    NaN   \n",
       "35            0.563636                NaN   0.437123                    NaN   \n",
       "36            0.591640                NaN   0.448317                    NaN   \n",
       "37            0.550820                NaN   0.450464                    NaN   \n",
       "57            0.580420                NaN   0.419509                    NaN   \n",
       "58            0.545455                NaN   0.453675                    NaN   \n",
       "59            0.593857                NaN   0.423210                    NaN   \n",
       "60            0.549383                NaN   0.510561                    NaN   \n",
       "61            0.563380                NaN   0.362120                    NaN   \n",
       "62            0.558140                NaN   0.366643                    NaN   \n",
       "63            0.571429                NaN   0.486303                    NaN   \n",
       "64            0.587838                NaN   0.450848                    NaN   \n",
       "65            0.578073                NaN   0.442141                    NaN   \n",
       "66            0.590747                NaN   0.456181                    NaN   \n",
       "67            0.577465                NaN   0.413595                    NaN   \n",
       "..                 ...                ...        ...                    ...   \n",
       "306           0.595918                NaN   0.453026                    NaN   \n",
       "307           0.576923                NaN   0.412375                    NaN   \n",
       "308           0.576271                NaN   0.458157                    NaN   \n",
       "309           0.552301                NaN   0.526710                    NaN   \n",
       "310           0.542222                NaN   0.378023                    NaN   \n",
       "311           0.549356                NaN   0.502734                    NaN   \n",
       "312           0.542986                NaN   0.484061                    NaN   \n",
       "313           0.561265                NaN   0.478323                    NaN   \n",
       "314           0.559671                NaN   0.460062                    NaN   \n",
       "315           0.532189                NaN   0.520550                    NaN   \n",
       "316           0.548043                NaN   0.401640                    NaN   \n",
       "317           0.528139                NaN   0.489808                    NaN   \n",
       "318           0.568965                NaN   0.445748                    NaN   \n",
       "319           0.567901                NaN   0.542561                    NaN   \n",
       "320           0.508621                NaN   0.528722                    NaN   \n",
       "321           0.590038                NaN   0.384665                    NaN   \n",
       "322           0.534483                NaN   0.502705                    NaN   \n",
       "323           0.586207                NaN   0.488476                    NaN   \n",
       "324           0.558333                NaN   0.466521                    NaN   \n",
       "325           0.566372                NaN   0.447245                    NaN   \n",
       "326           0.592593                NaN   0.429450                    NaN   \n",
       "327           0.521367                NaN   0.500936                    NaN   \n",
       "328           0.602410                NaN   0.490258                    NaN   \n",
       "329           0.502203                NaN   0.516663                    NaN   \n",
       "330           0.548523                NaN   0.473883                    NaN   \n",
       "331           0.588235                NaN   0.490045                    NaN   \n",
       "332           0.549356                NaN   0.458278                    NaN   \n",
       "333           0.558333                NaN   0.485095                    NaN   \n",
       "334           0.607004                NaN   0.308932                    NaN   \n",
       "335           0.614754                NaN   0.471272                    NaN   \n",
       "\n",
       "     test Precision  test Recall  valid Accuracy  ...  valid Loss  \\\n",
       "19         0.511494     0.664179        0.876617  ...    0.429593   \n",
       "20         0.479798     0.708955        0.860696  ...    0.434975   \n",
       "21         0.469194     0.738806        0.849751  ...    0.523841   \n",
       "22         0.473684     0.738806        0.841791  ...    0.530552   \n",
       "23         0.489583     0.701493        0.851741  ...    0.488528   \n",
       "24         0.470874     0.723881        0.829851  ...    0.537976   \n",
       "25         0.461538     0.716418        0.842786  ...    0.541371   \n",
       "26         0.497512     0.746269        0.857711  ...    0.452747   \n",
       "27         0.514286     0.671642        0.874627  ...    0.378810   \n",
       "28         0.458937     0.708955        0.866667  ...    0.471542   \n",
       "29         0.531250     0.634328        0.891542  ...    0.345693   \n",
       "30         0.494505     0.671642        0.873632  ...    0.425387   \n",
       "31         0.487047     0.701493        0.876617  ...    0.449001   \n",
       "32         0.552795     0.664179        0.881592  ...    0.407950   \n",
       "33         0.529070     0.679105        0.881592  ...    0.408002   \n",
       "34         0.452632     0.641791        0.869652  ...    0.478236   \n",
       "35         0.474490     0.694030        0.877612  ...    0.403486   \n",
       "36         0.519774     0.686567        0.884577  ...    0.427392   \n",
       "37         0.491228     0.626866        0.892537  ...    0.404172   \n",
       "57         0.546053     0.619403        0.890547  ...    0.378666   \n",
       "58         0.496933     0.604478        0.880597  ...    0.435547   \n",
       "59         0.547170     0.649254        0.891542  ...    0.410248   \n",
       "60         0.468421     0.664179        0.867662  ...    0.508237   \n",
       "61         0.533333     0.597015        0.885572  ...    0.317093   \n",
       "62         0.502994     0.626866        0.887562  ...    0.317464   \n",
       "63         0.505747     0.656716        0.867662  ...    0.441740   \n",
       "64         0.537037     0.649254        0.889552  ...    0.413494   \n",
       "65         0.520958     0.649254        0.891542  ...    0.373358   \n",
       "66         0.564626     0.619403        0.888557  ...    0.400573   \n",
       "67         0.546667     0.611940        0.899503  ...    0.342127   \n",
       "..              ...          ...             ...  ...         ...   \n",
       "306        0.657658     0.544776        0.923383  ...    0.369372   \n",
       "307        0.595238     0.559702        0.901493  ...    0.341758   \n",
       "308        0.666667     0.507463        0.920398  ...    0.343866   \n",
       "309        0.628571     0.492537        0.923383  ...    0.376918   \n",
       "310        0.670330     0.455224        0.928358  ...    0.245958   \n",
       "311        0.646465     0.477612        0.917413  ...    0.366041   \n",
       "312        0.689655     0.447761        0.928358  ...    0.292909   \n",
       "313        0.596639     0.529851        0.912438  ...    0.371474   \n",
       "314        0.623853     0.507463        0.916418  ...    0.314330   \n",
       "315        0.626263     0.462687        0.924378  ...    0.342852   \n",
       "316        0.523810     0.574627        0.890547  ...    0.359008   \n",
       "317        0.628866     0.455224        0.917413  ...    0.327826   \n",
       "318        0.673469     0.492537        0.922388  ...    0.303262   \n",
       "319        0.633027     0.514925        0.922388  ...    0.334571   \n",
       "320        0.602041     0.440298        0.921393  ...    0.341839   \n",
       "321        0.606299     0.574627        0.906468  ...    0.314057   \n",
       "322        0.632653     0.462687        0.922388  ...    0.337562   \n",
       "323        0.693878     0.507463        0.922388  ...    0.342792   \n",
       "324        0.632075     0.500000        0.923383  ...    0.303226   \n",
       "325        0.695652     0.477612        0.917413  ...    0.347164   \n",
       "326        0.660550     0.537313        0.915423  ...    0.313667   \n",
       "327        0.610000     0.455224        0.923383  ...    0.378845   \n",
       "328        0.652174     0.559702        0.914428  ...    0.392229   \n",
       "329        0.612903     0.425373        0.922388  ...    0.355745   \n",
       "330        0.631068     0.485075        0.924378  ...    0.329670   \n",
       "331        0.619835     0.559702        0.914428  ...    0.358677   \n",
       "332        0.646465     0.477612        0.916418  ...    0.332558   \n",
       "333        0.632075     0.500000        0.928358  ...    0.338581   \n",
       "334        0.634146     0.582090        0.919403  ...    0.237768   \n",
       "335        0.681818     0.559702        0.917413  ...    0.372592   \n",
       "\n",
       "     valid Matthews Correff  valid Precision  valid Recall           arch  \\\n",
       "19                 0.507218         0.389830      0.811765   qrnn_ft0_cl8   \n",
       "20                 0.483857         0.358974      0.823529   qrnn_ft0_cl8   \n",
       "21                 0.477067         0.342857      0.847059   qrnn_ft0_cl8   \n",
       "22                 0.441885         0.323810      0.800000   qrnn_ft0_cl8   \n",
       "23                 0.474608         0.344660      0.835294   qrnn_ft0_cl8   \n",
       "24                 0.435847         0.309735      0.823529   qrnn_ft0_cl8   \n",
       "25                 0.454872         0.328638      0.823529   qrnn_ft0_cl8   \n",
       "26                 0.473131         0.352041      0.811765   qrnn_ft0_cl8   \n",
       "27                 0.492229         0.382857      0.788235   qrnn_ft0_cl8   \n",
       "28                 0.494311         0.370370      0.823529   qrnn_ft0_cl8   \n",
       "29                 0.532369         0.425000      0.800000   qrnn_ft0_cl8   \n",
       "30                 0.484692         0.379310      0.776471   qrnn_ft0_cl8   \n",
       "31                 0.518262         0.392265      0.835294   qrnn_ft0_cl8   \n",
       "32                 0.511490         0.400000      0.800000   qrnn_ft0_cl8   \n",
       "33                 0.500378         0.397590      0.776471   qrnn_ft0_cl8   \n",
       "34                 0.505266         0.377660      0.835294   qrnn_ft0_cl8   \n",
       "35                 0.525650         0.395604      0.847059   qrnn_ft0_cl8   \n",
       "36                 0.539378         0.411429      0.847059   qrnn_ft0_cl8   \n",
       "37                 0.539953         0.428571      0.811765   qrnn_ft0_cl8   \n",
       "57                 0.491477         0.414966      0.717647  qrnn_ft20_cl8   \n",
       "58                 0.503941         0.396450      0.788235  qrnn_ft20_cl8   \n",
       "59                 0.526933         0.424051      0.788235  qrnn_ft20_cl8   \n",
       "60                 0.501671         0.373684      0.835294  qrnn_ft20_cl8   \n",
       "61                 0.525116         0.410714      0.811765  qrnn_ft20_cl8   \n",
       "62                 0.496125         0.409091      0.741176  qrnn_ft20_cl8   \n",
       "63                 0.479220         0.368132      0.788235  qrnn_ft20_cl8   \n",
       "64                 0.522595         0.418750      0.788235  qrnn_ft20_cl8   \n",
       "65                 0.526933         0.424051      0.788235  qrnn_ft20_cl8   \n",
       "66                 0.503877         0.412903      0.752941  qrnn_ft20_cl8   \n",
       "67                 0.528914         0.444444      0.752941  qrnn_ft20_cl8   \n",
       "..                      ...              ...           ...            ...   \n",
       "306                     NaN         0.538462      0.658824   lstm_ft6_cl8   \n",
       "307                     NaN         0.446970      0.694118   lstm_ft6_cl8   \n",
       "308                     NaN         0.523364      0.658824   lstm_ft6_cl8   \n",
       "309                     NaN         0.540816      0.623529   lstm_ft6_cl8   \n",
       "310                     NaN         0.564356      0.670588   lstm_ft6_cl8   \n",
       "311                     NaN         0.509259      0.647059   lstm_ft6_cl8   \n",
       "312                     NaN         0.573034      0.600000   lstm_ft6_cl8   \n",
       "313                     NaN         0.486726      0.647059   lstm_ft6_cl8   \n",
       "314                     NaN         0.504425      0.670588   lstm_ft6_cl8   \n",
       "315                     NaN         0.545455      0.635294   lstm_ft6_cl8   \n",
       "316                     NaN         0.421384      0.788235   lstm_ft6_cl8   \n",
       "317                     NaN         0.509804      0.611765   lstm_ft6_cl8   \n",
       "318                     NaN         0.534653      0.635294   lstm_ft6_cl8   \n",
       "319                     NaN         0.533333      0.658824   lstm_ft6_cl8   \n",
       "320                     NaN         0.528302      0.658824   lstm_ft6_cl8   \n",
       "321                     NaN         0.466667      0.741176   lstm_ft6_cl8   \n",
       "322                     NaN         0.537634      0.588235   lstm_ft6_cl8   \n",
       "323                     NaN         0.533333      0.658824   lstm_ft6_cl8   \n",
       "324                     NaN         0.538462      0.658824   lstm_ft6_cl8   \n",
       "325                     NaN         0.510204      0.588235   lstm_ft6_cl8   \n",
       "326                     NaN         0.500000      0.623529   lstm_ft6_cl8   \n",
       "327                     NaN         0.540000      0.635294   lstm_ft6_cl8   \n",
       "328                     NaN         0.495726      0.682353   lstm_ft6_cl8   \n",
       "329                     NaN         0.534653      0.635294   lstm_ft6_cl8   \n",
       "330                     NaN         0.542056      0.682353   lstm_ft6_cl8   \n",
       "331                     NaN         0.496000      0.729412   lstm_ft6_cl8   \n",
       "332                     NaN         0.504274      0.694118   lstm_ft6_cl8   \n",
       "333                     NaN         0.568421      0.635294   lstm_ft6_cl8   \n",
       "334                     NaN         0.516393      0.741176   lstm_ft6_cl8   \n",
       "335                     NaN         0.509091      0.658824   lstm_ft6_cl8   \n",
       "\n",
       "         ds lmseed fine_tune model exp_type  \n",
       "19   reddit      1        no  qrnn    _orig  \n",
       "20   reddit      1        no  qrnn    _orig  \n",
       "21   reddit      1        no  qrnn    _orig  \n",
       "22   reddit      1        no  qrnn    _orig  \n",
       "23   reddit      1        no  qrnn    _orig  \n",
       "24   reddit      1        no  qrnn    _orig  \n",
       "25   reddit      1        no  qrnn    _orig  \n",
       "26   reddit      1        no  qrnn    _orig  \n",
       "27   reddit      1        no  qrnn    _orig  \n",
       "28   reddit      1        no  qrnn    _orig  \n",
       "29   reddit      1        no  qrnn    _orig  \n",
       "30   reddit      1        no  qrnn    _orig  \n",
       "31   reddit      1        no  qrnn    _orig  \n",
       "32   reddit      1        no  qrnn    _orig  \n",
       "33   reddit      1        no  qrnn    _orig  \n",
       "34   reddit      1        no  qrnn    _orig  \n",
       "35   reddit      1        no  qrnn    _orig  \n",
       "36   reddit      1        no  qrnn    _orig  \n",
       "37   reddit      1        no  qrnn    _orig  \n",
       "57   reddit      1       yes  qrnn    _orig  \n",
       "58   reddit      1       yes  qrnn    _orig  \n",
       "59   reddit      1       yes  qrnn    _orig  \n",
       "60   reddit      1       yes  qrnn    _orig  \n",
       "61   reddit      1       yes  qrnn    _orig  \n",
       "62   reddit      1       yes  qrnn    _orig  \n",
       "63   reddit      1       yes  qrnn    _orig  \n",
       "64   reddit      1       yes  qrnn    _orig  \n",
       "65   reddit      1       yes  qrnn    _orig  \n",
       "66   reddit      1       yes  qrnn    _orig  \n",
       "67   reddit      1       yes  qrnn    _orig  \n",
       "..      ...    ...       ...   ...      ...  \n",
       "306  reddit      1       yes  lstm    _orig  \n",
       "307  reddit      1       yes  lstm    _orig  \n",
       "308  reddit      1       yes  lstm    _orig  \n",
       "309  reddit      1       yes  lstm    _orig  \n",
       "310  reddit      1       yes  lstm    _orig  \n",
       "311  reddit      1       yes  lstm    _orig  \n",
       "312  reddit      1       yes  lstm    _orig  \n",
       "313  reddit      1       yes  lstm    _orig  \n",
       "314  reddit      1       yes  lstm    _orig  \n",
       "315  reddit      1       yes  lstm    _orig  \n",
       "316  reddit      1       yes  lstm    _orig  \n",
       "317  reddit      1       yes  lstm    _orig  \n",
       "318  reddit      1       yes  lstm    _orig  \n",
       "319  reddit      1       yes  lstm    _orig  \n",
       "320  reddit      1       yes  lstm    _orig  \n",
       "321  reddit      1       yes  lstm    _orig  \n",
       "322  reddit      1       yes  lstm    _orig  \n",
       "323  reddit      1       yes  lstm    _orig  \n",
       "324  reddit      1       yes  lstm    _orig  \n",
       "325  reddit      1       yes  lstm    _orig  \n",
       "326  reddit      1       yes  lstm    _orig  \n",
       "327  reddit      1       yes  lstm    _orig  \n",
       "328  reddit      1       yes  lstm    _orig  \n",
       "329  reddit      1       yes  lstm    _orig  \n",
       "330  reddit      1       yes  lstm    _orig  \n",
       "331  reddit      1       yes  lstm    _orig  \n",
       "332  reddit      1       yes  lstm    _orig  \n",
       "333  reddit      1       yes  lstm    _orig  \n",
       "334  reddit      1       yes  lstm    _orig  \n",
       "335  reddit      1       yes  lstm    _orig  \n",
       "\n",
       "[189 rows x 22 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"ds\"]==\"reddit\")&(df[\"model_name\"].str.contains(\"lmseed-1\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0-ftseed-0-clsweightseed-0-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0-ftseed-0-clsweightseed-1-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0-ftseed-0-clsweightseed-2-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0-ftseed-0-clsweightseed-3-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0-ftseed-0-clsweightseed-4-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0-ftseed-0-clsweightseed-5-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0-ftseed-0-clsweightseed-6-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0-ftseed-0-clsweightseed-7-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0-ftseed-0-clsweightseed-8-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0-ftseed-0-clsweightseed-9-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>1-ftseed-0-clsweightseed-0-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1-ftseed-0-clsweightseed-1-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1-ftseed-0-clsweightseed-2-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1-ftseed-0-clsweightseed-3-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1-ftseed-0-clsweightseed-4-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1-ftseed-0-clsweightseed-5-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1-ftseed-0-clsweightseed-6-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1-ftseed-0-clsweightseed-7-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1-ftseed-0-clsweightseed-8-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1-ftseed-0-clsweightseed-9-clstrainseed-0.m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0\n",
       "304  0-ftseed-0-clsweightseed-0-clstrainseed-0.m\n",
       "305  0-ftseed-0-clsweightseed-1-clstrainseed-0.m\n",
       "306  0-ftseed-0-clsweightseed-2-clstrainseed-0.m\n",
       "307  0-ftseed-0-clsweightseed-3-clstrainseed-0.m\n",
       "308  0-ftseed-0-clsweightseed-4-clstrainseed-0.m\n",
       "309  0-ftseed-0-clsweightseed-5-clstrainseed-0.m\n",
       "310  0-ftseed-0-clsweightseed-6-clstrainseed-0.m\n",
       "311  0-ftseed-0-clsweightseed-7-clstrainseed-0.m\n",
       "312  0-ftseed-0-clsweightseed-8-clstrainseed-0.m\n",
       "313  0-ftseed-0-clsweightseed-9-clstrainseed-0.m\n",
       "314  1-ftseed-0-clsweightseed-0-clstrainseed-0.m\n",
       "315  1-ftseed-0-clsweightseed-1-clstrainseed-0.m\n",
       "316  1-ftseed-0-clsweightseed-2-clstrainseed-0.m\n",
       "317  1-ftseed-0-clsweightseed-3-clstrainseed-0.m\n",
       "318  1-ftseed-0-clsweightseed-4-clstrainseed-0.m\n",
       "319  1-ftseed-0-clsweightseed-5-clstrainseed-0.m\n",
       "320  1-ftseed-0-clsweightseed-6-clstrainseed-0.m\n",
       "321  1-ftseed-0-clsweightseed-7-clstrainseed-0.m\n",
       "322  1-ftseed-0-clsweightseed-8-clstrainseed-0.m\n",
       "323  1-ftseed-0-clsweightseed-9-clstrainseed-0.m"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"arch\"] == \"lstm_small_ft6_el20\") & (df[\"ds\"]==\"wiki\")][\"model_name\"].str.extract(\"lmseed-(.*)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-0-clstrainseed-0.m',\n",
       "       'lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-0-clstrainseed-1.m',\n",
       "       'lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-0-clstrainseed-2.m',\n",
       "       'lstm_ft20_cl8_lmseed-0-ftseed-0-clsweightseed-0-clstrainseed-3.m', ...,\n",
       "       'lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9-clstrainseed-3.m',\n",
       "       'lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9-clstrainseed-4.m',\n",
       "       'lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9-clstrainseed-5.m',\n",
       "       'lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9-clstrainseed-6.m'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"model_name\"].str.contains(\"lstm\") & df[\"model_dir_parent\"].str.contains(\"reddit\")][\"model_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.862474</td>\n",
       "      <td>0.573931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492615</td>\n",
       "      <td>0.690495</td>\n",
       "      <td>0.867452</td>\n",
       "      <td>0.512282</td>\n",
       "      <td>0.448106</td>\n",
       "      <td>0.449435</td>\n",
       "      <td>0.494340</td>\n",
       "      <td>0.374274</td>\n",
       "      <td>0.816718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.016832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027161</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>0.017477</td>\n",
       "      <td>0.031288</td>\n",
       "      <td>0.037504</td>\n",
       "      <td>0.055156</td>\n",
       "      <td>0.030134</td>\n",
       "      <td>0.033402</td>\n",
       "      <td>0.021990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.829851</td>\n",
       "      <td>0.450161</td>\n",
       "      <td>0.373101</td>\n",
       "      <td>0.345693</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.309735</td>\n",
       "      <td>0.776471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.854250</td>\n",
       "      <td>0.565132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.429536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471576</td>\n",
       "      <td>0.666045</td>\n",
       "      <td>0.853234</td>\n",
       "      <td>0.488877</td>\n",
       "      <td>0.419496</td>\n",
       "      <td>0.407963</td>\n",
       "      <td>0.475223</td>\n",
       "      <td>0.346505</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.574924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.457041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.694030</td>\n",
       "      <td>0.873632</td>\n",
       "      <td>0.515385</td>\n",
       "      <td>0.453120</td>\n",
       "      <td>0.434975</td>\n",
       "      <td>0.494311</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.870750</td>\n",
       "      <td>0.581451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.482928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.513588</td>\n",
       "      <td>0.714552</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>0.533709</td>\n",
       "      <td>0.473814</td>\n",
       "      <td>0.485955</td>\n",
       "      <td>0.516569</td>\n",
       "      <td>0.397094</td>\n",
       "      <td>0.835294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.603390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552795</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.892537</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.506322</td>\n",
       "      <td>0.541371</td>\n",
       "      <td>0.539953</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.847059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear  test Loss  \\\n",
       "count      38.000000          38.000000                0.0  38.000000   \n",
       "mean        0.862474           0.573931                NaN   0.458411   \n",
       "std         0.010040           0.016832                NaN   0.028654   \n",
       "min         0.848000           0.530864                NaN   0.418411   \n",
       "25%         0.854250           0.565132                NaN   0.429536   \n",
       "50%         0.862000           0.574924                NaN   0.457041   \n",
       "75%         0.870750           0.581451                NaN   0.482928   \n",
       "max         0.883000           0.603390                NaN   0.519333   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count                    0.0       38.000000    38.000000       38.000000   \n",
       "mean                     NaN        0.492615     0.690495        0.867452   \n",
       "std                      NaN        0.027161     0.034733        0.017477   \n",
       "min                      NaN        0.452632     0.626866        0.829851   \n",
       "25%                      NaN        0.471576     0.666045        0.853234   \n",
       "50%                      NaN        0.489583     0.694030        0.873632   \n",
       "75%                      NaN        0.513588     0.714552        0.880597   \n",
       "max                      NaN        0.552795     0.746269        0.892537   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count           38.000000           38.000000   38.000000   \n",
       "mean             0.512282            0.448106    0.449435   \n",
       "std              0.031288            0.037504    0.055156   \n",
       "min              0.450161            0.373101    0.345693   \n",
       "25%              0.488877            0.419496    0.407963   \n",
       "50%              0.515385            0.453120    0.434975   \n",
       "75%              0.533709            0.473814    0.485955   \n",
       "max              0.560976            0.506322    0.541371   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count               38.000000        38.000000     38.000000  \n",
       "mean                 0.494340         0.374274      0.816718  \n",
       "std                  0.030134         0.033402      0.021990  \n",
       "min                  0.435847         0.309735      0.776471  \n",
       "25%                  0.475223         0.346505      0.800000  \n",
       "50%                  0.494311         0.379310      0.823529  \n",
       "75%                  0.516569         0.397094      0.835294  \n",
       "max                  0.539953         0.428571      0.847059  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"model_name\"].str.contains(\"ft0\") & df[\"model_dir_parent\"].str.contains(\"reddit\")].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.886325</td>\n",
       "      <td>0.549485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598312</td>\n",
       "      <td>0.522912</td>\n",
       "      <td>0.912272</td>\n",
       "      <td>0.575503</td>\n",
       "      <td>0.488324</td>\n",
       "      <td>0.356876</td>\n",
       "      <td>0.518006</td>\n",
       "      <td>0.502310</td>\n",
       "      <td>0.693808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.010419</td>\n",
       "      <td>0.034398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059474</td>\n",
       "      <td>0.087491</td>\n",
       "      <td>0.017925</td>\n",
       "      <td>0.031314</td>\n",
       "      <td>0.025352</td>\n",
       "      <td>0.049796</td>\n",
       "      <td>0.022445</td>\n",
       "      <td>0.068440</td>\n",
       "      <td>0.070335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.337015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.468421</td>\n",
       "      <td>0.365672</td>\n",
       "      <td>0.867662</td>\n",
       "      <td>0.501873</td>\n",
       "      <td>0.436951</td>\n",
       "      <td>0.259310</td>\n",
       "      <td>0.479220</td>\n",
       "      <td>0.368132</td>\n",
       "      <td>0.576471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.519692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.434011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.896517</td>\n",
       "      <td>0.551511</td>\n",
       "      <td>0.469048</td>\n",
       "      <td>0.321651</td>\n",
       "      <td>0.500217</td>\n",
       "      <td>0.437528</td>\n",
       "      <td>0.635294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.553019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.496269</td>\n",
       "      <td>0.918905</td>\n",
       "      <td>0.579091</td>\n",
       "      <td>0.488143</td>\n",
       "      <td>0.354547</td>\n",
       "      <td>0.522595</td>\n",
       "      <td>0.515685</td>\n",
       "      <td>0.682353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.578073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643650</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.926368</td>\n",
       "      <td>0.598915</td>\n",
       "      <td>0.504911</td>\n",
       "      <td>0.385994</td>\n",
       "      <td>0.528724</td>\n",
       "      <td>0.556342</td>\n",
       "      <td>0.761765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.613445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.621682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.938308</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.539513</td>\n",
       "      <td>0.508237</td>\n",
       "      <td>0.564766</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.835294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear   test Loss  \\\n",
       "count     114.000000         114.000000                0.0  114.000000   \n",
       "mean        0.886325           0.549485                NaN    0.477472   \n",
       "std         0.010419           0.034398                NaN    0.060049   \n",
       "min         0.854000           0.457944                NaN    0.337015   \n",
       "25%         0.880000           0.519692                NaN    0.434011   \n",
       "50%         0.888000           0.553019                NaN    0.471294   \n",
       "75%         0.893750           0.578073                NaN    0.521337   \n",
       "max         0.908000           0.613445                NaN    0.621682   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count                    0.0      114.000000   114.000000      114.000000   \n",
       "mean                     NaN        0.598312     0.522912        0.912272   \n",
       "std                      NaN        0.059474     0.087491        0.017925   \n",
       "min                      NaN        0.468421     0.365672        0.867662   \n",
       "25%                      NaN        0.547170     0.447761        0.896517   \n",
       "50%                      NaN        0.608696     0.496269        0.918905   \n",
       "75%                      NaN        0.643650     0.619403        0.926368   \n",
       "max                      NaN        0.717391     0.664179        0.938308   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count          114.000000           38.000000  114.000000   \n",
       "mean             0.575503            0.488324    0.356876   \n",
       "std              0.031314            0.025352    0.049796   \n",
       "min              0.501873            0.436951    0.259310   \n",
       "25%              0.551511            0.469048    0.321651   \n",
       "50%              0.579091            0.488143    0.354547   \n",
       "75%              0.598915            0.504911    0.385994   \n",
       "max              0.643564            0.539513    0.508237   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count               38.000000       114.000000    114.000000  \n",
       "mean                 0.518006         0.502310      0.693808  \n",
       "std                  0.022445         0.068440      0.070335  \n",
       "min                  0.479220         0.368132      0.576471  \n",
       "25%                  0.500217         0.437528      0.635294  \n",
       "50%                  0.522595         0.515685      0.682353  \n",
       "75%                  0.528724         0.556342      0.761765  \n",
       "max                  0.564766         0.632184      0.835294  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"model_name\"].str.contains(\"ft20\")&df[\"model_dir_parent\"].str.contains(\"reddit\")].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.889631</td>\n",
       "      <td>0.556689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616103</td>\n",
       "      <td>0.519564</td>\n",
       "      <td>0.913222</td>\n",
       "      <td>0.576077</td>\n",
       "      <td>0.472772</td>\n",
       "      <td>0.351914</td>\n",
       "      <td>0.509898</td>\n",
       "      <td>0.502990</td>\n",
       "      <td>0.689189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012674</td>\n",
       "      <td>0.029699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061584</td>\n",
       "      <td>0.074937</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.029764</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>0.048060</td>\n",
       "      <td>0.024269</td>\n",
       "      <td>0.057346</td>\n",
       "      <td>0.065336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.458716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.424370</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.481752</td>\n",
       "      <td>0.409904</td>\n",
       "      <td>0.227242</td>\n",
       "      <td>0.457706</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.541176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.538203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.442533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594122</td>\n",
       "      <td>0.470149</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.559786</td>\n",
       "      <td>0.452652</td>\n",
       "      <td>0.324985</td>\n",
       "      <td>0.495162</td>\n",
       "      <td>0.478974</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.561120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.468689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628719</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.918905</td>\n",
       "      <td>0.581117</td>\n",
       "      <td>0.482824</td>\n",
       "      <td>0.345211</td>\n",
       "      <td>0.513778</td>\n",
       "      <td>0.515478</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.580073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654746</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.594856</td>\n",
       "      <td>0.496302</td>\n",
       "      <td>0.375990</td>\n",
       "      <td>0.531811</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.717647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.753731</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.516319</td>\n",
       "      <td>0.510704</td>\n",
       "      <td>0.545763</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.870588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear   test Loss  \\\n",
       "count     222.000000         222.000000                0.0  222.000000   \n",
       "mean        0.889631           0.556689                NaN    0.469021   \n",
       "std         0.012674           0.029699                NaN    0.054419   \n",
       "min         0.830000           0.458716                NaN    0.308932   \n",
       "25%         0.886000           0.538203                NaN    0.442533   \n",
       "50%         0.893000           0.561120                NaN    0.468689   \n",
       "75%         0.897000           0.580073                NaN    0.495938   \n",
       "max         0.912000           0.622222                NaN    0.641866   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count                    0.0      222.000000   222.000000      222.000000   \n",
       "mean                     NaN        0.616103     0.519564        0.913222   \n",
       "std                      NaN        0.061584     0.074937        0.017361   \n",
       "min                      NaN        0.424370     0.373134        0.841791   \n",
       "25%                      NaN        0.594122     0.470149        0.910448   \n",
       "50%                      NaN        0.628719     0.507463        0.918905   \n",
       "75%                      NaN        0.654746     0.544776        0.923383   \n",
       "max                      NaN        0.744681     0.753731        0.935323   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count          222.000000           38.000000  222.000000   \n",
       "mean             0.576077            0.472772    0.351914   \n",
       "std              0.029764            0.031813    0.048060   \n",
       "min              0.481752            0.409904    0.227242   \n",
       "25%              0.559786            0.452652    0.324985   \n",
       "50%              0.581117            0.482824    0.345211   \n",
       "75%              0.594856            0.496302    0.375990   \n",
       "max              0.648936            0.516319    0.510704   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count               38.000000       222.000000    222.000000  \n",
       "mean                 0.509898         0.502990      0.689189  \n",
       "std                  0.024269         0.057346      0.065336  \n",
       "min                  0.457706         0.333333      0.541176  \n",
       "25%                  0.495162         0.478974      0.647059  \n",
       "50%                  0.513778         0.515478      0.676471  \n",
       "75%                  0.531811         0.540000      0.717647  \n",
       "max                  0.545763         0.619048      0.870588  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"model_name\"].str.contains(\"ft6\")&df[\"model_dir_parent\"].str.contains(\"reddit\")].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.877648</td>\n",
       "      <td>0.530767</td>\n",
       "      <td>0.394214</td>\n",
       "      <td>0.440682</td>\n",
       "      <td>0.416614</td>\n",
       "      <td>0.559141</td>\n",
       "      <td>0.526155</td>\n",
       "      <td>0.895949</td>\n",
       "      <td>0.527250</td>\n",
       "      <td>0.473292</td>\n",
       "      <td>0.378256</td>\n",
       "      <td>0.492101</td>\n",
       "      <td>0.446751</td>\n",
       "      <td>0.675854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.049111</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>0.049949</td>\n",
       "      <td>0.042219</td>\n",
       "      <td>0.058934</td>\n",
       "      <td>0.103923</td>\n",
       "      <td>0.022894</td>\n",
       "      <td>0.032346</td>\n",
       "      <td>0.040935</td>\n",
       "      <td>0.065082</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.077313</td>\n",
       "      <td>0.084773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.294158</td>\n",
       "      <td>0.306861</td>\n",
       "      <td>0.330020</td>\n",
       "      <td>0.439394</td>\n",
       "      <td>0.246269</td>\n",
       "      <td>0.827861</td>\n",
       "      <td>0.427536</td>\n",
       "      <td>0.351639</td>\n",
       "      <td>0.218546</td>\n",
       "      <td>0.390519</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.873000</td>\n",
       "      <td>0.510067</td>\n",
       "      <td>0.378241</td>\n",
       "      <td>0.414953</td>\n",
       "      <td>0.398873</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.881592</td>\n",
       "      <td>0.511013</td>\n",
       "      <td>0.453966</td>\n",
       "      <td>0.340201</td>\n",
       "      <td>0.476972</td>\n",
       "      <td>0.393750</td>\n",
       "      <td>0.623529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.389634</td>\n",
       "      <td>0.432840</td>\n",
       "      <td>0.416495</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.897512</td>\n",
       "      <td>0.529148</td>\n",
       "      <td>0.474097</td>\n",
       "      <td>0.383505</td>\n",
       "      <td>0.496001</td>\n",
       "      <td>0.434109</td>\n",
       "      <td>0.694118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.564885</td>\n",
       "      <td>0.429435</td>\n",
       "      <td>0.468542</td>\n",
       "      <td>0.441779</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.912438</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.505464</td>\n",
       "      <td>0.416792</td>\n",
       "      <td>0.511805</td>\n",
       "      <td>0.488189</td>\n",
       "      <td>0.729412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.487822</td>\n",
       "      <td>0.616851</td>\n",
       "      <td>0.507263</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.938308</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.548576</td>\n",
       "      <td>0.538841</td>\n",
       "      <td>0.555753</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear   test Loss  \\\n",
       "count     105.000000         105.000000          19.000000  105.000000   \n",
       "mean        0.877648           0.530767           0.394214    0.440682   \n",
       "std         0.011742           0.049111           0.048942    0.049949   \n",
       "min         0.841000           0.349206           0.294158    0.306861   \n",
       "25%         0.873000           0.510067           0.378241    0.414953   \n",
       "50%         0.879000           0.540541           0.389634    0.432840   \n",
       "75%         0.885000           0.564885           0.429435    0.468542   \n",
       "max         0.901000           0.608392           0.487822    0.616851   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count              19.000000      105.000000   105.000000      105.000000   \n",
       "mean                0.416614        0.559141     0.526155        0.895949   \n",
       "std                 0.042219        0.058934     0.103923        0.022894   \n",
       "min                 0.330020        0.439394     0.246269        0.827861   \n",
       "25%                 0.398873        0.523810     0.462687        0.881592   \n",
       "50%                 0.416495        0.555556     0.552239        0.897512   \n",
       "75%                 0.441779        0.590909     0.597015        0.912438   \n",
       "max                 0.507263        0.728571     0.716418        0.938308   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count          105.000000          105.000000  105.000000   \n",
       "mean             0.527250            0.473292    0.378256   \n",
       "std              0.032346            0.040935    0.065082   \n",
       "min              0.427536            0.351639    0.218546   \n",
       "25%              0.511013            0.453966    0.340201   \n",
       "50%              0.529148            0.474097    0.383505   \n",
       "75%              0.551282            0.505464    0.416792   \n",
       "max              0.584906            0.548576    0.538841   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count              105.000000       105.000000    105.000000  \n",
       "mean                 0.492101         0.446751      0.675854  \n",
       "std                  0.030763         0.077313      0.084773  \n",
       "min                  0.390519         0.303571      0.470588  \n",
       "25%                  0.476972         0.393750      0.623529  \n",
       "50%                  0.496001         0.434109      0.694118  \n",
       "75%                  0.511805         0.488189      0.729412  \n",
       "max                  0.555753         0.682540      0.800000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"model_name\"].str.contains(\"lmseed-1\")&df[\"model_dir_parent\"].str.contains(\"wiki\")].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.883971</td>\n",
       "      <td>0.497524</td>\n",
       "      <td>0.378477</td>\n",
       "      <td>0.487743</td>\n",
       "      <td>0.410213</td>\n",
       "      <td>0.604804</td>\n",
       "      <td>0.435608</td>\n",
       "      <td>0.917716</td>\n",
       "      <td>0.557504</td>\n",
       "      <td>0.513135</td>\n",
       "      <td>0.350163</td>\n",
       "      <td>0.518178</td>\n",
       "      <td>0.524011</td>\n",
       "      <td>0.609300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.049955</td>\n",
       "      <td>0.055686</td>\n",
       "      <td>0.070524</td>\n",
       "      <td>0.036650</td>\n",
       "      <td>0.055474</td>\n",
       "      <td>0.086233</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>0.028135</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.054146</td>\n",
       "      <td>0.028378</td>\n",
       "      <td>0.060992</td>\n",
       "      <td>0.065841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.295877</td>\n",
       "      <td>0.310529</td>\n",
       "      <td>0.351113</td>\n",
       "      <td>0.369281</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.790050</td>\n",
       "      <td>0.418733</td>\n",
       "      <td>0.332226</td>\n",
       "      <td>0.227039</td>\n",
       "      <td>0.419594</td>\n",
       "      <td>0.273381</td>\n",
       "      <td>0.447059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.480349</td>\n",
       "      <td>0.331747</td>\n",
       "      <td>0.452680</td>\n",
       "      <td>0.384954</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.402985</td>\n",
       "      <td>0.913433</td>\n",
       "      <td>0.543590</td>\n",
       "      <td>0.496241</td>\n",
       "      <td>0.331412</td>\n",
       "      <td>0.501775</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.576471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.504274</td>\n",
       "      <td>0.392966</td>\n",
       "      <td>0.480935</td>\n",
       "      <td>0.402936</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.919403</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.511386</td>\n",
       "      <td>0.348879</td>\n",
       "      <td>0.516180</td>\n",
       "      <td>0.519608</td>\n",
       "      <td>0.611765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.531532</td>\n",
       "      <td>0.426830</td>\n",
       "      <td>0.510850</td>\n",
       "      <td>0.443213</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.574586</td>\n",
       "      <td>0.531980</td>\n",
       "      <td>0.374401</td>\n",
       "      <td>0.535929</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.452756</td>\n",
       "      <td>0.743211</td>\n",
       "      <td>0.461858</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.843284</td>\n",
       "      <td>0.942289</td>\n",
       "      <td>0.639053</td>\n",
       "      <td>0.605920</td>\n",
       "      <td>0.708696</td>\n",
       "      <td>0.605933</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.894118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear   test Loss  \\\n",
       "count     105.000000         105.000000          19.000000  105.000000   \n",
       "mean        0.883971           0.497524           0.378477    0.487743   \n",
       "std         0.011456           0.049955           0.055686    0.070524   \n",
       "min         0.786000           0.340909           0.295877    0.310529   \n",
       "25%         0.880000           0.480349           0.331747    0.452680   \n",
       "50%         0.886000           0.504274           0.392966    0.480935   \n",
       "75%         0.889000           0.531532           0.426830    0.510850   \n",
       "max         0.896000           0.570470           0.452756    0.743211   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count              19.000000      105.000000   105.000000      105.000000   \n",
       "mean                0.410213        0.604804     0.435608        0.917716   \n",
       "std                 0.036650        0.055474     0.086233        0.015613   \n",
       "min                 0.351113        0.369281     0.223881        0.790050   \n",
       "25%                 0.384954        0.568421     0.402985        0.913433   \n",
       "50%                 0.402936        0.606383     0.432836        0.919403   \n",
       "75%                 0.443213        0.633663     0.485075        0.925373   \n",
       "max                 0.461858        0.756098     0.843284        0.942289   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count          105.000000          105.000000  105.000000   \n",
       "mean             0.557504            0.513135    0.350163   \n",
       "std              0.028135            0.032800    0.054146   \n",
       "min              0.418733            0.332226    0.227039   \n",
       "25%              0.543590            0.496241    0.331412   \n",
       "50%              0.556818            0.511386    0.348879   \n",
       "75%              0.574586            0.531980    0.374401   \n",
       "max              0.639053            0.605920    0.708696   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count              105.000000       105.000000    105.000000  \n",
       "mean                 0.518178         0.524011      0.609300  \n",
       "std                  0.028378         0.060992      0.065841  \n",
       "min                  0.419594         0.273381      0.447059  \n",
       "25%                  0.501775         0.490566      0.576471  \n",
       "50%                  0.516180         0.519608      0.611765  \n",
       "75%                  0.535929         0.550562      0.647059  \n",
       "max                  0.605933         0.764706      0.894118  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"model_name\"].str.contains(\"lmseed-0\")&df[\"model_dir_parent\"].str.contains(\"wiki\")].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.882701</td>\n",
       "      <td>0.508385</td>\n",
       "      <td>0.386346</td>\n",
       "      <td>0.469366</td>\n",
       "      <td>0.413414</td>\n",
       "      <td>0.594190</td>\n",
       "      <td>0.465805</td>\n",
       "      <td>0.910322</td>\n",
       "      <td>0.544230</td>\n",
       "      <td>0.496651</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.506987</td>\n",
       "      <td>0.499340</td>\n",
       "      <td>0.626427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.010649</td>\n",
       "      <td>0.061408</td>\n",
       "      <td>0.052320</td>\n",
       "      <td>0.077210</td>\n",
       "      <td>0.039129</td>\n",
       "      <td>0.059123</td>\n",
       "      <td>0.113975</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>0.026982</td>\n",
       "      <td>0.033789</td>\n",
       "      <td>0.063274</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.079239</td>\n",
       "      <td>0.089218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.294158</td>\n",
       "      <td>0.306861</td>\n",
       "      <td>0.330020</td>\n",
       "      <td>0.369281</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.790050</td>\n",
       "      <td>0.418733</td>\n",
       "      <td>0.332226</td>\n",
       "      <td>0.218546</td>\n",
       "      <td>0.419594</td>\n",
       "      <td>0.273381</td>\n",
       "      <td>0.447059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.878250</td>\n",
       "      <td>0.475739</td>\n",
       "      <td>0.341244</td>\n",
       "      <td>0.418694</td>\n",
       "      <td>0.392833</td>\n",
       "      <td>0.553692</td>\n",
       "      <td>0.389925</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.522606</td>\n",
       "      <td>0.472869</td>\n",
       "      <td>0.324373</td>\n",
       "      <td>0.491255</td>\n",
       "      <td>0.428529</td>\n",
       "      <td>0.564706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.522408</td>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.460637</td>\n",
       "      <td>0.412878</td>\n",
       "      <td>0.586261</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.498272</td>\n",
       "      <td>0.366168</td>\n",
       "      <td>0.507061</td>\n",
       "      <td>0.504717</td>\n",
       "      <td>0.623529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.555996</td>\n",
       "      <td>0.429274</td>\n",
       "      <td>0.499096</td>\n",
       "      <td>0.442910</td>\n",
       "      <td>0.629365</td>\n",
       "      <td>0.557836</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>0.559594</td>\n",
       "      <td>0.520867</td>\n",
       "      <td>0.393097</td>\n",
       "      <td>0.522013</td>\n",
       "      <td>0.547654</td>\n",
       "      <td>0.694118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.487822</td>\n",
       "      <td>0.743211</td>\n",
       "      <td>0.507263</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.843284</td>\n",
       "      <td>0.942289</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.564153</td>\n",
       "      <td>0.708696</td>\n",
       "      <td>0.565151</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.894118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear   test Loss  \\\n",
       "count     134.000000         134.000000          38.000000  134.000000   \n",
       "mean        0.882701           0.508385           0.386346    0.469366   \n",
       "std         0.010649           0.061408           0.052320    0.077210   \n",
       "min         0.786000           0.340909           0.294158    0.306861   \n",
       "25%         0.878250           0.475739           0.341244    0.418694   \n",
       "50%         0.883000           0.522408           0.391300    0.460637   \n",
       "75%         0.888000           0.555996           0.429274    0.499096   \n",
       "max         0.901000           0.608392           0.487822    0.743211   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count              38.000000      134.000000   134.000000      134.000000   \n",
       "mean                0.413414        0.594190     0.465805        0.910322   \n",
       "std                 0.039129        0.059123     0.113975        0.019958   \n",
       "min                 0.330020        0.369281     0.223881        0.790050   \n",
       "25%                 0.392833        0.553692     0.389925        0.895522   \n",
       "50%                 0.412878        0.586261     0.462687        0.916418   \n",
       "75%                 0.442910        0.629365     0.557836        0.924378   \n",
       "max                 0.507263        0.756098     0.843284        0.942289   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count          134.000000          134.000000  134.000000   \n",
       "mean             0.544230            0.496651    0.355789   \n",
       "std              0.026982            0.033789    0.063274   \n",
       "min              0.418733            0.332226    0.218546   \n",
       "25%              0.522606            0.472869    0.324373   \n",
       "50%              0.545455            0.498272    0.366168   \n",
       "75%              0.559594            0.520867    0.393097   \n",
       "max              0.602273            0.564153    0.708696   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count              134.000000       134.000000    134.000000  \n",
       "mean                 0.506987         0.499340      0.626427  \n",
       "std                  0.026100         0.079239      0.089218  \n",
       "min                  0.419594         0.273381      0.447059  \n",
       "25%                  0.491255         0.428529      0.564706  \n",
       "50%                  0.507061         0.504717      0.623529  \n",
       "75%                  0.522013         0.547654      0.694118  \n",
       "max                  0.565151         0.764706      0.894118  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"model_name\"].str.contains(\"ft6\")&df[\"model_dir_parent\"].str.contains(\"wiki\")].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.889631</td>\n",
       "      <td>0.556689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616103</td>\n",
       "      <td>0.519564</td>\n",
       "      <td>0.913222</td>\n",
       "      <td>0.576077</td>\n",
       "      <td>0.472772</td>\n",
       "      <td>0.351914</td>\n",
       "      <td>0.509898</td>\n",
       "      <td>0.502990</td>\n",
       "      <td>0.689189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012674</td>\n",
       "      <td>0.029699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061584</td>\n",
       "      <td>0.074937</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.029764</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>0.048060</td>\n",
       "      <td>0.024269</td>\n",
       "      <td>0.057346</td>\n",
       "      <td>0.065336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.458716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.424370</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.481752</td>\n",
       "      <td>0.409904</td>\n",
       "      <td>0.227242</td>\n",
       "      <td>0.457706</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.541176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.538203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.442533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594122</td>\n",
       "      <td>0.470149</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.559786</td>\n",
       "      <td>0.452652</td>\n",
       "      <td>0.324985</td>\n",
       "      <td>0.495162</td>\n",
       "      <td>0.478974</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.561120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.468689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628719</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.918905</td>\n",
       "      <td>0.581117</td>\n",
       "      <td>0.482824</td>\n",
       "      <td>0.345211</td>\n",
       "      <td>0.513778</td>\n",
       "      <td>0.515478</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.580073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654746</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.594856</td>\n",
       "      <td>0.496302</td>\n",
       "      <td>0.375990</td>\n",
       "      <td>0.531811</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.717647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.753731</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.516319</td>\n",
       "      <td>0.510704</td>\n",
       "      <td>0.545763</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.870588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear   test Loss  \\\n",
       "count     222.000000         222.000000                0.0  222.000000   \n",
       "mean        0.889631           0.556689                NaN    0.469021   \n",
       "std         0.012674           0.029699                NaN    0.054419   \n",
       "min         0.830000           0.458716                NaN    0.308932   \n",
       "25%         0.886000           0.538203                NaN    0.442533   \n",
       "50%         0.893000           0.561120                NaN    0.468689   \n",
       "75%         0.897000           0.580073                NaN    0.495938   \n",
       "max         0.912000           0.622222                NaN    0.641866   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count                    0.0      222.000000   222.000000      222.000000   \n",
       "mean                     NaN        0.616103     0.519564        0.913222   \n",
       "std                      NaN        0.061584     0.074937        0.017361   \n",
       "min                      NaN        0.424370     0.373134        0.841791   \n",
       "25%                      NaN        0.594122     0.470149        0.910448   \n",
       "50%                      NaN        0.628719     0.507463        0.918905   \n",
       "75%                      NaN        0.654746     0.544776        0.923383   \n",
       "max                      NaN        0.744681     0.753731        0.935323   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count          222.000000           38.000000  222.000000   \n",
       "mean             0.576077            0.472772    0.351914   \n",
       "std              0.029764            0.031813    0.048060   \n",
       "min              0.481752            0.409904    0.227242   \n",
       "25%              0.559786            0.452652    0.324985   \n",
       "50%              0.581117            0.482824    0.345211   \n",
       "75%              0.594856            0.496302    0.375990   \n",
       "max              0.648936            0.516319    0.510704   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count               38.000000       222.000000    222.000000  \n",
       "mean                 0.509898         0.502990      0.689189  \n",
       "std                  0.024269         0.057346      0.065336  \n",
       "min                  0.457706         0.333333      0.541176  \n",
       "25%                  0.495162         0.478974      0.647059  \n",
       "50%                  0.513778         0.515478      0.676471  \n",
       "75%                  0.531811         0.540000      0.717647  \n",
       "max                  0.545763         0.619048      0.870588  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"model_name\"].str.contains(\"ft6\")&df[\"model_dir_parent\"].str.contains(\"reddit\")].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>valid F1 score bin</th>\n",
       "      <th>valid Kappa Linear</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.881105</td>\n",
       "      <td>0.527548</td>\n",
       "      <td>0.394214</td>\n",
       "      <td>0.435930</td>\n",
       "      <td>0.416614</td>\n",
       "      <td>0.575084</td>\n",
       "      <td>0.510867</td>\n",
       "      <td>0.899921</td>\n",
       "      <td>0.530734</td>\n",
       "      <td>0.478477</td>\n",
       "      <td>0.358723</td>\n",
       "      <td>0.495977</td>\n",
       "      <td>0.460817</td>\n",
       "      <td>0.663571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.006837</td>\n",
       "      <td>0.062993</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>0.060446</td>\n",
       "      <td>0.042219</td>\n",
       "      <td>0.054312</td>\n",
       "      <td>0.118727</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.018979</td>\n",
       "      <td>0.026522</td>\n",
       "      <td>0.066003</td>\n",
       "      <td>0.019224</td>\n",
       "      <td>0.082383</td>\n",
       "      <td>0.096653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.294158</td>\n",
       "      <td>0.306861</td>\n",
       "      <td>0.330020</td>\n",
       "      <td>0.509317</td>\n",
       "      <td>0.246269</td>\n",
       "      <td>0.875622</td>\n",
       "      <td>0.502128</td>\n",
       "      <td>0.441865</td>\n",
       "      <td>0.218546</td>\n",
       "      <td>0.464773</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.378241</td>\n",
       "      <td>0.410202</td>\n",
       "      <td>0.398873</td>\n",
       "      <td>0.537931</td>\n",
       "      <td>0.395522</td>\n",
       "      <td>0.883582</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.454830</td>\n",
       "      <td>0.308024</td>\n",
       "      <td>0.481969</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.564706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.554795</td>\n",
       "      <td>0.389634</td>\n",
       "      <td>0.421994</td>\n",
       "      <td>0.416495</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.567164</td>\n",
       "      <td>0.891542</td>\n",
       "      <td>0.525140</td>\n",
       "      <td>0.473170</td>\n",
       "      <td>0.377337</td>\n",
       "      <td>0.495008</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.429435</td>\n",
       "      <td>0.445094</td>\n",
       "      <td>0.441779</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.919403</td>\n",
       "      <td>0.546584</td>\n",
       "      <td>0.499536</td>\n",
       "      <td>0.415756</td>\n",
       "      <td>0.509516</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.741176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.487822</td>\n",
       "      <td>0.616851</td>\n",
       "      <td>0.507263</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>0.938308</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>0.548576</td>\n",
       "      <td>0.449702</td>\n",
       "      <td>0.555753</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test Accuracy  test F1 score bin  test Kappa Linear  test Loss  \\\n",
       "count      57.000000          57.000000          19.000000  57.000000   \n",
       "mean        0.881105           0.527548           0.394214   0.435930   \n",
       "std         0.006837           0.062993           0.048942   0.060446   \n",
       "min         0.869000           0.349206           0.294158   0.306861   \n",
       "25%         0.876000           0.500000           0.378241   0.410202   \n",
       "50%         0.881000           0.554795           0.389634   0.421994   \n",
       "75%         0.885000           0.571429           0.429435   0.445094   \n",
       "max         0.901000           0.608392           0.487822   0.616851   \n",
       "\n",
       "       test Matthews Correff  test Precision  test Recall  valid Accuracy  \\\n",
       "count              19.000000       57.000000    57.000000       57.000000   \n",
       "mean                0.416614        0.575084     0.510867        0.899921   \n",
       "std                 0.042219        0.054312     0.118727        0.019059   \n",
       "min                 0.330020        0.509317     0.246269        0.875622   \n",
       "25%                 0.398873        0.537931     0.395522        0.883582   \n",
       "50%                 0.416495        0.559441     0.567164        0.891542   \n",
       "75%                 0.441779        0.600000     0.597015        0.919403   \n",
       "max                 0.507263        0.728571     0.649254        0.938308   \n",
       "\n",
       "       valid F1 score bin  valid Kappa Linear  valid Loss  \\\n",
       "count           57.000000           57.000000   57.000000   \n",
       "mean             0.530734            0.478477    0.358723   \n",
       "std              0.018979            0.026522    0.066003   \n",
       "min              0.502128            0.441865    0.218546   \n",
       "25%              0.514286            0.454830    0.308024   \n",
       "50%              0.525140            0.473170    0.377337   \n",
       "75%              0.546584            0.499536    0.415756   \n",
       "max              0.581081            0.548576    0.449702   \n",
       "\n",
       "       valid Matthews Correff  valid Precision  valid Recall  \n",
       "count               57.000000        57.000000     57.000000  \n",
       "mean                 0.495977         0.460817      0.663571  \n",
       "std                  0.019224         0.082383      0.096653  \n",
       "min                  0.464773         0.386364      0.470588  \n",
       "25%                  0.481969         0.397436      0.564706  \n",
       "50%                  0.495008         0.416667      0.705882  \n",
       "75%                  0.509516         0.520833      0.741176  \n",
       "max                  0.555753         0.682540      0.800000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"model_name\"].str.contains(\"lmseed-1\")&\n",
    "   df[\"model_name\"].str.contains(\"ft6_cl8\")&df[\"model_dir_parent\"].str.contains(\"wiki\")].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-0-clstrainseed-1.m\n",
      "lstm_noearly_stop_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-0-clstrainseed-7.m\n",
      "lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-0-clstrainseed-7.m\n",
      "lstm_ft20_cl8_lmseed-1-ftseed-0-clsweightseed-0-clstrainseed-0.m\n",
      "lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-3-clstrainseed-3.m\n",
      "lstm_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-2-clstrainseed-6.m\n",
      "lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9-clstrainseed-6.m\n",
      "lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-1-clstrainseed-4.m\n"
     ]
    }
   ],
   "source": [
    "for model_name in df.sort_values(\"test F1 score bin\").tail(8)[\"model_name\"]:\n",
    "    print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_nowce_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-4-clstrainseed-0.m\n",
      "lstm_nowce_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-0-clstrainseed-5.m\n",
      "lstm_nowce_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-0-clstrainseed-9.m\n",
      "lstm_nowce_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-1-clstrainseed-0.m\n",
      "lstm_nowce_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-0-clstrainseed-7.m\n",
      "lstm_nowce_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-0-clstrainseed-6.m\n",
      "lstm_nowce_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-0-clstrainseed-5.m\n",
      "lstm_nowce_ft6_cl8_lmseed-0-ftseed-0-clsweightseed-0-clstrainseed-1.m\n"
     ]
    }
   ],
   "source": [
    "for model_name in df.sort_values(\"test F1 score bin\").head(8)[\"model_name\"]:\n",
    "    print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orderby=\"valid F1 score bin\"\n",
    "ycolumn=\"test F1 score bin\"\n",
    "xy = df.sort_values(orderby)\n",
    "plt.plot(xy[orderby], xy[ycolumn], 'b.')\n",
    "# plt.plot(xy[orderby], xy[\"test Precision\"], 'r.')\n",
    "# plt.plot(xy[orderby], xy[\"test Recall\"], 'g.')\n",
    "plt.xlabel(orderby)\n",
    "plt.ylabel(ycolumn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orderby=\"valid Recall\"\n",
    "ycolumn=\"test F1 score bin\"\n",
    "xy = df.sort_values(orderby)\n",
    "plt.plot(xy[orderby], xy[ycolumn], 'b.')\n",
    "plt.xlabel(orderby)\n",
    "plt.ylabel(ycolumn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orderby=\"valid Accuracy\"\n",
    "ycolumn=\"test Accuracy\"\n",
    "xy = df.sort_values(orderby)\n",
    "plt.plot(xy[orderby], xy[ycolumn], 'b.-')\n",
    "plt.xlabel(orderby)\n",
    "plt.ylabel(ycolumn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orderby=\"valid Accuracy\"\n",
    "ycolumn=\"test Accuracy\"\n",
    "xy = df.sort_values(orderby)\n",
    "plt.plot(xy[orderby], xy[ycolumn], 'bo')\n",
    "plt.xlabel(orderby)\n",
    "plt.ylabel(ycolumn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Path (<tt>../poleval.csv</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."
      ],
      "text/plain": [
       "/home/pczapla/workspace/ulmfit-multilingual/experiments/poleval.csv"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.FileLink(\"../poleval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_dir_parent</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test Accuracy</th>\n",
       "      <th>test F1 score bin</th>\n",
       "      <th>test Kappa Linear</th>\n",
       "      <th>test Loss</th>\n",
       "      <th>test Matthews Correff</th>\n",
       "      <th>test Precision</th>\n",
       "      <th>test Recall</th>\n",
       "      <th>valid Accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>valid Loss</th>\n",
       "      <th>valid Matthews Correff</th>\n",
       "      <th>valid Precision</th>\n",
       "      <th>valid Recall</th>\n",
       "      <th>arch</th>\n",
       "      <th>ds</th>\n",
       "      <th>lmseed</th>\n",
       "      <th>fine_tune</th>\n",
       "      <th>model</th>\n",
       "      <th>exp_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.577922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511494</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.876617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429593</td>\n",
       "      <td>0.507218</td>\n",
       "      <td>0.389830</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.572289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.426693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.860696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434975</td>\n",
       "      <td>0.483857</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.573913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469194</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.849751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523841</td>\n",
       "      <td>0.477067</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.577259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530552</td>\n",
       "      <td>0.441885</td>\n",
       "      <td>0.323810</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.851741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488528</td>\n",
       "      <td>0.474608</td>\n",
       "      <td>0.344660</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.570588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470874</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.829851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537976</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.309735</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.842786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541371</td>\n",
       "      <td>0.454872</td>\n",
       "      <td>0.328638</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.457041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497512</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.857711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452747</td>\n",
       "      <td>0.473131</td>\n",
       "      <td>0.352041</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378810</td>\n",
       "      <td>0.492229</td>\n",
       "      <td>0.382857</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.557185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458937</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471542</td>\n",
       "      <td>0.494311</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-1...</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.578231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.419756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.634328</td>\n",
       "      <td>0.891542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345693</td>\n",
       "      <td>0.532369</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-2...</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.494505</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.873632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425387</td>\n",
       "      <td>0.484692</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-3...</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.574924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.876617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449001</td>\n",
       "      <td>0.518262</td>\n",
       "      <td>0.392265</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-4...</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.603390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.419202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552795</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.881592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407950</td>\n",
       "      <td>0.511490</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-5...</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.594771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.427007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.529070</td>\n",
       "      <td>0.679105</td>\n",
       "      <td>0.881592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408002</td>\n",
       "      <td>0.500378</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.869652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478236</td>\n",
       "      <td>0.505266</td>\n",
       "      <td>0.377660</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.474490</td>\n",
       "      <td>0.694030</td>\n",
       "      <td>0.877612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403486</td>\n",
       "      <td>0.525650</td>\n",
       "      <td>0.395604</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.448317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519774</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427392</td>\n",
       "      <td>0.539378</td>\n",
       "      <td>0.411429</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.550820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.892537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404172</td>\n",
       "      <td>0.539953</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.577922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511494</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.876617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429593</td>\n",
       "      <td>0.507218</td>\n",
       "      <td>0.389830</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.572289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.426693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.860696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434975</td>\n",
       "      <td>0.483857</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.573913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469194</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.849751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523841</td>\n",
       "      <td>0.477067</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.577259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.841791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530552</td>\n",
       "      <td>0.441885</td>\n",
       "      <td>0.323810</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.851741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488528</td>\n",
       "      <td>0.474608</td>\n",
       "      <td>0.344660</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.570588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470874</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.829851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537976</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.309735</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.842786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541371</td>\n",
       "      <td>0.454872</td>\n",
       "      <td>0.328638</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.457041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497512</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.857711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452747</td>\n",
       "      <td>0.473131</td>\n",
       "      <td>0.352041</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378810</td>\n",
       "      <td>0.492229</td>\n",
       "      <td>0.382857</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.557185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458937</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471542</td>\n",
       "      <td>0.494311</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-1...</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.578231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.419756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.634328</td>\n",
       "      <td>0.891542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345693</td>\n",
       "      <td>0.532369</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>qrnn_ft0_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>qrnn</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-5...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.595918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.453026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-5...</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.412375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.901493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.446970</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.552301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.526710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.542222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.542986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.484061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.573034</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.561265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.478323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.596639</td>\n",
       "      <td>0.529851</td>\n",
       "      <td>0.912438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.486726</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.559671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626263</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.548043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.401640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.890547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421384</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.528139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.568965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.445748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633027</td>\n",
       "      <td>0.514925</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.508621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.440298</td>\n",
       "      <td>0.921393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.590038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.384665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.906468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.429450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660550</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.521367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.490258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.502203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.425373</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.548523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.631068</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542056</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.490045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619835</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504274</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.607004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.919403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516393</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>data/hate/pl-10-reddit/models/sp25k</td>\n",
       "      <td>lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>lstm_ft6_cl8</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>lstm</td>\n",
       "      <td>_orig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model_dir_parent  \\\n",
       "0    data/hate/pl-10-reddit/models/sp25k   \n",
       "1    data/hate/pl-10-reddit/models/sp25k   \n",
       "2    data/hate/pl-10-reddit/models/sp25k   \n",
       "3    data/hate/pl-10-reddit/models/sp25k   \n",
       "4    data/hate/pl-10-reddit/models/sp25k   \n",
       "5    data/hate/pl-10-reddit/models/sp25k   \n",
       "6    data/hate/pl-10-reddit/models/sp25k   \n",
       "7    data/hate/pl-10-reddit/models/sp25k   \n",
       "8    data/hate/pl-10-reddit/models/sp25k   \n",
       "9    data/hate/pl-10-reddit/models/sp25k   \n",
       "10   data/hate/pl-10-reddit/models/sp25k   \n",
       "11   data/hate/pl-10-reddit/models/sp25k   \n",
       "12   data/hate/pl-10-reddit/models/sp25k   \n",
       "13   data/hate/pl-10-reddit/models/sp25k   \n",
       "14   data/hate/pl-10-reddit/models/sp25k   \n",
       "15   data/hate/pl-10-reddit/models/sp25k   \n",
       "16   data/hate/pl-10-reddit/models/sp25k   \n",
       "17   data/hate/pl-10-reddit/models/sp25k   \n",
       "18   data/hate/pl-10-reddit/models/sp25k   \n",
       "19   data/hate/pl-10-reddit/models/sp25k   \n",
       "20   data/hate/pl-10-reddit/models/sp25k   \n",
       "21   data/hate/pl-10-reddit/models/sp25k   \n",
       "22   data/hate/pl-10-reddit/models/sp25k   \n",
       "23   data/hate/pl-10-reddit/models/sp25k   \n",
       "24   data/hate/pl-10-reddit/models/sp25k   \n",
       "25   data/hate/pl-10-reddit/models/sp25k   \n",
       "26   data/hate/pl-10-reddit/models/sp25k   \n",
       "27   data/hate/pl-10-reddit/models/sp25k   \n",
       "28   data/hate/pl-10-reddit/models/sp25k   \n",
       "29   data/hate/pl-10-reddit/models/sp25k   \n",
       "..                                   ...   \n",
       "306  data/hate/pl-10-reddit/models/sp25k   \n",
       "307  data/hate/pl-10-reddit/models/sp25k   \n",
       "308  data/hate/pl-10-reddit/models/sp25k   \n",
       "309  data/hate/pl-10-reddit/models/sp25k   \n",
       "310  data/hate/pl-10-reddit/models/sp25k   \n",
       "311  data/hate/pl-10-reddit/models/sp25k   \n",
       "312  data/hate/pl-10-reddit/models/sp25k   \n",
       "313  data/hate/pl-10-reddit/models/sp25k   \n",
       "314  data/hate/pl-10-reddit/models/sp25k   \n",
       "315  data/hate/pl-10-reddit/models/sp25k   \n",
       "316  data/hate/pl-10-reddit/models/sp25k   \n",
       "317  data/hate/pl-10-reddit/models/sp25k   \n",
       "318  data/hate/pl-10-reddit/models/sp25k   \n",
       "319  data/hate/pl-10-reddit/models/sp25k   \n",
       "320  data/hate/pl-10-reddit/models/sp25k   \n",
       "321  data/hate/pl-10-reddit/models/sp25k   \n",
       "322  data/hate/pl-10-reddit/models/sp25k   \n",
       "323  data/hate/pl-10-reddit/models/sp25k   \n",
       "324  data/hate/pl-10-reddit/models/sp25k   \n",
       "325  data/hate/pl-10-reddit/models/sp25k   \n",
       "326  data/hate/pl-10-reddit/models/sp25k   \n",
       "327  data/hate/pl-10-reddit/models/sp25k   \n",
       "328  data/hate/pl-10-reddit/models/sp25k   \n",
       "329  data/hate/pl-10-reddit/models/sp25k   \n",
       "330  data/hate/pl-10-reddit/models/sp25k   \n",
       "331  data/hate/pl-10-reddit/models/sp25k   \n",
       "332  data/hate/pl-10-reddit/models/sp25k   \n",
       "333  data/hate/pl-10-reddit/models/sp25k   \n",
       "334  data/hate/pl-10-reddit/models/sp25k   \n",
       "335  data/hate/pl-10-reddit/models/sp25k   \n",
       "\n",
       "                                            model_name  test Accuracy  \\\n",
       "0    qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.870   \n",
       "1    qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.858   \n",
       "2    qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.853   \n",
       "3    qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.855   \n",
       "4    qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.862   \n",
       "5    qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.854   \n",
       "6    qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.850   \n",
       "7    qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.865   \n",
       "8    qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.871   \n",
       "9    qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-0...          0.849   \n",
       "10   qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-1...          0.876   \n",
       "11   qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-2...          0.864   \n",
       "12   qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-3...          0.861   \n",
       "13   qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-4...          0.883   \n",
       "14   qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-5...          0.876   \n",
       "15   qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-6...          0.848   \n",
       "16   qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-7...          0.856   \n",
       "17   qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-8...          0.873   \n",
       "18   qrnn_ft0_cl8_lmseed-0-ftseed-0-clsweightseed-9...          0.863   \n",
       "19   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.870   \n",
       "20   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.858   \n",
       "21   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.853   \n",
       "22   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.855   \n",
       "23   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.862   \n",
       "24   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.854   \n",
       "25   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.850   \n",
       "26   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.865   \n",
       "27   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.871   \n",
       "28   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-0...          0.849   \n",
       "29   qrnn_ft0_cl8_lmseed-1-ftseed-0-clsweightseed-1...          0.876   \n",
       "..                                                 ...            ...   \n",
       "306  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-5...          0.901   \n",
       "307  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-5...          0.890   \n",
       "308  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.900   \n",
       "309  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.893   \n",
       "310  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.897   \n",
       "311  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.895   \n",
       "312  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.899   \n",
       "313  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.889   \n",
       "314  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-6...          0.893   \n",
       "315  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.891   \n",
       "316  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.873   \n",
       "317  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.891   \n",
       "318  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.900   \n",
       "319  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.895   \n",
       "320  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.886   \n",
       "321  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-7...          0.893   \n",
       "322  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.892   \n",
       "323  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.904   \n",
       "324  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.894   \n",
       "325  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.902   \n",
       "326  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.901   \n",
       "327  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.888   \n",
       "328  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-8...          0.901   \n",
       "329  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.887   \n",
       "330  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.893   \n",
       "331  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.895   \n",
       "332  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.895   \n",
       "333  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.894   \n",
       "334  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.899   \n",
       "335  lstm_ft6_cl8_lmseed-1-ftseed-0-clsweightseed-9...          0.906   \n",
       "\n",
       "     test F1 score bin  test Kappa Linear  test Loss  test Matthews Correff  \\\n",
       "0             0.577922                NaN   0.456889                    NaN   \n",
       "1             0.572289                NaN   0.426693                    NaN   \n",
       "2             0.573913                NaN   0.465223                    NaN   \n",
       "3             0.577259                NaN   0.483052                    NaN   \n",
       "4             0.576687                NaN   0.491995                    NaN   \n",
       "5             0.570588                NaN   0.483143                    NaN   \n",
       "6             0.561404                NaN   0.519333                    NaN   \n",
       "7             0.597015                NaN   0.457041                    NaN   \n",
       "8             0.582524                NaN   0.418411                    NaN   \n",
       "9             0.557185                NaN   0.482558                    NaN   \n",
       "10            0.578231                NaN   0.419756                    NaN   \n",
       "11            0.569620                NaN   0.458027                    NaN   \n",
       "12            0.574924                NaN   0.477018                    NaN   \n",
       "13            0.603390                NaN   0.419202                    NaN   \n",
       "14            0.594771                NaN   0.427007                    NaN   \n",
       "15            0.530864                NaN   0.488566                    NaN   \n",
       "16            0.563636                NaN   0.437123                    NaN   \n",
       "17            0.591640                NaN   0.448317                    NaN   \n",
       "18            0.550820                NaN   0.450464                    NaN   \n",
       "19            0.577922                NaN   0.456889                    NaN   \n",
       "20            0.572289                NaN   0.426693                    NaN   \n",
       "21            0.573913                NaN   0.465223                    NaN   \n",
       "22            0.577259                NaN   0.483052                    NaN   \n",
       "23            0.576687                NaN   0.491995                    NaN   \n",
       "24            0.570588                NaN   0.483143                    NaN   \n",
       "25            0.561404                NaN   0.519333                    NaN   \n",
       "26            0.597015                NaN   0.457041                    NaN   \n",
       "27            0.582524                NaN   0.418411                    NaN   \n",
       "28            0.557185                NaN   0.482558                    NaN   \n",
       "29            0.578231                NaN   0.419756                    NaN   \n",
       "..                 ...                ...        ...                    ...   \n",
       "306           0.595918                NaN   0.453026                    NaN   \n",
       "307           0.576923                NaN   0.412375                    NaN   \n",
       "308           0.576271                NaN   0.458157                    NaN   \n",
       "309           0.552301                NaN   0.526710                    NaN   \n",
       "310           0.542222                NaN   0.378023                    NaN   \n",
       "311           0.549356                NaN   0.502734                    NaN   \n",
       "312           0.542986                NaN   0.484061                    NaN   \n",
       "313           0.561265                NaN   0.478323                    NaN   \n",
       "314           0.559671                NaN   0.460062                    NaN   \n",
       "315           0.532189                NaN   0.520550                    NaN   \n",
       "316           0.548043                NaN   0.401640                    NaN   \n",
       "317           0.528139                NaN   0.489808                    NaN   \n",
       "318           0.568965                NaN   0.445748                    NaN   \n",
       "319           0.567901                NaN   0.542561                    NaN   \n",
       "320           0.508621                NaN   0.528722                    NaN   \n",
       "321           0.590038                NaN   0.384665                    NaN   \n",
       "322           0.534483                NaN   0.502705                    NaN   \n",
       "323           0.586207                NaN   0.488476                    NaN   \n",
       "324           0.558333                NaN   0.466521                    NaN   \n",
       "325           0.566372                NaN   0.447245                    NaN   \n",
       "326           0.592593                NaN   0.429450                    NaN   \n",
       "327           0.521367                NaN   0.500936                    NaN   \n",
       "328           0.602410                NaN   0.490258                    NaN   \n",
       "329           0.502203                NaN   0.516663                    NaN   \n",
       "330           0.548523                NaN   0.473883                    NaN   \n",
       "331           0.588235                NaN   0.490045                    NaN   \n",
       "332           0.549356                NaN   0.458278                    NaN   \n",
       "333           0.558333                NaN   0.485095                    NaN   \n",
       "334           0.607004                NaN   0.308932                    NaN   \n",
       "335           0.614754                NaN   0.471272                    NaN   \n",
       "\n",
       "     test Precision  test Recall  valid Accuracy  ...  valid Loss  \\\n",
       "0          0.511494     0.664179        0.876617  ...    0.429593   \n",
       "1          0.479798     0.708955        0.860696  ...    0.434975   \n",
       "2          0.469194     0.738806        0.849751  ...    0.523841   \n",
       "3          0.473684     0.738806        0.841791  ...    0.530552   \n",
       "4          0.489583     0.701493        0.851741  ...    0.488528   \n",
       "5          0.470874     0.723881        0.829851  ...    0.537976   \n",
       "6          0.461538     0.716418        0.842786  ...    0.541371   \n",
       "7          0.497512     0.746269        0.857711  ...    0.452747   \n",
       "8          0.514286     0.671642        0.874627  ...    0.378810   \n",
       "9          0.458937     0.708955        0.866667  ...    0.471542   \n",
       "10         0.531250     0.634328        0.891542  ...    0.345693   \n",
       "11         0.494505     0.671642        0.873632  ...    0.425387   \n",
       "12         0.487047     0.701493        0.876617  ...    0.449001   \n",
       "13         0.552795     0.664179        0.881592  ...    0.407950   \n",
       "14         0.529070     0.679105        0.881592  ...    0.408002   \n",
       "15         0.452632     0.641791        0.869652  ...    0.478236   \n",
       "16         0.474490     0.694030        0.877612  ...    0.403486   \n",
       "17         0.519774     0.686567        0.884577  ...    0.427392   \n",
       "18         0.491228     0.626866        0.892537  ...    0.404172   \n",
       "19         0.511494     0.664179        0.876617  ...    0.429593   \n",
       "20         0.479798     0.708955        0.860696  ...    0.434975   \n",
       "21         0.469194     0.738806        0.849751  ...    0.523841   \n",
       "22         0.473684     0.738806        0.841791  ...    0.530552   \n",
       "23         0.489583     0.701493        0.851741  ...    0.488528   \n",
       "24         0.470874     0.723881        0.829851  ...    0.537976   \n",
       "25         0.461538     0.716418        0.842786  ...    0.541371   \n",
       "26         0.497512     0.746269        0.857711  ...    0.452747   \n",
       "27         0.514286     0.671642        0.874627  ...    0.378810   \n",
       "28         0.458937     0.708955        0.866667  ...    0.471542   \n",
       "29         0.531250     0.634328        0.891542  ...    0.345693   \n",
       "..              ...          ...             ...  ...         ...   \n",
       "306        0.657658     0.544776        0.923383  ...    0.369372   \n",
       "307        0.595238     0.559702        0.901493  ...    0.341758   \n",
       "308        0.666667     0.507463        0.920398  ...    0.343866   \n",
       "309        0.628571     0.492537        0.923383  ...    0.376918   \n",
       "310        0.670330     0.455224        0.928358  ...    0.245958   \n",
       "311        0.646465     0.477612        0.917413  ...    0.366041   \n",
       "312        0.689655     0.447761        0.928358  ...    0.292909   \n",
       "313        0.596639     0.529851        0.912438  ...    0.371474   \n",
       "314        0.623853     0.507463        0.916418  ...    0.314330   \n",
       "315        0.626263     0.462687        0.924378  ...    0.342852   \n",
       "316        0.523810     0.574627        0.890547  ...    0.359008   \n",
       "317        0.628866     0.455224        0.917413  ...    0.327826   \n",
       "318        0.673469     0.492537        0.922388  ...    0.303262   \n",
       "319        0.633027     0.514925        0.922388  ...    0.334571   \n",
       "320        0.602041     0.440298        0.921393  ...    0.341839   \n",
       "321        0.606299     0.574627        0.906468  ...    0.314057   \n",
       "322        0.632653     0.462687        0.922388  ...    0.337562   \n",
       "323        0.693878     0.507463        0.922388  ...    0.342792   \n",
       "324        0.632075     0.500000        0.923383  ...    0.303226   \n",
       "325        0.695652     0.477612        0.917413  ...    0.347164   \n",
       "326        0.660550     0.537313        0.915423  ...    0.313667   \n",
       "327        0.610000     0.455224        0.923383  ...    0.378845   \n",
       "328        0.652174     0.559702        0.914428  ...    0.392229   \n",
       "329        0.612903     0.425373        0.922388  ...    0.355745   \n",
       "330        0.631068     0.485075        0.924378  ...    0.329670   \n",
       "331        0.619835     0.559702        0.914428  ...    0.358677   \n",
       "332        0.646465     0.477612        0.916418  ...    0.332558   \n",
       "333        0.632075     0.500000        0.928358  ...    0.338581   \n",
       "334        0.634146     0.582090        0.919403  ...    0.237768   \n",
       "335        0.681818     0.559702        0.917413  ...    0.372592   \n",
       "\n",
       "     valid Matthews Correff  valid Precision  valid Recall          arch  \\\n",
       "0                  0.507218         0.389830      0.811765  qrnn_ft0_cl8   \n",
       "1                  0.483857         0.358974      0.823529  qrnn_ft0_cl8   \n",
       "2                  0.477067         0.342857      0.847059  qrnn_ft0_cl8   \n",
       "3                  0.441885         0.323810      0.800000  qrnn_ft0_cl8   \n",
       "4                  0.474608         0.344660      0.835294  qrnn_ft0_cl8   \n",
       "5                  0.435847         0.309735      0.823529  qrnn_ft0_cl8   \n",
       "6                  0.454872         0.328638      0.823529  qrnn_ft0_cl8   \n",
       "7                  0.473131         0.352041      0.811765  qrnn_ft0_cl8   \n",
       "8                  0.492229         0.382857      0.788235  qrnn_ft0_cl8   \n",
       "9                  0.494311         0.370370      0.823529  qrnn_ft0_cl8   \n",
       "10                 0.532369         0.425000      0.800000  qrnn_ft0_cl8   \n",
       "11                 0.484692         0.379310      0.776471  qrnn_ft0_cl8   \n",
       "12                 0.518262         0.392265      0.835294  qrnn_ft0_cl8   \n",
       "13                 0.511490         0.400000      0.800000  qrnn_ft0_cl8   \n",
       "14                 0.500378         0.397590      0.776471  qrnn_ft0_cl8   \n",
       "15                 0.505266         0.377660      0.835294  qrnn_ft0_cl8   \n",
       "16                 0.525650         0.395604      0.847059  qrnn_ft0_cl8   \n",
       "17                 0.539378         0.411429      0.847059  qrnn_ft0_cl8   \n",
       "18                 0.539953         0.428571      0.811765  qrnn_ft0_cl8   \n",
       "19                 0.507218         0.389830      0.811765  qrnn_ft0_cl8   \n",
       "20                 0.483857         0.358974      0.823529  qrnn_ft0_cl8   \n",
       "21                 0.477067         0.342857      0.847059  qrnn_ft0_cl8   \n",
       "22                 0.441885         0.323810      0.800000  qrnn_ft0_cl8   \n",
       "23                 0.474608         0.344660      0.835294  qrnn_ft0_cl8   \n",
       "24                 0.435847         0.309735      0.823529  qrnn_ft0_cl8   \n",
       "25                 0.454872         0.328638      0.823529  qrnn_ft0_cl8   \n",
       "26                 0.473131         0.352041      0.811765  qrnn_ft0_cl8   \n",
       "27                 0.492229         0.382857      0.788235  qrnn_ft0_cl8   \n",
       "28                 0.494311         0.370370      0.823529  qrnn_ft0_cl8   \n",
       "29                 0.532369         0.425000      0.800000  qrnn_ft0_cl8   \n",
       "..                      ...              ...           ...           ...   \n",
       "306                     NaN         0.538462      0.658824  lstm_ft6_cl8   \n",
       "307                     NaN         0.446970      0.694118  lstm_ft6_cl8   \n",
       "308                     NaN         0.523364      0.658824  lstm_ft6_cl8   \n",
       "309                     NaN         0.540816      0.623529  lstm_ft6_cl8   \n",
       "310                     NaN         0.564356      0.670588  lstm_ft6_cl8   \n",
       "311                     NaN         0.509259      0.647059  lstm_ft6_cl8   \n",
       "312                     NaN         0.573034      0.600000  lstm_ft6_cl8   \n",
       "313                     NaN         0.486726      0.647059  lstm_ft6_cl8   \n",
       "314                     NaN         0.504425      0.670588  lstm_ft6_cl8   \n",
       "315                     NaN         0.545455      0.635294  lstm_ft6_cl8   \n",
       "316                     NaN         0.421384      0.788235  lstm_ft6_cl8   \n",
       "317                     NaN         0.509804      0.611765  lstm_ft6_cl8   \n",
       "318                     NaN         0.534653      0.635294  lstm_ft6_cl8   \n",
       "319                     NaN         0.533333      0.658824  lstm_ft6_cl8   \n",
       "320                     NaN         0.528302      0.658824  lstm_ft6_cl8   \n",
       "321                     NaN         0.466667      0.741176  lstm_ft6_cl8   \n",
       "322                     NaN         0.537634      0.588235  lstm_ft6_cl8   \n",
       "323                     NaN         0.533333      0.658824  lstm_ft6_cl8   \n",
       "324                     NaN         0.538462      0.658824  lstm_ft6_cl8   \n",
       "325                     NaN         0.510204      0.588235  lstm_ft6_cl8   \n",
       "326                     NaN         0.500000      0.623529  lstm_ft6_cl8   \n",
       "327                     NaN         0.540000      0.635294  lstm_ft6_cl8   \n",
       "328                     NaN         0.495726      0.682353  lstm_ft6_cl8   \n",
       "329                     NaN         0.534653      0.635294  lstm_ft6_cl8   \n",
       "330                     NaN         0.542056      0.682353  lstm_ft6_cl8   \n",
       "331                     NaN         0.496000      0.729412  lstm_ft6_cl8   \n",
       "332                     NaN         0.504274      0.694118  lstm_ft6_cl8   \n",
       "333                     NaN         0.568421      0.635294  lstm_ft6_cl8   \n",
       "334                     NaN         0.516393      0.741176  lstm_ft6_cl8   \n",
       "335                     NaN         0.509091      0.658824  lstm_ft6_cl8   \n",
       "\n",
       "         ds lmseed fine_tune model exp_type  \n",
       "0    reddit      0        no  qrnn    _orig  \n",
       "1    reddit      0        no  qrnn    _orig  \n",
       "2    reddit      0        no  qrnn    _orig  \n",
       "3    reddit      0        no  qrnn    _orig  \n",
       "4    reddit      0        no  qrnn    _orig  \n",
       "5    reddit      0        no  qrnn    _orig  \n",
       "6    reddit      0        no  qrnn    _orig  \n",
       "7    reddit      0        no  qrnn    _orig  \n",
       "8    reddit      0        no  qrnn    _orig  \n",
       "9    reddit      0        no  qrnn    _orig  \n",
       "10   reddit      0        no  qrnn    _orig  \n",
       "11   reddit      0        no  qrnn    _orig  \n",
       "12   reddit      0        no  qrnn    _orig  \n",
       "13   reddit      0        no  qrnn    _orig  \n",
       "14   reddit      0        no  qrnn    _orig  \n",
       "15   reddit      0        no  qrnn    _orig  \n",
       "16   reddit      0        no  qrnn    _orig  \n",
       "17   reddit      0        no  qrnn    _orig  \n",
       "18   reddit      0        no  qrnn    _orig  \n",
       "19   reddit      1        no  qrnn    _orig  \n",
       "20   reddit      1        no  qrnn    _orig  \n",
       "21   reddit      1        no  qrnn    _orig  \n",
       "22   reddit      1        no  qrnn    _orig  \n",
       "23   reddit      1        no  qrnn    _orig  \n",
       "24   reddit      1        no  qrnn    _orig  \n",
       "25   reddit      1        no  qrnn    _orig  \n",
       "26   reddit      1        no  qrnn    _orig  \n",
       "27   reddit      1        no  qrnn    _orig  \n",
       "28   reddit      1        no  qrnn    _orig  \n",
       "29   reddit      1        no  qrnn    _orig  \n",
       "..      ...    ...       ...   ...      ...  \n",
       "306  reddit      1       yes  lstm    _orig  \n",
       "307  reddit      1       yes  lstm    _orig  \n",
       "308  reddit      1       yes  lstm    _orig  \n",
       "309  reddit      1       yes  lstm    _orig  \n",
       "310  reddit      1       yes  lstm    _orig  \n",
       "311  reddit      1       yes  lstm    _orig  \n",
       "312  reddit      1       yes  lstm    _orig  \n",
       "313  reddit      1       yes  lstm    _orig  \n",
       "314  reddit      1       yes  lstm    _orig  \n",
       "315  reddit      1       yes  lstm    _orig  \n",
       "316  reddit      1       yes  lstm    _orig  \n",
       "317  reddit      1       yes  lstm    _orig  \n",
       "318  reddit      1       yes  lstm    _orig  \n",
       "319  reddit      1       yes  lstm    _orig  \n",
       "320  reddit      1       yes  lstm    _orig  \n",
       "321  reddit      1       yes  lstm    _orig  \n",
       "322  reddit      1       yes  lstm    _orig  \n",
       "323  reddit      1       yes  lstm    _orig  \n",
       "324  reddit      1       yes  lstm    _orig  \n",
       "325  reddit      1       yes  lstm    _orig  \n",
       "326  reddit      1       yes  lstm    _orig  \n",
       "327  reddit      1       yes  lstm    _orig  \n",
       "328  reddit      1       yes  lstm    _orig  \n",
       "329  reddit      1       yes  lstm    _orig  \n",
       "330  reddit      1       yes  lstm    _orig  \n",
       "331  reddit      1       yes  lstm    _orig  \n",
       "332  reddit      1       yes  lstm    _orig  \n",
       "333  reddit      1       yes  lstm    _orig  \n",
       "334  reddit      1       yes  lstm    _orig  \n",
       "335  reddit      1       yes  lstm    _orig  \n",
       "\n",
       "[584 rows x 22 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastaiv1]",
   "language": "python",
   "name": "conda-env-fastaiv1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
